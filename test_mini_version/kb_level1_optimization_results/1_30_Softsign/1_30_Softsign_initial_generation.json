[
  {
    "attempt": 0,
    "type": "generation",
    "response_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\nsource = r'''\n#include <torch/extension.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\ntemplate <typename scalar_t>\n__global__ void softsign_kernel(const scalar_t* __restrict__ x,\n                                scalar_t* __restrict__ y,\n                                const size_t N) {\n    size_t idx     = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t stride  = blockDim.x * gridDim.x;\n\n    for (size_t i = idx; i < N; i += stride) {\n        scalar_t val    = x[i];\n        scalar_t absval = val >= scalar_t(0) ? val : -val;\n        y[i]            = val / (scalar_t(1) + absval);\n    }\n}\n\ntorch::Tensor softsign_cuda(torch::Tensor x) {\n    TORCH_CHECK(x.is_cuda(),  \"Input tensor must reside on CUDA device\");\n    TORCH_CHECK(x.is_contiguous(), \"Input tensor must be contiguous\");\n    TORCH_CHECK(x.layout() == torch::kStrided, \"Only strided tensors supported\");\n\n    auto out = torch::empty_like(x);\n    const size_t N = x.numel();\n\n    const int threads = 256;\n    int blocks = std::min<int>((N + threads - 1) / threads, 65535);\n\n    AT_DISPATCH_FLOATING_TYPES_AND2(torch::kHalf, torch::kBFloat16,\n                                    x.scalar_type(), \"softsign_cuda_launch\", ([&] {\n        softsign_kernel<scalar_t><<<blocks, threads>>>(\n            x.data_ptr<scalar_t>(),\n            out.data_ptr<scalar_t>(),\n            N);\n    }));\n\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        TORCH_CHECK(false, \"softsign_kernel launch failed with error: \", cudaGetErrorString(err));\n    }\n    return out;\n}\n'''\n\ncpp_src = r'''\ntorch::Tensor softsign_cuda(torch::Tensor x);\n'''\n\nsoftsign = load_inline(\n    name         = 'softsign',\n    cpp_sources  = cpp_src,\n    cuda_sources = source,\n    functions    = ['softsign_cuda'],\n    with_cuda    = True,\n    verbose      = True,\n    extra_cuda_cflags=['-O2', '--ptxas-options=-v'],\n    extra_cflags=['-O2'],\n)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.softmax_mod = softsign\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.softmax_mod.softsign_cuda(x)"
  }
]