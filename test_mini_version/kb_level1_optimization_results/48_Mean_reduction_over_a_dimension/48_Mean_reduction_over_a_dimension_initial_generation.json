[
  {
    "attempt": 0,
    "type": "generation",
    "response": "```cpp\n#include <torch/extension.h>\n#include <vector> // 如果返回多个张量\n\n// C++ Wrapper 函数声明 (签名)\ntorch::Tensor kb_48_Mean_reduction_over_a_dimension_wrapper(torch::Tensor arg0, int64_t arg1);\n```\n\n```cu\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n#include <cmath>\n#include <vector>\n#include <stdexcept>\n// PyTorch 2.1+ 移除了 c10::cuda::getCurrentCUDAStream\n// 使用 at::cuda::getCurrentCUDAStream() 代替\n#include <ATen/cuda/CUDAContext.h>\n\n// [重要] CUDA 辅助函数需在 kernel 之前定义\n\n// 线程块内求和归约，返回整个 block 的和\n// 需要调用方提供共享内存数组 shared，长度至少为 (blockDim.x / warpSize)\n__device__ float blockReduceSum(float val, float* shared) {\n    int lane = threadIdx.x % warpSize;\n    int wid  = threadIdx.x / warpSize;\n\n    // Warp 内归约\n    for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n        val += __shfl_down_sync(0xFFFFFFFF, val, offset);\n    }\n\n    // 每个 warp 的 lane 0 写入共享内存\n    if (lane == 0) {\n        shared[wid] = val;\n    }\n    __syncthreads();\n\n    // 仅第一个 warp 进行最终归约\n    float out = 0.0f;\n    if (wid == 0) {\n        // 前 num_warps 个线程各自读取一个部分和\n        int num_warps = blockDim.x / warpSize;\n        out = (lane < num_warps) ? shared[lane] : 0.0f;\n        // 再进行一次 warp 级归约\n        for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n            out += __shfl_down_sync(0xFFFFFFFF, out, offset);\n        }\n    }\n    return out;\n}\n\n// 将任意维度的归约映射为 (outer, reduce, inner) 的三维布局，\n// 对中间维度 reduce 做均值归约。\n// 输入必须为连续内存布局。\n__global__ void mean_reduce_dim_kernel(\n    const float* __restrict__ x,\n    float* __restrict__ y,\n    long long outer,\n    long long reduce,\n    long long inner\n) {\n    long long out_idx = static_cast<long long>(blockIdx.x);\n    if (out_idx >= outer * inner) return;\n\n    long long outer_idx = (inner == 0) ? 0 : (out_idx / inner);\n    long long inner_idx = (inner == 0) ? 0 : (out_idx % inner);\n\n    float thread_sum = 0.0f;\n\n    // 分段遍历 reduce 维度\n    for (long long r = threadIdx.x; r < reduce; r += blockDim.x) {\n        long long in_index = ((outer_idx * reduce) + r) * inner + inner_idx;\n        thread_sum += x[in_index];\n    }\n\n    extern __shared__ float smem[];\n    float block_sum = blockReduceSum(thread_sum, smem);\n\n    if (threadIdx.x == 0) {\n        y[out_idx] = block_sum / static_cast<float>(reduce);\n    }\n}\n\n// C++ Wrapper 实现\ntorch::Tensor kb_48_Mean_reduction_over_a_dimension_wrapper(torch::Tensor arg0, int64_t arg1) {\n    TORCH_CHECK(arg0.is_cuda(), \"Input tensor must be on CUDA device\");\n    TORCH_CHECK(arg0.dtype() == torch::kFloat32, \"Only float32 tensors are supported\");\n    TORCH_CHECK(arg0.numel() > 0, \"Input tensor must have at least one element\");\n\n    auto x = arg0.contiguous();\n    auto sizes = x.sizes();\n    int64_t ndim = static_cast<int64_t>(sizes.size());\n    TORCH_CHECK(ndim >= 1, \"Input tensor must have at least 1 dimension\");\n\n    int64_t dim = arg1;\n    if (dim < 0) dim += ndim;\n    TORCH_CHECK(dim >= 0 && dim < ndim, \"Reduction dim is out of range\");\n\n    // 计算 outer, reduce, inner\n    long long outer = 1;\n    for (int64_t i = 0; i < dim; ++i) outer *= static_cast<long long>(sizes[i]);\n    long long reduce = static_cast<long long>(sizes[dim]);\n    long long inner = 1;\n    for (int64_t i = dim + 1; i < ndim; ++i) inner *= static_cast<long long>(sizes[i]);\n\n    TORCH_CHECK(reduce > 0, \"Reduction size must be > 0\");\n\n    // 输出形状：移除 dim\n    std::vector<int64_t> out_sizes;\n    out_sizes.reserve(ndim - 1);\n    for (int64_t i = 0; i < ndim; ++i) {\n        if (i == dim) continue;\n        out_sizes.push_back(sizes[i]);\n    }\n\n    auto options = x.options();\n    auto y = torch::empty(out_sizes, options);\n\n    // 计算 launch 配置\n    const int threads = 256; // 必须为 32 的倍数以匹配 blockReduceSum 实现\n    long long blocks_ll = outer * inner;\n    TORCH_CHECK(blocks_ll <= static_cast<long long>(std::numeric_limits<int>::max()),\n                \"Number of output elements is too large for grid.x\");\n    dim3 grid(static_cast<unsigned int>(blocks_ll));\n    dim3 block(threads);\n    size_t shmem_bytes = (threads / 32) * sizeof(float); // 每个 warp 一个 float\n\n    auto stream = at::cuda::getCurrentCUDAStream();\n\n    mean_reduce_dim_kernel<<<grid, block, shmem_bytes, stream.stream()>>>(\n        x.data_ptr<float>(),\n        y.data_ptr<float>(),\n        outer,\n        reduce,\n        inner\n    );\n\n    // 可选：检查内核错误\n    C10_CUDA_KERNEL_LAUNCH_CHECK();\n\n    return y;\n}\n```",
    "cpp_code_extracted": true,
    "cuda_code_extracted": true,
    "error": ""
  }
]