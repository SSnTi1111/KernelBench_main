[
  {
    "attempt": 0,
    "type": "generation",
    "response_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# ------------------------------------------------------------------------------\n# CUDA source\n# ------------------------------------------------------------------------------\nsource = r'''\n#include <torch/extension.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\n/////////////////////////////////////////////////////////////////\n// Sigmoid kernel\n/////////////////////////////////////////////////////////////////\ntemplate <typename scalar_t>\n__global__ void sigmoid_forward_kernel(const scalar_t* __restrict__ x,\n                                       scalar_t* __restrict__ y,\n                                       const int64_t numel)\n{\n    // Grid-stride loop so the kernel works for any tensor size\n    for (int64_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n         idx < numel;\n         idx += blockDim.x * gridDim.x)\n    {\n        if (idx < numel) {           // Boundary guard (redundant but safe)\n            const scalar_t val = x[idx];\n            y[idx] = static_cast<scalar_t>(1) /\n                     (static_cast<scalar_t>(1) + exp(-val));\n        }\n    }\n}\n\n/////////////////////////////////////////////////////////////////\n// Host wrapper\n/////////////////////////////////////////////////////////////////\ntorch::Tensor sigmoid_cuda(torch::Tensor input)\n{\n    TORCH_CHECK(input.is_cuda(), \"Input must be a CUDA tensor\");\n    TORCH_CHECK(input.dtype() == torch::kFloat32,\n                \"Only float32 tensors are supported\");\n    TORCH_CHECK(input.is_contiguous(), \"Input must be contiguous\");\n\n    auto output = torch::empty_like(input);\n\n    const int64_t numel = input.numel();\n    if (numel == 0) return output;\n\n    const int threads = 256;\n    const int blocks  = (numel + threads - 1) / threads;\n\n    // Launch kernel\n    sigmoid_forward_kernel<float><<<blocks, threads, 0>>>(\n        input.data_ptr<float>(),\n        output.data_ptr<float>(),\n        numel);\n\n    // Check for launch errors\n    cudaError_t err = cudaGetLastError();\n    TORCH_CHECK(err == cudaSuccess, \"sigmoid_cuda kernel launch failed : \",\n                cudaGetErrorString(err));\n\n    return output;\n}\n'''\n\n# ------------------------------------------------------------------------------\n# C++ prototypes exposed to Python\n# ------------------------------------------------------------------------------\ncpp_src = r'''\ntorch::Tensor sigmoid_cuda(torch::Tensor input);\n'''\n\n# ------------------------------------------------------------------------------\n# Compile & load\n# ------------------------------------------------------------------------------\nsigmoid_extension = load_inline(\n    name         = 'sigmoid_extension',\n    cpp_sources  = cpp_src,\n    cuda_sources = source,\n    functions    = ['sigmoid_cuda'],\n    with_cuda    = True,\n    verbose      = True,\n    extra_cuda_cflags=['-O3', '--use_fast_math', '--ptxas-options=-v'],\n)\n\n# ------------------------------------------------------------------------------\n# nn.Module that calls the custom CUDA kernel\n# ------------------------------------------------------------------------------\nclass ModelNew(nn.Module):\n    \"\"\"\n    Mirrors the original Model but utilizes a custom CUDA sigmoid kernel.\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Ensure input is contiguous for the kernel\n        if not x.is_contiguous():\n            x = x.contiguous()\n        return sigmoid_extension.sigmoid_cuda(x)"
  }
]