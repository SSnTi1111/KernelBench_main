[
  {
    "attempt": 0,
    "type": "generation",
    "response_cuda_code": "import math\nimport torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# ----------------------------------------------------------------------\n# CUDA / C++ source\n# ----------------------------------------------------------------------\nsource = r'''\n#include <torch/extension.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\n#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x \" must be a CUDA tensor\")\n#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\n///////////////////////////////////////////////////////////////////\n// Kernel : one thread computes one output element (n, oc, od, oh, ow)\n///////////////////////////////////////////////////////////////////\n__global__ void conv3d_forward_kernel(\n        const float *__restrict__ input,      // [N, C, D, H, W]\n        const float *__restrict__ weight,     // [OC, Cg, kD, kH, kW]\n        const float *__restrict__ bias,       // [OC]  (can be empty)\n        float *__restrict__ output,           // [N, OC, Od, Oh, Ow]\n        int N, int C, int D, int H, int W,\n        int OC, int kD, int kH, int kW,\n        int stride_d, int stride_h, int stride_w,\n        int pad_d, int pad_h, int pad_w,\n        int dil_d, int dil_h, int dil_w,\n        int groups,\n        int outD, int outH, int outW,\n        int bias_flag) {\n\n    long long idx = blockIdx.x * blockDim.x + threadIdx.x;\n    long long total = (long long)N * OC * outD * outH * outW;\n    if (idx >= total) return;\n\n    // Decompose linear index -> coordinates\n    int ow = idx % outW;\n    idx /= outW;\n    int oh = idx % outH;\n    idx /= outH;\n    int od = idx % outD;\n    idx /= outD;\n    int oc = idx % OC;\n    int n  = idx / OC;\n\n    int channels_per_group = C / groups;\n    int group_id = oc / (OC / groups);\n    int ic_start = group_id * channels_per_group;\n    int ic_end   = ic_start + channels_per_group;\n\n    // Initialize accumulator with bias (if any)\n    float val = bias_flag ? bias[oc] : 0.0f;\n\n    // Iterate over kernel volume\n    for (int kd = 0; kd < kD; ++kd) {\n        int in_d = od * stride_d - pad_d + kd * dil_d;\n        if (in_d < 0 || in_d >= D) continue;\n\n        for (int kh = 0; kh < kH; ++kh) {\n            int in_h = oh * stride_h - pad_h + kh * dil_h;\n            if (in_h < 0 || in_h >= H) continue;\n\n            for (int kw = 0; kw < kW; ++kw) {\n                int in_w = ow * stride_w - pad_w + kw * dil_w;\n                if (in_w < 0 || in_w >= W) continue;\n\n                // Pointer offset helpers\n                long long input_base  = (((long long)n * C * D + ic_start * D + 0LL) * H + 0LL) * W; // n, ic_start, d=0, h=0, w=0\n                long long weight_base = (((long long)oc * channels_per_group) * kD + kd) * kH * kW;  // oc, ic=0 will be added later\n\n                for (int ic = ic_start; ic < ic_end; ++ic) {\n                    int w_ic = ic - ic_start;\n\n                    long long inp_idx = input_base\n                        + ((long long)ic - ic_start) * D * H * W     // step through channel\n                        + (long long)in_d * H * W\n                        + (long long)in_h * W\n                        + in_w;\n\n                    long long w_idx  = weight_base\n                        + ((long long)w_ic) * kD * kH * kW\n                        + (long long)kh * kW\n                        + kw;\n\n                    val += input[inp_idx] * weight[w_idx];\n                }\n            }\n        }\n    }\n\n    // Store result\n    long long out_idx = (((long long)n * OC + oc) * outD + od) * outH * outW\n                        + (long long)oh * outW + ow;\n    output[out_idx] = val;\n}\n\n///////////////////////////////////////////////////////////////////\n// Host launcher\n///////////////////////////////////////////////////////////////////\ntorch::Tensor conv3d_forward(torch::Tensor input,\n                             torch::Tensor weight,\n                             torch::Tensor bias,        // can be empty tensor\n                             int stride_d, int stride_h, int stride_w,\n                             int pad_d, int pad_h, int pad_w,\n                             int dil_d, int dil_h, int dil_w,\n                             int groups,\n                             bool bias_flag) {\n\n    // ----------------- argument checks -----------------\n    CHECK_INPUT(input);\n    CHECK_INPUT(weight);\n    if (bias_flag) {\n        CHECK_INPUT(bias);\n        TORCH_CHECK(bias.numel() == weight.size(0), \"bias shape mismatch\");\n    }\n\n    TORCH_CHECK(input.dim()  == 5, \"input should be NDHWC with 5 dims (N,C,D,H,W)\");\n    TORCH_CHECK(weight.dim() == 5, \"weight should be (OC,C_per_group,kD,kH,kW)\");\n    int64_t N  = input.size(0);\n    int64_t C  = input.size(1);\n    int64_t D  = input.size(2);\n    int64_t H  = input.size(3);\n    int64_t W  = input.size(4);\n\n    int64_t OC = weight.size(0);\n    int64_t kD = weight.size(2);\n    int64_t kH = weight.size(3);\n    int64_t kW = weight.size(4);\n\n    TORCH_CHECK(C % groups == 0, \"C must be divisible by groups\");\n    TORCH_CHECK(OC % groups == 0, \"OC must be divisible by groups\");\n\n    // Compute output sizes following PyTorch formula\n    auto outD = (D + 2 * pad_d - dil_d * (kD - 1) - 1) / stride_d + 1;\n    auto outH = (H + 2 * pad_h - dil_h * (kH - 1) - 1) / stride_h + 1;\n    auto outW = (W + 2 * pad_w - dil_w * (kW - 1) - 1) / stride_w + 1;\n\n    TORCH_CHECK(outD > 0 && outH > 0 && outW > 0, \"Output size is <= 0\");\n\n    auto output = torch::zeros({N, OC, outD, outH, outW}, input.options());\n\n    // Grid / block\n    long long total = (long long)N * OC * outD * outH * outW;\n    const int threads = 256;\n    const int blocks  = (total + threads - 1) / threads;\n\n    conv3d_forward_kernel<<<blocks, threads>>>(\n        input.data_ptr<float>(),\n        weight.data_ptr<float>(),\n        bias_flag ? bias.data_ptr<float>() : nullptr,\n        output.data_ptr<float>(),\n        (int)N, (int)C, (int)D, (int)H, (int)W,\n        (int)OC, (int)kD, (int)kH, (int)kW,\n        stride_d, stride_h, stride_w,\n        pad_d, pad_h, pad_w,\n        dil_d, dil_h, dil_w,\n        groups,\n        (int)outD, (int)outH, (int)outW,\n        bias_flag ? 1 : 0\n    );\n    cudaError_t err = cudaGetLastError();\n    TORCH_CHECK(err == cudaSuccess, \"conv3d_forward_kernel launch failed with error: \", cudaGetErrorString(err));\n\n    return output;\n}\n'''\n\ncpp_src = r'''\ntorch::Tensor conv3d_forward(torch::Tensor input,\n                             torch::Tensor weight,\n                             torch::Tensor bias,\n                             int stride_d, int stride_h, int stride_w,\n                             int pad_d, int pad_h, int pad_w,\n                             int dil_d, int dil_h, int dil_w,\n                             int groups,\n                             bool bias_flag);\n'''\n\n# ----------------------------------------------------------------------\n# Inline load\n# ----------------------------------------------------------------------\nconv3d_cuda = load_inline(\n    name='conv3d_cuda',\n    cpp_sources=cpp_src,\n    cuda_sources=source,\n    functions=['conv3d_forward'],\n    with_cuda=True,\n    verbose=True,\n    extra_cuda_cflags=['-O3', '--ptxas-options=-v'],\n)\n\n# ----------------------------------------------------------------------\n# Python module that uses the CUDA kernel\n# ----------------------------------------------------------------------\nclass ModelNew(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel_size: int,\n                 stride: int = 1,\n                 padding: int = 0,\n                 dilation: int = 1,\n                 groups: int = 1,\n                 bias: bool = False) -> None:\n        super().__init__()\n\n        # handle tuple / int inputs\n        def _triple(v):\n            if isinstance(v, int):\n                return (v, v, v)\n            return tuple(v)\n        self.kernel_size = _triple(kernel_size)\n        self.stride      = _triple(stride)\n        self.padding     = _triple(padding)\n        self.dilation    = _triple(dilation)\n\n        self.in_channels  = in_channels\n        self.out_channels = out_channels\n        self.groups       = groups\n\n        # parameters\n        kD, kH, kW = self.kernel_size\n        self.weight = nn.Parameter(\n            torch.empty(out_channels, in_channels // groups, kD, kH, kW)\n        )\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n\n        # initialization (same as nn.Conv3d default)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if bias:\n            fan_in = in_channels * kD * kH * kW // groups\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Ensure contiguous tensors\n        x_in   = x.contiguous()\n        weight = self.weight.contiguous()\n        bias   = self.bias.contiguous() if self.bias is not None else torch.empty(0, device=x.device)\n\n        out = conv3d_cuda.conv3d_forward(\n            x_in,\n            weight,\n            bias,\n            *self.stride,\n            *self.padding,\n            *self.dilation,\n            self.groups,\n            self.bias is not None\n        )\n        return out"
  }
]