[
  {
    "attempt": 0,
    "type": "generation",
    "response": "```cpp\n#include <torch/extension.h>\n\n// C++ Wrapper 函数声明 (签名)\ntorch::Tensor kb_1_45_Average_Pooling_2D_wrapper(torch::Tensor arg0, int64_t arg1);\n```\n\n```cu\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n#include <cmath>\n#include <vector>\n#include <cstdint>\n// PyTorch 2.1+ 移除了 c10::cuda::getCurrentCUDAStream\n// 使用 at::cuda::getCurrentCUDAStream() 代替\n#include <ATen/cuda/CUDAContext.h>\n\n// 可选的归约辅助函数（本实现未使用，示例留存）\n__device__ float blockReduceSum(float val, float* shared) {\n    int lane = threadIdx.x % warpSize;\n    int wid = threadIdx.x / warpSize;\n\n    for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n        val += __shfl_down_sync(0xFFFFFFFF, val, offset);\n    }\n\n    if (lane == 0) {\n        shared[wid] = val;\n    }\n    __syncthreads();\n\n    val = (threadIdx.x < blockDim.x / warpSize) ? shared[lane] : 0.0f;\n    if (wid == 0) {\n        for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n            val += __shfl_down_sync(0xFFFFFFFF, val, offset);\n        }\n    }\n    return val;\n}\n\n// CUDA 内核实现: 2D Average Pooling (NCHW, padding=0, stride=kernel_size)\n__global__ void avg_pool2d_kernel(\n    const float* __restrict__ input,\n    float* __restrict__ output,\n    int64_t N, int64_t C, int64_t H, int64_t W,\n    int64_t outH, int64_t outW,\n    int64_t k, int64_t stride_\n) {\n    int64_t total = N * C * outH * outW;\n    int64_t tid = static_cast<int64_t>(blockIdx.x) * blockDim.x + threadIdx.x;\n    int64_t gridStride = static_cast<int64_t>(blockDim.x) * gridDim.x;\n\n    float invArea = 1.0f / static_cast<float>(k * k);\n\n    for (int64_t idx = tid; idx < total; idx += gridStride) {\n        int64_t ow = idx % outW;\n        int64_t tmp = idx / outW;\n        int64_t oh = tmp % outH;\n        tmp /= outH;\n        int64_t c  = tmp % C;\n        int64_t n  = tmp / C;\n\n        int64_t ih0 = oh * stride_;\n        int64_t iw0 = ow * stride_;\n\n        int64_t nc_base = ((n * C + c) * H) * W;\n\n        float sum = 0.0f;\n        for (int64_t ky = 0; ky < k; ++ky) {\n            int64_t ih = ih0 + ky; // padding=0，已保证有效范围\n            int64_t row_base = nc_base + ih * W;\n            for (int64_t kx = 0; kx < k; ++kx) {\n                int64_t iw = iw0 + kx;\n                sum += input[row_base + iw];\n            }\n        }\n        output[idx] = sum * invArea;\n    }\n}\n\n// C++ Wrapper 实现\ntorch::Tensor kb_1_45_Average_Pooling_2D_wrapper(torch::Tensor arg0, int64_t arg1) {\n    TORCH_CHECK(arg0.is_cuda(), \"arg0 must be a CUDA tensor\");\n    TORCH_CHECK(arg0.dtype() == torch::kFloat32, \"arg0 must be float32\");\n    TORCH_CHECK(arg0.dim() == 4, \"arg0 must be a 4D tensor [N, C, H, W]\");\n    TORCH_CHECK(arg1 > 0, \"kernel_size (arg1) must be > 0\");\n\n    auto input = arg0.contiguous();\n\n    int64_t N = input.size(0);\n    int64_t C = input.size(1);\n    int64_t H = input.size(2);\n    int64_t W = input.size(3);\n\n    int64_t k = arg1;\n    int64_t stride = k;   // 与 PyTorch 默认一致：stride=None -> stride=kernel_size\n    int64_t padding = 0;  // 问题规格中为 0\n\n    TORCH_CHECK(H >= k && W >= k, \"kernel_size must be <= input height/width\");\n    // 输出尺寸: floor((H + 2*padding - k)/stride) + 1\n    int64_t outH = (H + 2 * padding - k) / stride + 1;\n    int64_t outW = (W + 2 * padding - k) / stride + 1;\n    TORCH_CHECK(outH > 0 && outW > 0, \"Invalid output size computed\");\n\n    auto options = input.options();\n    torch::Tensor output = torch::empty({N, C, outH, outW}, options);\n\n    int threads = 256;\n    int64_t total = N * C * outH * outW;\n    int blocks = static_cast<int>((total + threads - 1) / threads);\n    blocks = std::max(1, blocks);\n\n    cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n\n    avg_pool2d_kernel<<<blocks, threads, 0, stream>>>(\n        input.data_ptr<float>(),\n        output.data_ptr<float>(),\n        N, C, H, W,\n        outH, outW,\n        k, stride\n    );\n\n    return output;\n}\n```",
    "cpp_code_extracted": true,
    "cuda_code_extracted": true,
    "error": ""
  }
]