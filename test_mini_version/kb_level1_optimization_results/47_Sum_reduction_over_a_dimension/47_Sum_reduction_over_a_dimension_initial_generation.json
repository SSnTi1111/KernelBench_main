[
  {
    "attempt": 0,
    "type": "generation",
    "response": "```cpp\n#include <torch/extension.h>\n\n// C++ Wrapper 函数声明 (签名)\ntorch::Tensor kb_47_Sum_reduction_over_a_dimension_wrapper(torch::Tensor arg0, int64_t arg1);\n```\n\n```cu\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n#include <cmath>\n#include <vector>\n#include <ATen/cuda/CUDAContext.h>\n\n// CUDA 辅助函数：块级求和归约（使用 warp shuffle）\n__device__ float blockReduceSum(float val, float* shared) {\n    int lane = threadIdx.x % warpSize;\n    int wid = threadIdx.x / warpSize;\n\n    // Warp 内归约\n    for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n        val += __shfl_down_sync(0xFFFFFFFF, val, offset);\n    }\n\n    // 每个 warp 的 lane==0 写入共享内存\n    if (lane == 0) {\n        shared[wid] = val;\n    }\n    __syncthreads();\n\n    // 使用第一个 warp 进行最终归约\n    val = (threadIdx.x < (blockDim.x / warpSize)) ? shared[lane] : 0.0f;\n    if (wid == 0) {\n        for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n            val += __shfl_down_sync(0xFFFFFFFF, val, offset);\n        }\n    }\n    return val;\n}\n\n// CUDA 内核：对指定维度进行求和归约（keepdim=True）\n// 输入按 contiguous 展平视为 [outer, reduce, inner]\n__global__ void sum_reduce_dim_kernel(\n    const float* __restrict__ x,\n    float* __restrict__ out,\n    int64_t outer_n,\n    int64_t reduce_n,\n    int64_t inner_n\n) {\n    int64_t o = blockIdx.y;\n    int64_t i = blockIdx.x;\n\n    int tid = threadIdx.x;\n    int stride = blockDim.x;\n\n    // 每个 block 负责一个 (o, i) 输出位置\n    int64_t base = o * reduce_n * inner_n + i;\n\n    float thread_sum = 0.0f;\n    for (int64_t r = tid; r < reduce_n; r += stride) {\n        thread_sum += x[base + r * inner_n];\n    }\n\n    __shared__ float shared[32]; // 最多支持 32 个 warp\n    float total = blockReduceSum(thread_sum, shared);\n\n    if (threadIdx.x == 0) {\n        // 输出也按 [outer, 1, inner] 的连续布局\n        out[o * inner_n + i] = total;\n    }\n}\n\n// C++ Wrapper 实现\ntorch::Tensor kb_47_Sum_reduction_over_a_dimension_wrapper(torch::Tensor arg0, int64_t arg1) {\n    TORCH_CHECK(arg0.is_cuda(), \"arg0 must be a CUDA tensor\");\n    TORCH_CHECK(arg0.dtype() == torch::kFloat32, \"Only float32 dtype is supported\");\n    TORCH_CHECK(arg0.is_contiguous(), \"arg0 must be contiguous for this kernel\");\n\n    auto x = arg0.contiguous();\n    int64_t ndim = x.dim();\n    TORCH_CHECK(ndim >= 1, \"Input must have at least 1 dimension\");\n\n    int64_t dim = arg1;\n    if (dim < 0) dim += ndim;\n    TORCH_CHECK(dim >= 0 && dim < ndim, \"Reduction dim out of range\");\n\n    auto sizes = x.sizes();\n\n    // 计算 outer, reduce, inner\n    int64_t outer_n = 1;\n    for (int64_t d = 0; d < dim; ++d) outer_n *= sizes[d];\n    int64_t reduce_n = sizes[dim];\n    int64_t inner_n = 1;\n    for (int64_t d = dim + 1; d < ndim; ++d) inner_n *= sizes[d];\n\n    // 输出形状：keepdim=True\n    std::vector<int64_t> out_sizes(sizes.begin(), sizes.end());\n    out_sizes[dim] = 1;\n    auto out = torch::empty(out_sizes, x.options());\n\n    // 处理 reduce_n == 0 的情况：结果为 0\n    if (reduce_n == 0 || outer_n == 0 || inner_n == 0) {\n        out.zero_();\n        return out;\n    }\n\n    // 按我们内核的布局，输出视为 [outer, 1, inner] 的连续张量。\n    // 由于 PyTorch empty 默认是 contiguous，且我们直接按线性写入，这样即可。\n    // 网格/块设置\n    int threads = 256;\n    dim3 grid((unsigned int)inner_n, (unsigned int)outer_n);\n    cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n\n    sum_reduce_dim_kernel<<<grid, threads, 0, stream>>>(\n        x.data_ptr<float>(),\n        out.data_ptr<float>(),\n        outer_n,\n        reduce_n,\n        inner_n\n    );\n\n    // 可选：错误检查\n    // TORCH_CHECK(cudaGetLastError() == cudaSuccess, \"Kernel launch failed\");\n\n    return out;\n}\n```",
    "cpp_code_extracted": true,
    "cuda_code_extracted": true,
    "error": ""
  }
]