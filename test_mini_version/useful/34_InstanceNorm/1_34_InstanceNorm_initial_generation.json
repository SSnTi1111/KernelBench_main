[
  {
    "attempt": 0,
    "type": "generation",
    "response": "```cpp\n#include <torch/extension.h>\n\n// C++ Wrapper 函数声明 (签名)\ntorch::Tensor kb_1_34_InstanceNorm_wrapper(torch::Tensor arg0);\n```\n\n```cu\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n#include <cmath>\n#include <vector>\n#include <ATen/cuda/CUDAContext.h>\n\n// 设备端块归约：对一个block内的float值求和\n// 需要调用方提供 shared 指针，大小至少为 blockDim.x / warpSize\n__device__ float blockReduceSum(float val, float* shared) {\n    int lane = threadIdx.x % warpSize;\n    int wid  = threadIdx.x / warpSize;\n\n    // warp 内归约\n    for (int offset = warpSize >> 1; offset > 0; offset >>= 1) {\n        val += __shfl_down_sync(0xFFFFFFFFu, val, offset);\n    }\n\n    // 每个 warp 的 lane 0 写到共享内存\n    if (lane == 0) {\n        shared[wid] = val;\n    }\n    __syncthreads();\n\n    // 仅第一个 warp 进行最终归约\n    val = (threadIdx.x < blockDim.x / warpSize) ? shared[lane] : 0.0f;\n    if (wid == 0) {\n        for (int offset = warpSize >> 1; offset > 0; offset >>= 1) {\n            val += __shfl_down_sync(0xFFFFFFFFu, val, offset);\n        }\n    }\n    return val;\n}\n\n// InstanceNorm2d 内核：对每个 (n, c) 平面做归一化\n// 输入输出均为 NCHW, float32\n__global__ void instance_norm2d_kernel(\n    const float* __restrict__ x,\n    float* __restrict__ y,\n    int N, int C, int H, int W,\n    float eps\n) {\n    int nc = blockIdx.x;  // 0..N*C-1\n    int n = nc / C;\n    int c = nc % C;\n\n    const int HW = H * W;\n    const long long plane_size = static_cast<long long>(HW);\n    const long long base = (static_cast<long long>(n) * C + c) * plane_size;\n\n    extern __shared__ float s_red[]; // size = num_warps\n    __shared__ float s_mean;\n    __shared__ float s_invstd;\n\n    // 第一次遍历：计算 sum 和 sumsq\n    float sum = 0.0f;\n    float sumsq = 0.0f;\n\n    for (int idx = threadIdx.x; idx < HW; idx += blockDim.x) {\n        float v = x[base + idx];\n        sum   += v;\n        sumsq += v * v;\n    }\n\n    float red_sum   = blockReduceSum(sum, s_red);\n    float red_sumsq = blockReduceSum(sumsq, s_red);\n\n    if (threadIdx.x == 0) {\n        float mean = red_sum / static_cast<float>(HW);\n        float var  = red_sumsq / static_cast<float>(HW) - mean * mean;\n        s_mean   = mean;\n        s_invstd = rsqrtf(var + eps);\n    }\n    __syncthreads();\n\n    float mean = s_mean;\n    float invstd = s_invstd;\n\n    // 第二次遍历：写出归一化结果（无仿射参数）\n    for (int idx = threadIdx.x; idx < HW; idx += blockDim.x) {\n        float v = x[base + idx];\n        y[base + idx] = (v - mean) * invstd;\n    }\n}\n\n// C++ Wrapper 实现\ntorch::Tensor kb_1_34_InstanceNorm_wrapper(torch::Tensor arg0) {\n    TORCH_CHECK(arg0.is_cuda(), \"arg0 must be a CUDA tensor\");\n    TORCH_CHECK(arg0.scalar_type() == at::kFloat, \"arg0 must be float32\");\n    TORCH_CHECK(arg0.dim() == 4, \"Expected 4D tensor in NCHW layout\");\n\n    auto x = arg0.contiguous();\n\n    const int64_t N64 = x.size(0);\n    const int64_t C64 = x.size(1);\n    const int64_t H64 = x.size(2);\n    const int64_t W64 = x.size(3);\n\n    TORCH_CHECK(N64 > 0 && C64 > 0 && H64 > 0 && W64 > 0, \"Invalid tensor sizes\");\n\n    // 转为 int（这些维度通常小于 2^31）\n    int N = static_cast<int>(N64);\n    int C = static_cast<int>(C64);\n    int H = static_cast<int>(H64);\n    int W = static_cast<int>(W64);\n\n    auto y = torch::empty_like(x);\n\n    const int blocks = N * C;\n    const int threads = 256; // 8 warps\n    const size_t shmem_bytes = (threads / 32) * sizeof(float); // 每个warp一个槽位\n\n    cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n\n    const float eps = 1e-5f; // 与 PyTorch 默认一致\n\n    instance_norm2d_kernel<<<blocks, threads, shmem_bytes, stream>>>(\n        x.data_ptr<float>(),\n        y.data_ptr<float>(),\n        N, C, H, W,\n        eps\n    );\n\n    cudaError_t err = cudaGetLastError();\n    TORCH_CHECK(err == cudaSuccess, \"CUDA kernel launch failed: \", cudaGetErrorString(err));\n\n    return y;\n}\n```",
    "cpp_code_extracted": true,
    "cuda_code_extracted": true,
    "error": ""
  }
]