[
  {
    "attempt": 0,
    "type": "generation",
    "response": "--- C++ 签名 (`cpp`) ---\n```cpp\n#include <torch/extension.h>\n\n// C++ Wrapper 函数声明 (签名)\ntorch::Tensor kb_91_cumsum_reverse_wrapper(torch::Tensor arg0, int64_t arg1);\n```\n\n\n--- C++/CUDA 组合实现 (`cu`) ---\n```cu\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n#include <cmath>\n#include <vector>\n#include <ATen/cuda/CUDAContext.h>\n\n// ============================================================================\n// 简单 2-D 反向 cumulative-sum CUDA 实现\n//   • 输入:  float32, 2-D, contiguous\n//   • dim = 0 ⇒ 沿着行方向(下→上)反向累计\n//   • dim = 1 ⇒ 沿着列方向(右→左)反向累计\n//   • 其他 dim 会在 wrapper 中报错\n// ============================================================================\n\n// ---------------------------------------------------------------------------\n// kernel-dim1 : 对每一行做反向累加 (从最后一列扫到第一列)\n// ---------------------------------------------------------------------------\n__global__ void reverse_cumsum_dim1_kernel(\n        const float* __restrict__ in,\n        float*       __restrict__ out,\n        int rows,\n        int cols)\n{\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row >= rows) return;\n\n    // 从最右侧开始累加\n    float acc = 0.f;\n    int base = row * cols;\n#pragma unroll 4\n    for (int c = cols - 1; c >= 0; --c) {\n        int idx = base + c;\n        acc += in[idx];\n        out[idx] = acc;\n    }\n}\n\n// ---------------------------------------------------------------------------\n// kernel-dim0 : 对每一列做反向累加 (从最后一行扫到第一行)\n// ---------------------------------------------------------------------------\n__global__ void reverse_cumsum_dim0_kernel(\n        const float* __restrict__ in,\n        float*       __restrict__ out,\n        int rows,\n        int cols)\n{\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (col >= cols) return;\n\n    float acc = 0.f;\n#pragma unroll 4\n    for (int r = rows - 1; r >= 0; --r) {\n        int idx = r * cols + col;\n        acc += in[idx];\n        out[idx] = acc;\n    }\n}\n\n// ---------------------------------------------------------------------------\n// C++ Wrapper\n// ---------------------------------------------------------------------------\ntorch::Tensor kb_91_cumsum_reverse_wrapper(torch::Tensor arg0, int64_t arg1)\n{\n    TORCH_CHECK(arg0.is_cuda(), \"Input tensor must be on CUDA device\");\n    TORCH_CHECK(arg0.scalar_type() == at::kFloat,\n                \"Only float32 tensors are supported\");\n    TORCH_CHECK(arg0.dim() == 2,\n                \"This reference implementation only supports 2-D tensors\");\n\n    // 处理 dim 为负数的情况\n    int64_t dim = arg1;\n    if (dim < 0) dim += arg0.dim();\n    TORCH_CHECK(dim == 0 || dim == 1,\n                \"dim must be 0 or 1 for 2-D tensor\");\n\n    // 保证连续性\n    if (!arg0.is_contiguous()) {\n        arg0 = arg0.contiguous();\n    }\n\n    // 输出张量\n    auto out = at::empty_like(arg0);\n\n    const int rows = static_cast<int>(arg0.size(0));\n    const int cols = static_cast<int>(arg0.size(1));\n\n    const int threads = 256;\n    dim3 blocks;\n\n    // 调用对应 kernel\n    const float* in_ptr  = arg0.data_ptr<float>();\n    float*       out_ptr = out.data_ptr<float>();\n\n    if (dim == 1) {\n        blocks = dim3((rows + threads - 1) / threads);\n        reverse_cumsum_dim1_kernel<<<blocks, threads, 0,\n            at::cuda::getCurrentCUDAStream()>>>(\n                in_ptr, out_ptr, rows, cols);\n    } else { // dim == 0\n        blocks = dim3((cols + threads - 1) / threads);\n        reverse_cumsum_dim0_kernel<<<blocks, threads, 0,\n            at::cuda::getCurrentCUDAStream()>>>(\n                in_ptr, out_ptr, rows, cols);\n    }\n\n    // CUDA 错误检查（调试用）\n#ifndef NDEBUG\n    cudaError_t err = cudaGetLastError();\n    TORCH_CHECK(err == cudaSuccess, \"CUDA kernel failed : \",\n                cudaGetErrorString(err));\n#endif\n\n    return out;\n}\n```",
    "cpp_code_extracted": true,
    "cuda_code_extracted": true,
    "error": ""
  }
]