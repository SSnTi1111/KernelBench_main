import os
import sys
import json
import time
import argparse
import torch
import traceback
import re
import signal
import gc

# [!!! è·¯å¾„é…ç½® - è¯·æ ¹æ®ä½ çš„ç¯å¢ƒä¿®æ”¹ !!!]
# æŒ‡å‘ä½ çš„ KernelBench_main ç›®å½•
KERNELBENCH_MAIN_PATH = "/home/lxt/KernelBench/KernelBench_main"
# æŒ‡å‘ä½ çš„ QiMeng-xpiler-eval ç›®å½•
XPILER_EVAL_PATH = "/home/lxt/QiMeng-xpiler-eval/QiMeng-xpiler-eval"

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥ mini_version æ¨¡å—
MINI_VERSION_PATH = os.path.join(KERNELBENCH_MAIN_PATH, "mini_version")
if MINI_VERSION_PATH not in sys.path:
    sys.path.append(MINI_VERSION_PATH)

# å¯¼å…¥ mini_version æ¨¡å—
try:
    import config as mv_config
    import llm_api as mv_llm_api
    import prompts as mv_prompts
    import main as mv_main
    import cuda_utils as mv_cuda_utils
except ImportError as e:
    print(f"Error: æ— æ³•ä» {MINI_VERSION_PATH} å¯¼å…¥ mini_version æ¨¡å—ã€‚")
    print(e)
    sys.exit(1)

# å¯¼å…¥æœ¬åœ°çš„ Xpiler åŠ è½½å™¨
import xpiler_loader

# --- è¾…åŠ©å‡½æ•° ---

def extract_all_code_blocks(text):
    """
    æå–æ–‡æœ¬ä¸­æ‰€æœ‰çš„ä»£ç å—å†…å®¹ã€‚
    è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ ```lang ... ``` ä¸­çš„å†…å®¹ã€‚
    """
    # åŒ¹é… ```ä»»æ„è¯­è¨€ ... ```
    pattern = r'```(?:\w+)?\n(.*?)\n```'
    matches = re.findall(pattern, text, re.DOTALL)
    return [m.strip() for m in matches]

def generate_wrapper_code(cuda_source, inputs, ref_outputs, kernel_name, wrapper_name):
    """
    è°ƒç”¨ LLM ä¸ºç°æœ‰çš„ Kernel ç”Ÿæˆ PyTorch Wrapper
    """
    # 1. è·å– Prompt
    prompt = mv_prompts.get_wrapper_generation_prompt(
        cuda_source, inputs, ref_outputs, kernel_name, wrapper_name
    )
    
    system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ CUDA/PyTorch ç»‘å®šä¸“å®¶ã€‚"
    
    # 2. è°ƒç”¨ LLM
    try:
        response_text = mv_llm_api.call_llm(
            agent_name="initial_generator", 
            system_prompt=system_prompt,
            user_prompt=prompt
        )
        
        # 3. æå–ä»£ç  (ä¿®æ­£ç‰ˆé€»è¾‘)
        # å› ä¸º Prompt æ¨¡æ¿è®©ä¸¤ä¸ªå—éƒ½å« ```cppï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æŒ‰é¡ºåºæå–
        blocks = extract_all_code_blocks(response_text)
        
        cpp_sig = None
        wrapper_impl = None

        if len(blocks) >= 2:
            # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯ç­¾åï¼Œç¬¬äºŒä¸ªæ˜¯å®ç°
            cpp_sig = blocks[0]
            wrapper_impl = blocks[1]
        elif len(blocks) == 1:
            # åªæœ‰ä¸€å—ï¼Œå¯èƒ½æ··åœ¨ä¸€èµ·äº†ï¼Œå°è¯•å½“åšå®ç°ï¼Œç­¾åå¯èƒ½ç¼ºå¤±æˆ–åœ¨å…¶ä¸­
            print("Warning: Only 1 code block found in wrapper generation.")
            wrapper_impl = blocks[0]
            # å°è¯•ä»å®ç°ä¸­æ­£åˆ™æå–ç­¾åï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            if "torch::Tensor" in wrapper_impl and ";" in wrapper_impl.split("{")[0]:
                 cpp_sig = wrapper_impl.split("{")[0].strip() + ";"
        
        return cpp_sig, wrapper_impl, response_text
    
    except Exception as e:
        print(f"Wrapper Generation Error: {e}")
        return None, None, str(e)

def extract_kernel_body(full_cuda_source):
    """
    ä» Xpiler çš„ .cu æ–‡ä»¶ä¸­æå– __global__ å‡½æ•°éƒ¨åˆ†ï¼Œ
    å»æ‰ extern "C" çš„ host ä»£ç ï¼Œä»¥å…ä¸æˆ‘ä»¬ç”Ÿæˆçš„ Wrapper å†²çªã€‚
    """
    lines = full_cuda_source.split('\n')
    cleaned_lines = []
    skip = False
    for line in lines:
        if 'extern "C"' in line:
            skip = True
        if not skip:
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)

# --- ä¸»é€»è¾‘ ---

def main(args):
    print(f"ğŸš€ Starting XpilerBench Optimization Loop")
    print(f"ğŸ“‚ Xpiler Path: {XPILER_EVAL_PATH}")
    # print(f"ğŸ¤– LLM Config: {json.dumps(mv_config.AGENT_MODELS, indent=2)}")
    
    results_dir = args.results_dir
    os.makedirs(results_dir, exist_ok=True)
    summary_path = os.path.join(results_dir, "xpiler_summary.json")
    summary_results = {}

    # 1. åˆå§‹åŒ–åŠ è½½å™¨
    loader = xpiler_loader.XpilerBenchmarkLoader(XPILER_EVAL_PATH)
    
    # 2. éå†ç®—å­
    problems = loader.get_problems(limit=args.limit_files)
    
    for prob in problems:
        name = prob['name']
        op_name = prob['op']
        args_dims = prob['args']
        raw_cuda_code = prob['code'] # Xpiler åŸå§‹ä»£ç  (Ground Truth)
        
        print(f"\n\n=== Processing: {name} ({op_name}) ===")
        
        problem_dir = os.path.join(results_dir, name)
        os.makedirs(problem_dir, exist_ok=True)
        history_file = os.path.join(problem_dir, "history.json")
        
        inputs = None
        ref_outputs = None
        
        try:
            # --- æ­¥éª¤ 1: å»ºç«‹ PyTorch åŸºçº¿ & è¾“å…¥ ---
            print("Step 1: Generating PyTorch Baseline...")
            torch_func, inputs = xpiler_loader.get_torch_baseline(op_name, args_dims, device="cuda")
            
            # è¿è¡ŒåŸºçº¿ä»¥è·å¾— ref_outputs
            torch.cuda.synchronize()
            # é¢„çƒ­
            for _ in range(5): torch_func(*inputs)
            # æµ‹é€Ÿ
            start_ev = torch.cuda.Event(enable_timing=True)
            end_ev = torch.cuda.Event(enable_timing=True)
            start_ev.record()
            for _ in range(20):
                ref_out = torch_func(*inputs)
            end_ev.record()
            torch.cuda.synchronize()
            baseline_ms = start_ev.elapsed_time(end_ev) / 20.0
            
            print(f"PyTorch Baseline: {baseline_ms:.4f} ms")
            
            if isinstance(ref_out, torch.Tensor):
                ref_outputs = [ref_out]
            elif isinstance(ref_out, (list, tuple)):
                ref_outputs = list(ref_out)
            else:
                ref_outputs = [ref_out]

            # --- æ­¥éª¤ 2: æ¸…æ´—åŸå§‹ä»£ç  & ç”Ÿæˆ Wrapper ---
            print("Step 2: Generating PyTorch Wrapper for Ground Truth Kernel...")
            
            clean_kernel_code = extract_kernel_body(raw_cuda_code)
            
            # å°è¯•ä»ä»£ç ä¸­æå– kernel åå­—
            kernel_name_match = re.search(r'__global__\s+void\s+(\w+)', clean_kernel_code)
            if not kernel_name_match:
                # æœ‰äº›ç‰¹æ®Šçš„å†™æ³•å¯èƒ½åŒ…å« launch_bounds ç­‰å®ï¼Œå°è¯•æ›´å®½æ³›çš„åŒ¹é…
                kernel_name_match = re.search(r'__global__\s+void\s+.*?\s+(\w+)\s*\(', clean_kernel_code, re.DOTALL)
            
            kernel_name = kernel_name_match.group(1) if kernel_name_match else "unknown_kernel"
            wrapper_name = f"{name}_wrapper".replace("-", "_") # ç¡®ä¿ wrapper åå­—åˆæ³•
            
            cpp_sig, wrapper_impl, _ = generate_wrapper_code(
                clean_kernel_code, inputs, ref_outputs, kernel_name, wrapper_name
            )
            
            if not cpp_sig or not wrapper_impl:
                print("Failed to generate wrapper.")
                summary_results[name] = {"status": "Wrapper Generation Failed"}
                continue
                
            # ç»„åˆæˆåˆå§‹çš„å¯ç¼–è¯‘ä»£ç 
            initial_cuda_code = clean_kernel_code + "\n\n" + wrapper_impl
            
            # éªŒè¯ä¸€ä¸‹åˆå§‹ä»£ç æ˜¯å¦èƒ½è·‘
            print("Verifying Initial Code Correctness...")
            try:
                # ä¸´æ—¶åŠ è½½
                # å…ˆæ¸…é™¤å¯èƒ½çš„æ—§æ¨¡å—ç¼“å­˜
                mv_cuda_utils._gemm_module = None 
                
                mv_cuda_utils.load_gemm_module(
                    cpp_sig, initial_cuda_code, f"{name}_sanity_check", wrapper_name
                )
                is_valid = mv_cuda_utils.check_correctness(inputs, ref_outputs, wrapper_name)
                if not is_valid:
                    print("Warning: Initial wrapper compiled but correctness check failed.")
                    summary_results[name] = {"status": "Initial Correctness Failed"}
                    # å³ä½¿å¤±è´¥ä¹Ÿå¯èƒ½è¿›å…¥ä¼˜åŒ–ï¼Œæˆ–è€…é€‰æ‹©è·³è¿‡ã€‚è¿™é‡Œé€‰æ‹©è·³è¿‡ä»¥ä¿è¯è´¨é‡ã€‚
                    continue
                print("Initial Code Verified âœ…")
            except Exception as e:
                print(f"Initial Compilation Failed: {e}")
                summary_results[name] = {"status": f"Initial Compilation Failed: {e}"}
                continue

            # --- æ­¥éª¤ 3: è¿›å…¥ä¼˜åŒ–å¾ªç¯ ---
            print("Step 3: Running Optimization Loop...")
            
            best_result = mv_main.run_optimization_on_problem(
                problem_name=name,
                cpp_source=cpp_sig,           
                initial_cuda_code=initial_cuda_code,
                inputs=inputs,
                ref_outputs=ref_outputs,
                kernel_name=kernel_name,      
                wrapper_function_name=wrapper_name,
                iteration_rounds=mv_config.ITERATION_ROUNDS,
                history_file_path=history_file,
                baseline_time_ms=baseline_ms
            )
            
            best_time = best_result.get('time_ms', float('inf'))
            speedup = baseline_ms / best_time if best_time > 0 else 0
            
            print(f"ğŸ Finished {name}")
            print(f"Baseline: {baseline_ms:.4f} ms | Best: {best_time:.4f} ms | Speedup: {speedup:.2f}x")
            
            summary_results[name] = {
                "baseline_ms": baseline_ms,
                "best_cuda_ms": best_time,
                "speedup": speedup,
                "status": "Success" if best_time < float('inf') else "Optimization Failed"
            }
            
        except Exception as e:
            print(f"Error processing {name}: {e}")
            traceback.print_exc()
            summary_results[name] = {"status": f"Error: {e}"}
            
        finally:
            # æ¸…ç†æ˜¾å­˜
            inputs = None
            ref_outputs = None
            gc.collect()
            torch.cuda.empty_cache()
            
        # å®æ—¶ä¿å­˜æ‘˜è¦
        with open(summary_path, "w") as f:
            json.dump(summary_results, f, indent=2)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--results_dir", default="./xpiler_optimization_results")
    parser.add_argument("--limit_files", type=int, default=0, help="0 for all")
    args = parser.parse_args()
    
    main(args)