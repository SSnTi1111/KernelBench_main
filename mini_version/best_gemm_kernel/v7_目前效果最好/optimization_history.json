[
  {
    "round": 0,
    "goal": "Baseline",
    "status": "Success",
    "time_ms": 1.5047679901123048,
    "ptxas_metrics": {
      "registers_used": 0.0,
      "shared_mem_bytes": 0.0,
      "spill_bytes": 0.0
    },
    "details": "Initial baseline measurement",
    "code": "\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float4\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u91cd\u6784\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u884c(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u6cbfK\u7ef4\u4e00\u6b21\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5143\u7d20(float4)\u5e76\u5b58\u5165\u5bf9\u5e94\u7684K\u4f4d\u7f6e\u4e0e\u884c\u4f4d\u7f6e\u3002\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u7ef4\u6301\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757\u884c(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u5217(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u5bf9B\u7684\u540c\u4e00K\u884c\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5217\u5143\u7d20(float4)\u3002\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u5728\u77e9\u5f62\u533a\u57df\u5185\u5b9e\u73b0\u9ad8\u6548\u7684Z-order\u6620\u5c04\uff1a\n    // 1) \u5148\u5bf9\u80fd\u5bb9\u7eb3\u7684\u6700\u59272^k\u65b9\u5f62\u533a\u57df\uff08q x q\uff09\u4f7f\u7528Morton\u89e3\u7801\n    // 2) \u5bf9\u53f3\u4fa7\u6761\u5e26(q..w-1, 0..q-1)\u548c\u5e95\u90e8\u6761\u5e26(0..w-1, q..h-1)\u4f7f\u7528\u7ebf\u6027\u6620\u5c04\n    uint32_t w = num_tiles_x;\n    uint32_t h = num_tiles_y;\n    uint32_t q = highest_pow2_leq(min(w, h)); // \u6700\u5927\u9002\u914d\u7684\u65b9\u5f62\u5c3a\u5bf8(2^k)\n\n    uint32_t tile_z_x, tile_z_y;\n    uint32_t square_count = q * q;\n    uint32_t right_strip_count = q * (w - q);\n\n    if (block_id < square_count) {\n        // \u65b9\u5f62\u533a\u57df\u5185\u7684Morton\u89e3\u7801\n        uint32_t code = block_id;\n        tile_z_x = morton_decode_x(code); // [0, q)\n        tile_z_y = morton_decode_y(code); // [0, q)\n    } else if (block_id < square_count + right_strip_count) {\n        // \u53f3\u4fa7\u6761\u5e26\uff1ax in [q, w-1], y in [0, q-1]\n        uint32_t i = block_id - square_count;\n        uint32_t rs_w = w - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53rs_w\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3aright_strip_count\u4e3a0\uff09\n        tile_z_x = q + (i % rs_w);\n        tile_z_y = (i / rs_w);\n    } else {\n        // \u5e95\u90e8\u6761\u5e26\uff1ax in [0, w-1], y in [q, h-1]\n        uint32_t i = block_id - square_count - right_strip_count;\n        uint32_t bs_h = h - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53bs_h\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3a\u5269\u4f59\u6570\u91cf\u4e3a0\uff09\n        tile_z_y = q + (i % bs_h);\n        tile_z_x = (i / bs_h);\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        // \u5c06tid_x\u5212\u5206\u4e3a(\u884c\u9009\u62e9, K\u5411\u91cf\u6bb5\u9009\u62e9)\uff1atid_x / 4 \u5bf9\u5e94\u672c\u7ebf\u7a0b\u52a0\u8f7d\u7684\u884c\u7d22\u5f15(\u76f8\u5bf9\u4e8e\u51764\u884c\u7ec4)\uff0ctid_x % 4 \u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,4,8,12)\n        int a_row_sel = tid_x / 4;      // 0..3\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u56db\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 4;      // 0..3\uff0c\u5bf9\u5e94K\u5185\u76844\u5143\u7d20\u6bb5\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}\n"
  },
  {
    "round": 1,
    "goal": "Reduce shared memory usage by implementing a smaller tile size (e.g., 32x32 instead of 64x64) while maintaining the same optimization techniques, to better fit within shared memory constraints and improve memory throughput.",
    "status": "Failed (Correctness)",
    "time_ms": null,
    "ptxas_metrics": {
      "registers_used": 40.0,
      "shared_mem_bytes": 4096.0,
      "spill_bytes": 0.0
    },
    "details": "New kernel is INCORRECT.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 8\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float4\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\uff1a[BLOCK_SIZE][4*BLOCK_SIZE]\uff08\u4f8b\u59828x32\uff09\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\uff1a[BLOCK_SIZE][4*BLOCK_SIZE]\uff08\u4f8b\u59828x32\uff09\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 32\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d632x32\u8f93\u51fa\uff09\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u5728\u77e9\u5f62\u533a\u57df\u5185\u5b9e\u73b0\u9ad8\u6548\u7684Z-order\u6620\u5c04\uff1a\n    // 1) \u5148\u5bf9\u80fd\u5bb9\u7eb3\u7684\u6700\u59272^k\u65b9\u5f62\u533a\u57df\uff08q x q\uff09\u4f7f\u7528Morton\u89e3\u7801\n    // 2) \u5bf9\u53f3\u4fa7\u6761\u5e26(q..w-1, 0..q-1)\u548c\u5e95\u90e8\u6761\u5e26(0..w-1, q..h-1)\u4f7f\u7528\u7ebf\u6027\u6620\u5c04\n    uint32_t w = num_tiles_x;\n    uint32_t h = num_tiles_y;\n    uint32_t q = highest_pow2_leq(min(w, h)); // \u6700\u5927\u9002\u914d\u7684\u65b9\u5f62\u5c3a\u5bf8(2^k)\n\n    uint32_t tile_z_x, tile_z_y;\n    uint32_t square_count = q * q;\n    uint32_t right_strip_count = q * (w - q);\n\n    if (block_id < square_count) {\n        // \u65b9\u5f62\u533a\u57df\u5185\u7684Morton\u89e3\u7801\n        uint32_t code = block_id;\n        tile_z_x = morton_decode_x(code); // [0, q)\n        tile_z_y = morton_decode_y(code); // [0, q)\n    } else if (block_id < square_count + right_strip_count) {\n        // \u53f3\u4fa7\u6761\u5e26\uff1ax in [q, w-1], y in [0, q-1]\n        uint32_t i = block_id - square_count;\n        uint32_t rs_w = w - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53rs_w\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3aright_strip_count\u4e3a0\uff09\n        tile_z_x = q + (i % rs_w);\n        tile_z_y = (i / rs_w);\n    } else {\n        // \u5e95\u90e8\u6761\u5e26\uff1ax in [0, w-1], y in [q, h-1]\n        uint32_t i = block_id - square_count - right_strip_count;\n        uint32_t bs_h = h - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53bs_h\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3a\u5269\u4f59\u6570\u91cf\u4e3a0\uff09\n        tile_z_y = q + (i % bs_h);\n        tile_z_x = (i / bs_h);\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d632x32\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;           // 0..1 (when BLOCK_SIZE=8, tid_x in [0,7])\n        int a_vec_seg = tid_x % 4;           // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..31\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;               // 0..1\n            int a_vec_seg = tid_x % 4;               // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..31\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 2,
    "goal": "Reduce shared memory usage by implementing a smaller tile size (e.g., 32x32 instead of 64x64) while maintaining the same optimization techniques (double buffering, vectorization, software pipelining), to better fit within shared memory constraints and improve memory throughput.",
    "status": "Failed (Performance Regression)",
    "time_ms": 2.7845632553100588,
    "ptxas_metrics": {
      "registers_used": 30.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 2.785 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b972x2\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float2\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u91cd\u6784\u4e3a [BLOCK_SIZE][2*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u884c(0..31)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u6cbfK\u7ef4\u4e00\u6b21\u52a0\u8f7d\u8fde\u7eed2\u4e2a\u5143\u7d20(float2)\u5e76\u5b58\u5165\u5bf9\u5e94\u7684K\u4f4d\u7f6e\u4e0e\u884c\u4f4d\u7f6e\u3002\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u7ef4\u6301\u4e3a [BLOCK_SIZE][2*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757\u884c(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u5217(0..31)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u5bf9B\u7684\u540c\u4e00K\u884c\u52a0\u8f7d\u8fde\u7eed2\u4e2a\u5217\u5143\u7d20(float2)\u3002\n    __shared__ float Asub_ping[BLOCK_SIZE][2 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][2 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][2 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][2 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 2 * BLOCK_SIZE; // 32\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d632x32\u8f93\u51fa\uff09\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u5728\u77e9\u5f62\u533a\u57df\u5185\u5b9e\u73b0\u9ad8\u6548\u7684Z-order\u6620\u5c04\uff1a\n    // 1) \u5148\u5bf9\u80fd\u5bb9\u7eb3\u7684\u6700\u59272^k\u65b9\u5f62\u533a\u57df\uff08q x q\uff09\u4f7f\u7528Morton\u89e3\u7801\n    // 2) \u5bf9\u53f3\u4fa7\u6761\u5e26(q..w-1, 0..q-1)\u548c\u5e95\u90e8\u6761\u5e26(0..w-1, q..h-1)\u4f7f\u7528\u7ebf\u6027\u6620\u5c04\n    uint32_t w = num_tiles_x;\n    uint32_t h = num_tiles_y;\n    uint32_t q = highest_pow2_leq(min(w, h)); // \u6700\u5927\u9002\u914d\u7684\u65b9\u5f62\u5c3a\u5bf8(2^k)\n\n    uint32_t tile_z_x, tile_z_y;\n    uint32_t square_count = q * q;\n    uint32_t right_strip_count = q * (w - q);\n\n    if (block_id < square_count) {\n        // \u65b9\u5f62\u533a\u57df\u5185\u7684Morton\u89e3\u7801\n        uint32_t code = block_id;\n        tile_z_x = morton_decode_x(code); // [0, q)\n        tile_z_y = morton_decode_y(code); // [0, q)\n    } else if (block_id < square_count + right_strip_count) {\n        // \u53f3\u4fa7\u6761\u5e26\uff1ax in [q, w-1], y in [0, q-1]\n        uint32_t i = block_id - square_count;\n        uint32_t rs_w = w - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53rs_w\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3aright_strip_count\u4e3a0\uff09\n        tile_z_x = q + (i % rs_w);\n        tile_z_y = (i / rs_w);\n    } else {\n        // \u5e95\u90e8\u6761\u5e26\uff1ax in [0, w-1], y in [q, h-1]\n        uint32_t i = block_id - square_count - right_strip_count;\n        uint32_t bs_h = h - q; // \u53ef\u80fd\u4e3a0\n        // \u5f53bs_h\u4e3a0\u65f6\uff0c\u6b64\u5206\u652f\u4e0d\u4f1a\u8fdb\u5165\uff08\u56e0\u4e3a\u5269\u4f59\u6570\u91cf\u4e3a0\uff09\n        tile_z_y = q + (i % bs_h);\n        tile_z_x = (i / bs_h);\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d632x32\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76842x2\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 2 + 0;\n    int a_r1_local = tid_y * 2 + 1;\n\n    int b_c0_local = tid_x * 2 + 0;\n    int b_c1_local = tid_x * 2 + 1;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76842x2\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[2 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[2 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[2 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[2 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat2\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76842\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        // \u5c06tid_x\u5212\u5206\u4e3a(\u884c\u9009\u62e9, K\u5411\u91cf\u6bb5\u9009\u62e9)\uff1atid_x / 8 \u5bf9\u5e94\u672c\u7ebf\u7a0b\u52a0\u8f7d\u7684\u884c\u7d22\u5f15(\u76f8\u5bf9\u4e8e\u51762\u884c\u7ec4)\uff0ctid_x % 8 \u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,2,4,...,14)\n        int a_row_sel = tid_x / 8;      // 0..1\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u4e24\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 8;      // 0..7\uff0c\u5bf9\u5e94K\u5185\u76842\u5143\u7d20\u6bb5\n        int a_local_row = tid_y * 2 + a_row_sel; // 0..31\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 2; // 0,2,4,...,14\n\n        float2 a2 = make_float2(0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk1 < N && (aline % 8 == 0)) {\n                a2 = *reinterpret_cast<const float2*>(a_ptr);\n            } else {\n                a2.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a2.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a2.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a2.y;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat2\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76842\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float2 b2 = make_float2(0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c1 < N && (bline % 8 == 0)) {\n                b2 = *reinterpret_cast<const float2*>(b_ptr);\n            } else {\n                b2.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b2.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b2.x;\n        Bsub_curr[tid_y][b_c1_local] = b2.y;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0c\u9488\u5bf92x2\u8ba1\u7b97\u6a21\u5f0f\u5c55\u5f00\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; ++k) {\n            float a0 = Asub_curr[k][a_r0_local];\n            float a1 = Asub_curr[k][a_r1_local];\n\n            float b0 = Bsub_curr[k][b_c0_local];\n            float b1 = Bsub_curr[k][b_c1_local];\n\n            acc00 += a0 * b0;\n            acc01 += a0 * b1;\n            acc10 += a1 * b0;\n            acc11 += a1 * b1;\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 8;          // 0..1\n            int a_vec_seg = tid_x % 8;          // 0..7\n            int a_local_row = tid_y * 2 + a_row_sel; // 0..31\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 2;\n\n            float2 a2n = make_float2(0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk1 < N && (aline_n % 8 == 0)) {\n                    a2n = *reinterpret_cast<const float2*>(a_ptr_n);\n                } else {\n                    a2n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a2n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a2n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a2n.y;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float2 b2n = make_float2(0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c1 < N && (bline_n % 8 == 0)) {\n                    b2n = *reinterpret_cast<const float2*>(b_ptr_n);\n                } else {\n                    b2n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b2n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b2n.x;\n            Bsub_next[tid_y][b_c1_local] = b2n.y;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[2 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[2 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff082x2\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 3,
    "goal": "Simplify the block mapping strategy by replacing Morton ordering with standard row-major block distribution to reduce computational overhead and improve memory access patterns, while maintaining the current shared memory tiling and double buffering optimizations.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5524864196777344,
    "ptxas_metrics": {
      "registers_used": 40.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.552 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float4\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u91cd\u6784\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u884c(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u6cbfK\u7ef4\u4e00\u6b21\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5143\u7d20(float4)\u5e76\u5b58\u5165\u5bf9\u5e94\u7684K\u4f4d\u7f6e\u4e0e\u884c\u4f4d\u7f6e\u3002\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u7ef4\u6301\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757\u884c(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u5217(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u5bf9B\u7684\u540c\u4e00K\u884c\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5217\u5143\u7d20(float4)\u3002\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Row-major block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(blockIdx.y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(blockIdx.x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u56db\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 4;      // 0..3\uff0c\u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,4,8,12)\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 4,
    "goal": "Simplify the block mapping by implementing a pure row-major grid strategy with careful attention to memory coalescing, eliminating the complex Morton ordering and its associated branching overhead, while retaining the existing 4x4 per-thread tiling, shared memory double buffering, and vectorized loads.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.703219223022461,
    "ptxas_metrics": {
      "registers_used": 40.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.703 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float4\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u91cd\u6784\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u884c(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u6cbfK\u7ef4\u4e00\u6b21\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5143\u7d20(float4)\u5e76\u5b58\u5165\u5bf9\u5e94\u7684K\u4f4d\u7f6e\u4e0e\u884c\u4f4d\u7f6e\u3002\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u7ef4\u6301\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757\u884c(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u5217(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u5bf9B\u7684\u540c\u4e00K\u884c\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5217\u5143\u7d20(float4)\u3002\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Row-major block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    const int GROUP_FACTOR_X = TILE_SIZE / BLOCK_SIZE; // 4\n    const int GROUP_FACTOR_Y = TILE_SIZE / BLOCK_SIZE; // 4\n\n    // \u7531\u4e8e\u5916\u90e8launcher\u6309BLOCK_SIZE(16)\u5212\u5206\u4e86grid\uff0c\u8fd9\u91cc\u5c06\u5176\u6298\u53e0\u4e3a\u6309TILE_SIZE(64)\u7684tiles\u3002\n    // \u4ec5\u8ba9\u6bcf4x4\u4e2ablock\u4e2d\u7684\u5de6\u4e0a\u89d2block\u6267\u884c\u8ba1\u7b97\uff0c\u5176\u4f59\u76f4\u63a5\u8fd4\u56de\uff0c\u907f\u514d\u91cd\u590d\u8ba1\u7b97\u3002\n    if ((blockIdx.x % GROUP_FACTOR_X) != 0 || (blockIdx.y % GROUP_FACTOR_Y) != 0) {\n        return;\n    }\n\n    int tile_x = blockIdx.x / GROUP_FACTOR_X;\n    int tile_y = blockIdx.y / GROUP_FACTOR_Y;\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    int tile_row_base = tile_y * TILE_SIZE;\n    int tile_col_base = tile_x * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        // \u5c06tid_x\u5212\u5206\u4e3a(\u884c\u9009\u62e9, K\u5411\u91cf\u6bb5\u9009\u62e9)\uff1atid_x / 4 \u5bf9\u5e94\u672c\u7ebf\u7a0b\u52a0\u8f7d\u7684\u884c\u7d22\u5f15(\u76f8\u5bf9\u4e8e\u51764\u884c\u7ec4)\uff0ctid_x % 4 \u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,4,8,12)\n        int a_row_sel = tid_x / 4;      // 0..3\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u56db\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 4;      // 0..3\uff0c\u5bf9\u5e94K\u5b50\u5757\u5185\u76844\u5143\u7d20\u6bb5\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 5,
    "goal": "Simplify the memory access pattern by implementing a standard row-major block distribution with optimized shared memory tiling, eliminating the complex Morton ordering and double buffering overhead to improve L2 cache utilization and reduce global memory pressure.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5902720451354981,
    "ptxas_metrics": {
      "registers_used": 66.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.590 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Simplified row-major tile mapping (64x64 per block) and single-buffer shared memory tiling.\n    // - Each block computes a 64x64 output tile: TILE_SIZE = 4 * BLOCK_SIZE = 64\n    // - Each thread computes a 4x4 sub-tile in registers.\n    // - Shared memory tiles: Asub[64][16] and Bsub[16][64]\n    // - Vectorized float4 global loads where possible, with boundary checks.\n\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n\n    // Determine number of 64x64 tiles along each dimension\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    // Flattened block id in row-major order\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // Discard excess launched blocks (wrapper uses 16x16 grid granularity)\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // Map flat id to 2D tile coordinates (row-major)\n    uint32_t tile_x = block_id % num_tiles_x;\n    uint32_t tile_y = block_id / num_tiles_x;\n\n    // Output tile base coordinates\n    int tile_row_base = static_cast<int>(tile_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_x) * TILE_SIZE;\n\n    // Thread indices\n    int tid_y = threadIdx.y; // [0, 15]\n    int tid_x = threadIdx.x; // [0, 15]\n\n    // Each thread computes a 4x4 output block at these local coordinates\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    // Global row/col indices for the 4x4 outputs\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // Accumulators in registers for the 4x4 outputs\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // Single-buffer shared memory tiles\n    __shared__ float Asub[4 * BLOCK_SIZE][BLOCK_SIZE]; // [64][16]\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE]; // [16][64]\n\n    // K-loop over tiles of width BLOCK_SIZE (16)\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n        // --------------------------\n        // Cooperative loads into SMEM\n        // --------------------------\n\n        // A: load one float4 covering 4 consecutive K elements for a specific row in the 64x16 Asub tile\n        int a_row_sel = tid_x / 4;                // 0..3 (selects which of the 4 rows in this thread's group)\n        int a_vec_seg = tid_x % 4;                // 0..3 (which 4-wide segment within the 16-wide K tile)\n        int a_local_row = tid_y * 4 + a_row_sel;  // 0..63 (row within the 64-row tile)\n        int g_row_A = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;         // {0,4,8,12}\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row_A < N) {\n            int gk0 = k_tile + local_k_base + 0;\n            int gk1 = k_tile + local_k_base + 1;\n            int gk2 = k_tile + local_k_base + 2;\n            int gk3 = k_tile + local_k_base + 3;\n            const float* a_ptr = &A[g_row_A * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row_A * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row_A * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row_A * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row_A * N + gk3] : 0.0f;\n            }\n        }\n        // Store into Asub as [row][k]\n        Asub[a_local_row][local_k_base + 0] = a4.x;\n        Asub[a_local_row][local_k_base + 1] = a4.y;\n        Asub[a_local_row][local_k_base + 2] = a4.z;\n        Asub[a_local_row][local_k_base + 3] = a4.w;\n\n        // B: load one float4 covering 4 consecutive col elements for a specific K row in the 16x64 Bsub tile\n        int kB = k_tile + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n        // Store into Bsub as [k][col]\n        Bsub[tid_y][b_c0_local] = b4.x;\n        Bsub[tid_y][b_c1_local] = b4.y;\n        Bsub[tid_y][b_c2_local] = b4.z;\n        Bsub[tid_y][b_c3_local] = b4.w;\n\n        __syncthreads();\n\n        // --------------------------\n        // Compute using shared tiles\n        // --------------------------\n        #pragma unroll\n        for (int kk = 0; kk < BLOCK_SIZE; ++kk) {\n            float a0 = Asub[a_r0_local][kk];\n            float a1 = Asub[a_r1_local][kk];\n            float a2 = Asub[a_r2_local][kk];\n            float a3 = Asub[a_r3_local][kk];\n\n            float b0 = Bsub[kk][b_c0_local];\n            float b1 = Bsub[kk][b_c1_local];\n            float b2 = Bsub[kk][b_c2_local];\n            float b3 = Bsub[kk][b_c3_local];\n\n            // 4x4 outer product accumulation\n            acc00 += a0 * b0; acc01 += a0 * b1; acc02 += a0 * b2; acc03 += a0 * b3;\n            acc10 += a1 * b0; acc11 += a1 * b1; acc12 += a1 * b2; acc13 += a1 * b3;\n            acc20 += a2 * b0; acc21 += a2 * b1; acc22 += a2 * b2; acc23 += a2 * b3;\n            acc30 += a3 * b0; acc31 += a3 * b1; acc32 += a3 * b2; acc33 += a3 * b3;\n        }\n\n        __syncthreads(); // Ensure all threads finished using Asub/Bsub before next load\n    }\n\n    // --------------------------\n    // Write back the 4x4 results\n    // --------------------------\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 6,
    "goal": "Optimize the kernel by simplifying the block mapping to pure row-major ordering and reducing double buffering overhead while maintaining the current 4x4 per-thread tiling and vectorized loads, focusing on minimizing computational overhead to better saturate global memory bandwidth.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5555583953857421,
    "ptxas_metrics": {
      "registers_used": 57.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.556 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5355\u7f13\u51b2\u5171\u4eab\u5185\u5b58\uff08\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa\uff09+ \u6bcf\u4e2aK\u5b50\u5757\u540c\u6b65\u52a0\u8f7d + \u5411\u91cf\u5316\u5168\u5c40\u5185\u5b58\u8bbf\u95ee\n    __shared__ float Asub[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Row-major tile mapping (64x64 tiles)\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\uff0c\u5e76\u6620\u5c04\u523064x64 tile\u7f51\u683c\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n    uint32_t tile_x = (num_tiles_x == 0) ? 0u : (block_id % num_tiles_x);\n    uint32_t tile_y = (num_tiles_x == 0) ? 0u : (block_id / num_tiles_x);\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(tile_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff1a\u6bcf\u6b21\u8fed\u4ee3\u52a0\u8f7d\u4e00\u4e2aK\u5b50\u5757\u5230\u5171\u4eab\u5185\u5b58\uff0c\u7136\u540e\u8ba1\u7b97\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;                // 0..3\n        int a_vec_seg = tid_x % 4;                // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel;  // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;         // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = k_tile + local_k_base + 0;\n            int gk1 = k_tile + local_k_base + 1;\n            int gk2 = k_tile + local_k_base + 2;\n            int gk3 = k_tile + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub[local_k_base + 0][a_local_row] = a4.x;\n        Asub[local_k_base + 1][a_local_row] = a4.y;\n        Asub[local_k_base + 2][a_local_row] = a4.z;\n        Asub[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = k_tile + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub[tid_y][b_c0_local] = b4.x;\n        Bsub[tid_y][b_c1_local] = b4.y;\n        Bsub[tid_y][b_c2_local] = b4.z;\n        Bsub[tid_y][b_c3_local] = b4.w;\n\n        __syncthreads();\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub[k + 0][a_r0_local];\n                float a1 = Asub[k + 0][a_r1_local];\n                float a2 = Asub[k + 0][a_r2_local];\n                float a3 = Asub[k + 0][a_r3_local];\n\n                float b0 = Bsub[k + 0][b_c0_local];\n                float b1 = Bsub[k + 0][b_c1_local];\n                float b2 = Bsub[k + 0][b_c2_local];\n                float b3 = Bsub[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub[k + 1][a_r0_local];\n                float a1 = Asub[k + 1][a_r1_local];\n                float a2 = Asub[k + 1][a_r2_local];\n                float a3 = Asub[k + 1][a_r3_local];\n\n                float b0 = Bsub[k + 1][b_c0_local];\n                float b1 = Bsub[k + 1][b_c1_local];\n                float b2 = Bsub[k + 1][b_c2_local];\n                float b3 = Bsub[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub[k + 2][a_r0_local];\n                float a1 = Asub[k + 2][a_r1_local];\n                float a2 = Asub[k + 2][a_r2_local];\n                float a3 = Asub[k + 2][a_r3_local];\n\n                float b0 = Bsub[k + 2][b_c0_local];\n                float b1 = Bsub[k + 2][b_c1_local];\n                float b2 = Bsub[k + 2][b_c2_local];\n                float b3 = Bsub[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub[k + 3][a_r0_local];\n                float a1 = Asub[k + 3][a_r1_local];\n                float a2 = Asub[k + 3][a_r2_local];\n                float a3 = Asub[k + 3][a_r3_local];\n\n                float b0 = Bsub[k + 3][b_c0_local];\n                float b1 = Bsub[k + 3][b_c1_local];\n                float b2 = Bsub[k + 3][b_c2_local];\n                float b3 = Bsub[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u786e\u4fdd\u5f53\u524dK\u5b50\u5757\u7684\u6240\u6709\u8ba1\u7b97\u5b8c\u6210\uff0c\u518d\u8fdb\u884c\u4e0b\u4e00\u6b21\u52a0\u8f7d\uff0c\u907f\u514d\u5171\u4eab\u5185\u5b58\u8986\u76d6\u9020\u6210\u7684\u6570\u636e\u7ade\u4e89\n        __syncthreads();\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 7,
    "goal": "Optimize memory access patterns by implementing a pure row-major block distribution with simplified shared memory tiling (32x32 tiles) and eliminating double buffering overhead, while maintaining 4x4 per-thread tiling and vectorized loads to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 3.163033676147461,
    "ptxas_metrics": {
      "registers_used": 46.0,
      "shared_mem_bytes": 4096.0,
      "spill_bytes": 0.0
    },
    "details": "New time 3.163 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// Row-major block distribution, 32x32 tile per block,\n// single-buffer shared memory, float4 vectorized loads,\n// 4x4 per-thread compute with 16x16 thread blocks\n// (only 8x8 threads perform compute, others assist with loads).\n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Tile size reduced to 32x32\n    const int TILE_SIZE = 2 * BLOCK_SIZE; // 32\n\n    // Thread indices\n    int tid_y = threadIdx.y; // [0, 15]\n    int tid_x = threadIdx.x; // [0, 15]\n\n    // Pure row-major block mapping\n    int tile_row_base = blockIdx.y * TILE_SIZE;\n    int tile_col_base = blockIdx.x * TILE_SIZE;\n\n    // If the tile is completely out of bounds, return\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // Shared memory (single buffer)\n    __shared__ float Asub[BLOCK_SIZE][TILE_SIZE]; // [16][32]\n    __shared__ float Bsub[BLOCK_SIZE][TILE_SIZE]; // [16][32]\n\n    // Per-thread 4x4 output tile indices (only meaningful for compute-active threads)\n    bool compute_active = (tid_x < 8) && (tid_y < 8);\n\n    int a_r0_local = tid_y * 4 + 0; // 0..31 for compute-active threads\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0; // 0..31 for compute-active threads\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // 4x4 accumulators\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // Loop over K dimension in blocks of BLOCK_SIZE (16)\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // ------------------------------\n        // Load A tile (16 x 32) into Asub using 128 threads (tid_x < 8)\n        // Mapping: rows 0..31 (a_local_row), K-segment (0..3) each as float4\n        // ------------------------------\n        if (tid_x < 8) {\n            int a_local_row = tid_y * 2 + (tid_x / 4); // 0..31\n            int kseg = tid_x % 4;                      // 0..3\n            int local_k_base = kseg * 4;               // 0,4,8,12\n\n            float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            int g_row = tile_row_base + a_local_row;\n            if (g_row < N) {\n                int gk0 = k_tile + local_k_base + 0;\n                int gk1 = k_tile + local_k_base + 1;\n                int gk2 = k_tile + local_k_base + 2;\n                int gk3 = k_tile + local_k_base + 3;\n                const float* a_ptr = &A[g_row * N + gk0];\n                uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n                if (gk3 < N && (aline % 16 == 0)) {\n                    a4 = *reinterpret_cast<const float4*>(a_ptr);\n                } else {\n                    a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub[local_k_base + 0][a_local_row] = a4.x;\n            Asub[local_k_base + 1][a_local_row] = a4.y;\n            Asub[local_k_base + 2][a_local_row] = a4.z;\n            Asub[local_k_base + 3][a_local_row] = a4.w;\n        }\n\n        // ------------------------------\n        // Load B tile (16 x 32) into Bsub using 128 threads (tid_x >= 8)\n        // Mapping: k-row = 0..15 (from tid_y), col-group = 0..7 (from tid_x-8)\n        // ------------------------------\n        if (tid_x >= 8) {\n            int kB = k_tile + tid_y;\n            int col_group = tid_x - 8; // 0..7\n            int c_base = tile_col_base + col_group * 4;\n\n            float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (kB < N) {\n                const float* b_ptr = &B[kB * N + c_base];\n                uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n                if ((c_base + 3) < N && (bline % 16 == 0)) {\n                    b4 = *reinterpret_cast<const float4*>(b_ptr);\n                } else {\n                    b4.x = (c_base + 0 < N) ? B[kB * N + (c_base + 0)] : 0.0f;\n                    b4.y = (c_base + 1 < N) ? B[kB * N + (c_base + 1)] : 0.0f;\n                    b4.z = (c_base + 2 < N) ? B[kB * N + (c_base + 2)] : 0.0f;\n                    b4.w = (c_base + 3 < N) ? B[kB * N + (c_base + 3)] : 0.0f;\n                }\n            }\n\n            Bsub[tid_y][col_group * 4 + 0] = b4.x;\n            Bsub[tid_y][col_group * 4 + 1] = b4.y;\n            Bsub[tid_y][col_group * 4 + 2] = b4.z;\n            Bsub[tid_y][col_group * 4 + 3] = b4.w;\n        }\n\n        __syncthreads();\n\n        // ------------------------------\n        // Compute on the loaded tiles\n        // Only 8x8 threads perform 4x4 compute to cover a 32x32 tile\n        // ------------------------------\n        if (compute_active) {\n            #pragma unroll\n            for (int k = 0; k < BLOCK_SIZE; k += 4) {\n                // k + 0\n                {\n                    float a0 = Asub[k + 0][a_r0_local];\n                    float a1 = Asub[k + 0][a_r1_local];\n                    float a2 = Asub[k + 0][a_r2_local];\n                    float a3 = Asub[k + 0][a_r3_local];\n\n                    float b0 = Bsub[k + 0][b_c0_local];\n                    float b1 = Bsub[k + 0][b_c1_local];\n                    float b2 = Bsub[k + 0][b_c2_local];\n                    float b3 = Bsub[k + 0][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 1\n                {\n                    float a0 = Asub[k + 1][a_r0_local];\n                    float a1 = Asub[k + 1][a_r1_local];\n                    float a2 = Asub[k + 1][a_r2_local];\n                    float a3 = Asub[k + 1][a_r3_local];\n\n                    float b0 = Bsub[k + 1][b_c0_local];\n                    float b1 = Bsub[k + 1][b_c1_local];\n                    float b2 = Bsub[k + 1][b_c2_local];\n                    float b3 = Bsub[k + 1][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 2\n                {\n                    float a0 = Asub[k + 2][a_r0_local];\n                    float a1 = Asub[k + 2][a_r1_local];\n                    float a2 = Asub[k + 2][a_r2_local];\n                    float a3 = Asub[k + 2][a_r3_local];\n\n                    float b0 = Bsub[k + 2][b_c0_local];\n                    float b1 = Bsub[k + 2][b_c1_local];\n                    float b2 = Bsub[k + 2][b_c2_local];\n                    float b3 = Bsub[k + 2][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 3\n                {\n                    float a0 = Asub[k + 3][a_r0_local];\n                    float a1 = Asub[k + 3][a_r1_local];\n                    float a2 = Asub[k + 3][a_r2_local];\n                    float a3 = Asub[k + 3][a_r3_local];\n\n                    float b0 = Bsub[k + 3][b_c0_local];\n                    float b1 = Bsub[k + 3][b_c1_local];\n                    float b2 = Bsub[k + 3][b_c2_local];\n                    float b3 = Bsub[k + 3][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n            }\n        }\n\n        __syncthreads(); // Ensure all threads finished compute before reusing shared memory\n    }\n\n    // Write back results (with bounds checks), only for compute-active threads\n    if (compute_active) {\n        if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n        if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n        if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n        if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n        if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n        if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n        if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n        if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n        if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n        if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n        if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n        if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n        if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n        if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n        if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n        if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n    }\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 8,
    "goal": "Simplify the kernel by removing Morton ordering and double buffering overhead while maintaining the 4x4 per-thread tiling and vectorized loads, focusing on maximizing pure computational throughput and minimizing memory access latency through a straightforward row-major block distribution.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.551155185699463,
    "ptxas_metrics": {
      "registers_used": 58.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.551 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Per-thread computes a 4x4 output tile using shared memory blocking (K step = BLOCK_SIZE)\n    // Single-buffered shared memory with vectorized global loads (float4)\n    // Tile size per block: 64x64 (TILE_SIZE = 4 * BLOCK_SIZE)\n    __shared__ float Asub[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n\n    // Compute number of tiles in each dimension (row-major tiling)\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    // Flattened block id from a larger grid (wrapper uses 16x16-based grid); map row-major to 64x64 tiles\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // Row-major tile coordinates\n    uint32_t tile_z_y = block_id / num_tiles_x;\n    uint32_t tile_z_x = block_id % num_tiles_x;\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // If entire tile is out of bounds, return early\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // Each thread's 4x4 output sub-tile (local coords within 64x64 tile)\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // 4x4 accumulators in registers\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // Iterate over K dimension in BLOCK_SIZE steps\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // Load A tile into shared memory: each thread loads a float4 across K for one local row\n        int a_row_sel   = tid_x / 4;                 // selects which of the 4 local rows this thread loads\n        int a_vec_seg   = tid_x % 4;                 // selects which 4-wide segment within the K-tile\n        int a_local_row = tid_y * 4 + a_row_sel;     // [0..63]\n        int g_row       = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;            // 0,4,8,12 within the 16-wide K-tile\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = k_tile + local_k_base + 0;\n            int gk1 = k_tile + local_k_base + 1;\n            int gk2 = k_tile + local_k_base + 2;\n            int gk3 = k_tile + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub[local_k_base + 0][a_local_row] = a4.x;\n        Asub[local_k_base + 1][a_local_row] = a4.y;\n        Asub[local_k_base + 2][a_local_row] = a4.z;\n        Asub[local_k_base + 3][a_local_row] = a4.w;\n\n        // Load B tile into shared memory: each thread loads a float4 across N for one K row\n        int kB = k_tile + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub[tid_y][b_c0_local] = b4.x;\n        Bsub[tid_y][b_c1_local] = b4.y;\n        Bsub[tid_y][b_c2_local] = b4.z;\n        Bsub[tid_y][b_c3_local] = b4.w;\n\n        __syncthreads();\n\n        // Compute using shared memory tiles, unrolled k-loop by 4\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub[k + 0][a_r0_local];\n                float a1 = Asub[k + 0][a_r1_local];\n                float a2 = Asub[k + 0][a_r2_local];\n                float a3 = Asub[k + 0][a_r3_local];\n\n                float b0 = Bsub[k + 0][b_c0_local];\n                float b1 = Bsub[k + 0][b_c1_local];\n                float b2 = Bsub[k + 0][b_c2_local];\n                float b3 = Bsub[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub[k + 1][a_r0_local];\n                float a1 = Asub[k + 1][a_r1_local];\n                float a2 = Asub[k + 1][a_r2_local];\n                float a3 = Asub[k + 1][a_r3_local];\n\n                float b0 = Bsub[k + 1][b_c0_local];\n                float b1 = Bsub[k + 1][b_c1_local];\n                float b2 = Bsub[k + 1][b_c2_local];\n                float b3 = Bsub[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub[k + 2][a_r0_local];\n                float a1 = Asub[k + 2][a_r1_local];\n                float a2 = Asub[k + 2][a_r2_local];\n                float a3 = Asub[k + 2][a_r3_local];\n\n                float b0 = Bsub[k + 2][b_c0_local];\n                float b1 = Bsub[k + 2][b_c1_local];\n                float b2 = Bsub[k + 2][b_c2_local];\n                float b3 = Bsub[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub[k + 3][a_r0_local];\n                float a1 = Asub[k + 3][a_r1_local];\n                float a2 = Asub[k + 3][a_r2_local];\n                float a3 = Asub[k + 3][a_r3_local];\n\n                float b0 = Bsub[k + 3][b_c0_local];\n                float b1 = Bsub[k + 3][b_c1_local];\n                float b2 = Bsub[k + 3][b_c2_local];\n                float b3 = Bsub[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        __syncthreads();\n    }\n\n    // Write back the 4x4 results with boundary checks\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 9,
    "goal": "Optimize the kernel by removing the complex Morton ordering and double buffering overhead while maintaining the 4x4 per-thread tiling and vectorized loads, focusing on maximizing pure computational throughput and minimizing memory access latency through a straightforward row-major block distribution with simplified shared memory tiling.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5597567558288574,
    "ptxas_metrics": {
      "registers_used": 57.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.560 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\uff08\u5355\u7f13\u51b2\uff09 + \u884c\u4e3b\u5e8ftile\u6620\u5c04\n    // \u672c\u7248\u672c\u5bf9\u5168\u5c40\u5185\u5b58\u52a0\u8f7d\u8fdb\u884c\u4e86float4\u5411\u91cf\u5316\uff1a\n    //  - A\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u91cd\u6784\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u884c(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u6cbfK\u7ef4\u4e00\u6b21\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5143\u7d20(float4)\u5e76\u5b58\u5165\u5bf9\u5e94\u7684K\u4f4d\u7f6e\u4e0e\u884c\u4f4d\u7f6e\u3002\n    //  - B\u7684\u5171\u4eab\u5185\u5b58\u7ef4\u6301\u4e3a [BLOCK_SIZE][4*BLOCK_SIZE]\uff0c\u7b2c\u4e00\u7ef4\u4e3aK\u5b50\u5757\u884c(0..15)\uff0c\u7b2c\u4e8c\u7ef4\u4e3atile\u5185\u7684\u5217(0..63)\n    //    \u6bcf\u4e2a\u7ebf\u7a0b\u5bf9B\u7684\u540c\u4e00K\u884c\u52a0\u8f7d\u8fde\u7eed4\u4e2a\u5217\u5143\u7d20(float4)\u3002\n    __shared__ float Asub[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Row-major block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    int tile_row_base = static_cast<int>(blockIdx.y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(blockIdx.x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u5355\u7f13\u51b2\uff1a\u6bcf\u6b21\u5faa\u73af\u52a0\u8f7d\u5f53\u524dtile\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;                  // 0..3\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u56db\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 4;                  // 0..3\uff0c\u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,4,8,12)\n        int a_local_row = tid_y * 4 + a_row_sel;    // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;           // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = k_tile + local_k_base + 0;\n            int gk1 = k_tile + local_k_base + 1;\n            int gk2 = k_tile + local_k_base + 2;\n            int gk3 = k_tile + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub[local_k_base + 0][a_local_row] = a4.x;\n        Asub[local_k_base + 1][a_local_row] = a4.y;\n        Asub[local_k_base + 2][a_local_row] = a4.z;\n        Asub[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = k_tile + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub[tid_y][b_c0_local] = b4.x;\n        Bsub[tid_y][b_c1_local] = b4.y;\n        Bsub[tid_y][b_c2_local] = b4.z;\n        Bsub[tid_y][b_c3_local] = b4.w;\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524dK\u5b50\u5757\u7684\u6570\u636e\u52a0\u8f7d\n        __syncthreads();\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub[k + 0][a_r0_local];\n                float a1 = Asub[k + 0][a_r1_local];\n                float a2 = Asub[k + 0][a_r2_local];\n                float a3 = Asub[k + 0][a_r3_local];\n\n                float b0 = Bsub[k + 0][b_c0_local];\n                float b1 = Bsub[k + 0][b_c1_local];\n                float b2 = Bsub[k + 0][b_c2_local];\n                float b3 = Bsub[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub[k + 1][a_r0_local];\n                float a1 = Asub[k + 1][a_r1_local];\n                float a2 = Asub[k + 1][a_r2_local];\n                float a3 = Asub[k + 1][a_r3_local];\n\n                float b0 = Bsub[k + 1][b_c0_local];\n                float b1 = Bsub[k + 1][b_c1_local];\n                float b2 = Bsub[k + 1][b_c2_local];\n                float b3 = Bsub[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub[k + 2][a_r0_local];\n                float a1 = Asub[k + 2][a_r1_local];\n                float a2 = Asub[k + 2][a_r2_local];\n                float a3 = Asub[k + 2][a_r3_local];\n\n                float b0 = Bsub[k + 2][b_c0_local];\n                float b1 = Bsub[k + 2][b_c1_local];\n                float b2 = Bsub[k + 2][b_c2_local];\n                float b3 = Bsub[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub[k + 3][a_r0_local];\n                float a1 = Asub[k + 3][a_r1_local];\n                float a2 = Asub[k + 3][a_r2_local];\n                float a3 = Asub[k + 3][a_r3_local];\n\n                float b0 = Bsub[k + 3][b_c0_local];\n                float b1 = Bsub[k + 3][b_c1_local];\n                float b2 = Bsub[k + 3][b_c2_local];\n                float b3 = Bsub[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\uff0c\u907f\u514d\u4e0e\u4e0b\u4e00\u6b21\u52a0\u8f7d\u5171\u4eab\u5185\u5b58\u65f6\u53d1\u751f\u6570\u636e\u7ade\u4e89\n        __syncthreads();\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 10,
    "goal": "Remove the complex Morton ordering and double buffering overhead entirely, implementing a straightforward row-major block distribution with simplified shared memory tiling to maximize computational throughput and reduce control flow overhead.",
    "status": "Failed (Performance Regression)",
    "time_ms": 11.891609954833985,
    "ptxas_metrics": {
      "registers_used": 48.0,
      "shared_mem_bytes": 2048.0,
      "spill_bytes": 0.0
    },
    "details": "New time 11.892 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Simple row-major block mapping\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int block_row_base = blockIdx.y * BLOCK_SIZE;\n    int block_col_base = blockIdx.x * BLOCK_SIZE;\n\n    // Shared memory tiles (16x16 each)\n    __shared__ float Asub[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub[BLOCK_SIZE][BLOCK_SIZE];\n\n    // 4x4 per-thread output tile coordinates (relative to block)\n    // Only threads where tid_x % 4 == 0 and tid_y % 4 == 0 will compute a 4x4 micro-tile\n    bool active = ((tid_x & 3) == 0) && ((tid_y & 3) == 0);\n\n    int r0 = block_row_base + tid_y + 0;\n    int r1 = block_row_base + tid_y + 1;\n    int r2 = block_row_base + tid_y + 2;\n    int r3 = block_row_base + tid_y + 3;\n\n    int c0 = block_col_base + tid_x + 0;\n    int c1 = block_col_base + tid_x + 1;\n    int c2 = block_col_base + tid_x + 2;\n    int c3 = block_col_base + tid_x + 3;\n\n    // 4x4 register accumulators\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // Loop over K dimension tiles of size BLOCK_SIZE\n    for (int k0 = 0; k0 < N; k0 += BLOCK_SIZE) {\n        // Each thread loads one element of A and one of B into shared memory\n        int aRow = block_row_base + tid_y;\n        int aCol = k0 + tid_x;\n        if (aRow < N && aCol < N) {\n            Asub[tid_y][tid_x] = A[aRow * N + aCol];\n        } else {\n            Asub[tid_y][tid_x] = 0.0f;\n        }\n\n        int bRow = k0 + tid_y;\n        int bCol = block_col_base + tid_x;\n        if (bRow < N && bCol < N) {\n            Bsub[tid_y][tid_x] = B[bRow * N + bCol];\n        } else {\n            Bsub[tid_y][tid_x] = 0.0f;\n        }\n\n        __syncthreads();\n\n        // Compute using the loaded tiles\n        if (active) {\n            #pragma unroll\n            for (int t = 0; t < BLOCK_SIZE; ++t) {\n                float a0 = Asub[tid_y + 0][t];\n                float a1 = Asub[tid_y + 1][t];\n                float a2 = Asub[tid_y + 2][t];\n                float a3 = Asub[tid_y + 3][t];\n\n                float b0 = Bsub[t][tid_x + 0];\n                float b1 = Bsub[t][tid_x + 1];\n                float b2 = Bsub[t][tid_x + 2];\n                float b3 = Bsub[t][tid_x + 3];\n\n                acc00 += a0 * b0;\n                acc01 += a0 * b1;\n                acc02 += a0 * b2;\n                acc03 += a0 * b3;\n\n                acc10 += a1 * b0;\n                acc11 += a1 * b1;\n                acc12 += a1 * b2;\n                acc13 += a1 * b3;\n\n                acc20 += a2 * b0;\n                acc21 += a2 * b1;\n                acc22 += a2 * b2;\n                acc23 += a2 * b3;\n\n                acc30 += a3 * b0;\n                acc31 += a3 * b1;\n                acc32 += a3 * b2;\n                acc33 += a3 * b3;\n            }\n        }\n\n        __syncthreads();\n    }\n\n    // Write back results with boundary checks\n    if (active) {\n        if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n        if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n        if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n        if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n        if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n        if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n        if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n        if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n        if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n        if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n        if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n        if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n        if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n        if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n        if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n        if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n    }\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 11,
    "goal": "Optimize the kernel by removing the complex Morton ordering and double buffering overhead while maintaining the 4x4 per-thread tiling and vectorized loads, focusing on maximizing pure computational throughput and minimizing control flow divergence through a straightforward row-major block distribution with simplified shared memory tiling.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5597567558288574,
    "ptxas_metrics": {
      "registers_used": 57.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.560 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5355\u7f13\u51b2\u5171\u4eab\u5185\u5b58\uff0c\u7ef4\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u5e03\u5c40\n    __shared__ float Asub[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // \u884c\u4e3b\u5e8f\u5757\u6620\u5c04\uff0c\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    int tile_row_base = static_cast<int>(blockIdx.y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(blockIdx.x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff1a\u52a0\u8f7d -> \u540c\u6b65 -> \u8ba1\u7b97 -> \u540c\u6b65\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;                 // 0..3\uff0c\u9009\u62e9\u672c\u7ebf\u7a0b\u7684\u56db\u884c\u4e2d\u7684\u54ea\u4e00\u884c\n        int a_vec_seg = tid_x % 4;                 // 0..3\uff0c\u5bf9\u5e94K\u5b50\u5757\u5185\u7684\u6bb5(0,4,8,12)\n        int a_local_row = tid_y * 4 + a_row_sel;   // 0..63\n        int g_row = tile_row_base + a_local_row;   // \u5168\u5c40\u884c\n        int local_k_base = a_vec_seg * 4;          // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = k_tile + local_k_base + 0;\n            int gk1 = k_tile + local_k_base + 1;\n            int gk2 = k_tile + local_k_base + 2;\n            int gk3 = k_tile + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n        Asub[local_k_base + 0][a_local_row] = a4.x;\n        Asub[local_k_base + 1][a_local_row] = a4.y;\n        Asub[local_k_base + 2][a_local_row] = a4.z;\n        Asub[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = k_tile + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n        Bsub[tid_y][b_c0_local] = b4.x;\n        Bsub[tid_y][b_c1_local] = b4.y;\n        Bsub[tid_y][b_c2_local] = b4.z;\n        Bsub[tid_y][b_c3_local] = b4.w;\n\n        __syncthreads();\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub[k + 0][a_r0_local];\n                float a1 = Asub[k + 0][a_r1_local];\n                float a2 = Asub[k + 0][a_r2_local];\n                float a3 = Asub[k + 0][a_r3_local];\n\n                float b0 = Bsub[k + 0][b_c0_local];\n                float b1 = Bsub[k + 0][b_c1_local];\n                float b2 = Bsub[k + 0][b_c2_local];\n                float b3 = Bsub[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub[k + 1][a_r0_local];\n                float a1 = Asub[k + 1][a_r1_local];\n                float a2 = Asub[k + 1][a_r2_local];\n                float a3 = Asub[k + 1][a_r3_local];\n\n                float b0 = Bsub[k + 1][b_c0_local];\n                float b1 = Bsub[k + 1][b_c1_local];\n                float b2 = Bsub[k + 1][b_c2_local];\n                float b3 = Bsub[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub[k + 2][a_r0_local];\n                float a1 = Asub[k + 2][a_r1_local];\n                float a2 = Asub[k + 2][a_r2_local];\n                float a3 = Asub[k + 2][a_r3_local];\n\n                float b0 = Bsub[k + 2][b_c0_local];\n                float b1 = Bsub[k + 2][b_c1_local];\n                float b2 = Bsub[k + 2][b_c2_local];\n                float b3 = Bsub[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub[k + 3][a_r0_local];\n                float a1 = Asub[k + 3][a_r1_local];\n                float a2 = Asub[k + 3][a_r2_local];\n                float a3 = Asub[k + 3][a_r3_local];\n\n                float b0 = Bsub[k + 3][b_c0_local];\n                float b1 = Bsub[k + 3][b_c1_local];\n                float b2 = Bsub[k + 3][b_c2_local];\n                float b3 = Bsub[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        __syncthreads();\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 12,
    "goal": "Optimize memory access efficiency by implementing a pure row-major block distribution with simplified shared memory tiling, focusing on maximizing sustained global memory bandwidth utilization through coalesced accesses and minimizing control flow divergence from Morton ordering complexity.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.6994304656982422,
    "ptxas_metrics": {
      "registers_used": 61.0,
      "shared_mem_bytes": 8512.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.699 ms is not better than best time 1.505 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding (unused now but kept for compatibility)\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Row-major 64x64 tiling with 16x16 threads. Each thread computes a 4x4 sub-tile.\n    // Single-buffer shared memory with padding to reduce bank conflicts.\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n\n    // Shared tiles: A_tile is 64x16, B_tile is 16x64\n    __shared__ float Asub[4 * BLOCK_SIZE][BLOCK_SIZE + 1];\n    __shared__ float Bsub[BLOCK_SIZE][4 * BLOCK_SIZE + 1];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // Compute row-major tile mapping from a linearized block id.\n    uint32_t num_tiles_x = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t num_tiles_y = (N + TILE_SIZE - 1) / TILE_SIZE;\n    uint32_t total_tiles  = num_tiles_x * num_tiles_y;\n\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    uint32_t tile_x = (num_tiles_x > 0) ? (block_id % num_tiles_x) : 0;\n    uint32_t tile_y = (num_tiles_x > 0) ? (block_id / num_tiles_x) : 0;\n\n    int tile_row_base = static_cast<int>(tile_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_x) * TILE_SIZE;\n\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // Per-thread 4x4 output coordinates within the 64x64 tile\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // 4x4 accumulators\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // Loop over K dimension in tiles of size BLOCK_SIZE (16)\n    for (int k0 = 0; k0 < N; k0 += BLOCK_SIZE) {\n\n        // Load A tile (64x16) into shared memory using float4 when possible\n        // Thread mapping for A load:\n        //  - a_row_local_load in [0,63] via: tid_y*4 + (tid_x >> 2)\n        //  - k_vec segment in [0,3] via: tid_x & 3\n        int a_row_local_load = tid_y * 4 + (tid_x >> 2); // 0..63\n        int a_grow = tile_row_base + a_row_local_load;\n\n        int a_k_vec = (tid_x & 3); // 0..3\n        int a_k_base = k0 + a_k_vec * 4;\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (a_grow < N) {\n            if (a_k_base + 3 < N) {\n                // Vectorized load across K dimension\n                const float* a_ptr = &A[a_grow * N + a_k_base];\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                // Boundary-safe scalar loads\n                a4.x = (a_k_base + 0 < N) ? A[a_grow * N + (a_k_base + 0)] : 0.0f;\n                a4.y = (a_k_base + 1 < N) ? A[a_grow * N + (a_k_base + 1)] : 0.0f;\n                a4.z = (a_k_base + 2 < N) ? A[a_grow * N + (a_k_base + 2)] : 0.0f;\n                a4.w = (a_k_base + 3 < N) ? A[a_grow * N + (a_k_base + 3)] : 0.0f;\n            }\n        }\n        // Store into shared with padding on second dimension\n        Asub[a_row_local_load][a_k_vec * 4 + 0] = a4.x;\n        Asub[a_row_local_load][a_k_vec * 4 + 1] = a4.y;\n        Asub[a_row_local_load][a_k_vec * 4 + 2] = a4.z;\n        Asub[a_row_local_load][a_k_vec * 4 + 3] = a4.w;\n\n        // Load B tile (16x64) into shared memory using float4 when possible\n        // Thread mapping for B load:\n        //  - b_row_local_load in [0,15] via: tid_y\n        //  - b_col_base_local_load in [0,63] via: tid_x * 4\n        int b_row_local_load = tid_y;                 // 0..15\n        int b_col_base_local_load = tid_x * 4;        // 0..60\n        int b_grow = k0 + b_row_local_load;\n        int b_gcol = tile_col_base + b_col_base_local_load;\n\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (b_grow < N) {\n            if (b_gcol + 3 < N) {\n                const float* b_ptr = &B[b_grow * N + b_gcol];\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (b_gcol + 0 < N) ? B[b_grow * N + (b_gcol + 0)] : 0.0f;\n                b4.y = (b_gcol + 1 < N) ? B[b_grow * N + (b_gcol + 1)] : 0.0f;\n                b4.z = (b_gcol + 2 < N) ? B[b_grow * N + (b_gcol + 2)] : 0.0f;\n                b4.w = (b_gcol + 3 < N) ? B[b_grow * N + (b_gcol + 3)] : 0.0f;\n            }\n        }\n        // Store into shared with padding on second dimension\n        Bsub[b_row_local_load][b_col_base_local_load + 0] = b4.x;\n        Bsub[b_row_local_load][b_col_base_local_load + 1] = b4.y;\n        Bsub[b_row_local_load][b_col_base_local_load + 2] = b4.z;\n        Bsub[b_row_local_load][b_col_base_local_load + 3] = b4.w;\n\n        __syncthreads();\n\n        // Compute this block's partial results\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; ++k) {\n            float a0 = Asub[a_r0_local][k];\n            float a1 = Asub[a_r1_local][k];\n            float a2 = Asub[a_r2_local][k];\n            float a3 = Asub[a_r3_local][k];\n\n            float b0 = Bsub[k][b_c0_local];\n            float b1 = Bsub[k][b_c1_local];\n            float b2 = Bsub[k][b_c2_local];\n            float b3 = Bsub[k][b_c3_local];\n\n            acc00 += a0 * b0; acc01 += a0 * b1; acc02 += a0 * b2; acc03 += a0 * b3;\n            acc10 += a1 * b0; acc11 += a1 * b1; acc12 += a1 * b2; acc13 += a1 * b3;\n            acc20 += a2 * b0; acc21 += a2 * b1; acc22 += a2 * b2; acc23 += a2 * b3;\n            acc30 += a3 * b0; acc31 += a3 * b1; acc32 += a3 * b2; acc33 += a3 * b3;\n        }\n\n        __syncthreads();\n    }\n\n    // Write back results with boundary checks\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 13,
    "goal": "Optimize the block mapping strategy by implementing a simplified, more efficient Morton ordering approach that minimizes branching overhead while maintaining good spatial locality, focusing on reducing control flow divergence to improve L2 cache utilization and memory throughput.",
    "status": "Success (New Best)",
    "time_ms": 1.5033344268798827,
    "ptxas_metrics": {
      "registers_used": 55.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "Performance improved from 1.505 ms to 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u4fdd\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u4e0e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4e0d\u53d8\uff0c\u4ec5\u7b80\u5316\u4e86\u7ebf\u7a0b\u5757\u5230\u8f93\u51fatile\u7684Z-order\u6620\u5c04\u903b\u8f91\uff1a\n    //  - \u4f7f\u7528\u5355\u4e00\u7684Morton\u66f2\u7ebf\u8986\u76d6\u5305\u542b(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42\u65b9\u5f62\u533a\u57dfP\u00d7P\n    //  - \u901a\u8fc7\u5728\u56db\u53c9\u6811\u5c42\u7ea7\u4e0a\u8fdb\u884c\u201c\u9009\u62e9\u201d\u64cd\u4f5c\uff08\u6309\u56db\u8c61\u9650\u8ba1\u6570\uff09\u5c06block_id\u6620\u5c04\u5230\u77e9\u5f62\u5185\u7b2cidx\u4e2aZ\u5e8f\u4f4d\u7f6e\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    // \u6bcf\u5c42\u53ea\u5305\u542b\u5c11\u91cf\u7b97\u672f\u4e0e\u6bd4\u8f83\uff0c\u4e14\u6240\u6709\u7ebf\u7a0b\u5757\u5185\u7ebf\u7a0b\u6267\u884c\u4e00\u81f4\uff0c\u907f\u514d\u7ebf\u7a0b\u5185\u5206\u6b67\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 14,
    "goal": "Optimize memory access patterns by increasing data reuse through larger tile sizes (e.g., 128x128) while maintaining the successful Morton ordering and double buffering approach, focusing on reducing the DRAM-to-L2 throughput ratio by maximizing shared memory utilization and minimizing global memory transactions.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.8870271682739257,
    "ptxas_metrics": {
      "registers_used": 121.0,
      "shared_mem_bytes": 32768.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.887 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u6bcf\u7ebf\u7a0b\u8ba1\u7b978x8\u8f93\u51fa + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 8 * BLOCK_SIZE; // 128\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d6128x128\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        uint32_t w0 = (w_rem < half) ? w_rem : half;\n        uint32_t h0 = (h_rem < half) ? h_rem : half;\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;\n\n        uint32_t c00 = w0 * h0;\n        uint32_t c10 = w1 * h0;\n        uint32_t c01 = w0 * h1;\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0; size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0; size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1; size = half;\n            continue;\n        }\n        idx -= c01;\n\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d6128x128\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76848x8\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 8 + 0;\n    int a_r1_local = tid_y * 8 + 1;\n    int a_r2_local = tid_y * 8 + 2;\n    int a_r3_local = tid_y * 8 + 3;\n    int a_r4_local = tid_y * 8 + 4;\n    int a_r5_local = tid_y * 8 + 5;\n    int a_r6_local = tid_y * 8 + 6;\n    int a_r7_local = tid_y * 8 + 7;\n\n    int b_c0_local = tid_x * 8 + 0;\n    int b_c1_local = tid_x * 8 + 1;\n    int b_c2_local = tid_x * 8 + 2;\n    int b_c3_local = tid_x * 8 + 3;\n    int b_c4_local = tid_x * 8 + 4;\n    int b_c5_local = tid_x * 8 + 5;\n    int b_c6_local = tid_x * 8 + 6;\n    int b_c7_local = tid_x * 8 + 7;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n    int r4 = tile_row_base + a_r4_local;\n    int r5 = tile_row_base + a_r5_local;\n    int r6 = tile_row_base + a_r6_local;\n    int r7 = tile_row_base + a_r7_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n    int c4 = tile_col_base + b_c4_local;\n    int c5 = tile_col_base + b_c5_local;\n    int c6 = tile_col_base + b_c6_local;\n    int c7 = tile_col_base + b_c7_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76848x8\u7d2f\u52a0\u5668\n    float acc[8][8];\n#pragma unroll\n    for (int i = 0; i < 8; ++i) {\n#pragma unroll\n        for (int j = 0; j < 8; ++j) {\n            acc[i][j] = 0.0f;\n        }\n    }\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[8 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[8 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[8 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[8 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff0cA/B\u54042\u4e2afloat4\u6bcf\u7ebf\u7a0b\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e24\u884c\uff08\u76f8\u5dee+64\uff09\u7684\u5404\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row0 = tid_y * 4 + a_row_sel;     // 0..63\n        int a_local_row1 = a_local_row0 + 64;         // 64..127\n        int g_row0 = tile_row_base + a_local_row0;\n        int g_row1 = tile_row_base + a_local_row1;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        // row0\n        float4 a4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row0 < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr0 = &A[g_row0 * N + gk0];\n            uintptr_t aline0 = reinterpret_cast<uintptr_t>(a_ptr0);\n            if (gk3 < N && (aline0 % 16 == 0)) {\n                a4_0 = *reinterpret_cast<const float4*>(a_ptr0);\n            } else {\n                a4_0.x = (gk0 < N) ? A[g_row0 * N + gk0] : 0.0f;\n                a4_0.y = (gk1 < N) ? A[g_row0 * N + gk1] : 0.0f;\n                a4_0.z = (gk2 < N) ? A[g_row0 * N + gk2] : 0.0f;\n                a4_0.w = (gk3 < N) ? A[g_row0 * N + gk3] : 0.0f;\n            }\n        }\n        Asub_curr[local_k_base + 0][a_local_row0] = a4_0.x;\n        Asub_curr[local_k_base + 1][a_local_row0] = a4_0.y;\n        Asub_curr[local_k_base + 2][a_local_row0] = a4_0.z;\n        Asub_curr[local_k_base + 3][a_local_row0] = a4_0.w;\n\n        // row1 (+64)\n        float4 a4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row1 < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr1 = &A[g_row1 * N + gk0];\n            uintptr_t aline1 = reinterpret_cast<uintptr_t>(a_ptr1);\n            if (gk3 < N && (aline1 % 16 == 0)) {\n                a4_1 = *reinterpret_cast<const float4*>(a_ptr1);\n            } else {\n                a4_1.x = (gk0 < N) ? A[g_row1 * N + gk0] : 0.0f;\n                a4_1.y = (gk1 < N) ? A[g_row1 * N + gk1] : 0.0f;\n                a4_1.z = (gk2 < N) ? A[g_row1 * N + gk2] : 0.0f;\n                a4_1.w = (gk3 < N) ? A[g_row1 * N + gk3] : 0.0f;\n            }\n        }\n        Asub_curr[local_k_base + 0][a_local_row1] = a4_1.x;\n        Asub_curr[local_k_base + 1][a_local_row1] = a4_1.y;\n        Asub_curr[local_k_base + 2][a_local_row1] = a4_1.z;\n        Asub_curr[local_k_base + 3][a_local_row1] = a4_1.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e24\u6bb5float4\uff08\u5217\u8fde\u7eed\uff09\uff0c\u8986\u76d68\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 b4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            // first 4 columns\n            const float* b_ptr0 = &B[kB * N + c0];\n            uintptr_t bline0 = reinterpret_cast<uintptr_t>(b_ptr0);\n            if ((c3 < N) && (bline0 % 16 == 0)) {\n                b4_0 = *reinterpret_cast<const float4*>(b_ptr0);\n            } else {\n                b4_0.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4_0.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4_0.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4_0.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n            // next 4 columns\n            const float* b_ptr1 = &B[kB * N + c4];\n            uintptr_t bline1 = reinterpret_cast<uintptr_t>(b_ptr1);\n            if ((c7 < N) && (bline1 % 16 == 0)) {\n                b4_1 = *reinterpret_cast<const float4*>(b_ptr1);\n            } else {\n                b4_1.x = (c4 < N) ? B[kB * N + c4] : 0.0f;\n                b4_1.y = (c5 < N) ? B[kB * N + c5] : 0.0f;\n                b4_1.z = (c6 < N) ? B[kB * N + c6] : 0.0f;\n                b4_1.w = (c7 < N) ? B[kB * N + c7] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4_0.x;\n        Bsub_curr[tid_y][b_c1_local] = b4_0.y;\n        Bsub_curr[tid_y][b_c2_local] = b4_0.z;\n        Bsub_curr[tid_y][b_c3_local] = b4_0.w;\n        Bsub_curr[tid_y][b_c4_local] = b4_1.x;\n        Bsub_curr[tid_y][b_c5_local] = b4_1.y;\n        Bsub_curr[tid_y][b_c6_local] = b4_1.z;\n        Bsub_curr[tid_y][b_c7_local] = b4_1.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            #pragma unroll\n            for (int t = 0; t < 4; ++t) {\n                float a_vec[8];\n                float b_vec[8];\n\n                a_vec[0] = Asub_curr[k + t][a_r0_local];\n                a_vec[1] = Asub_curr[k + t][a_r1_local];\n                a_vec[2] = Asub_curr[k + t][a_r2_local];\n                a_vec[3] = Asub_curr[k + t][a_r3_local];\n                a_vec[4] = Asub_curr[k + t][a_r4_local];\n                a_vec[5] = Asub_curr[k + t][a_r5_local];\n                a_vec[6] = Asub_curr[k + t][a_r6_local];\n                a_vec[7] = Asub_curr[k + t][a_r7_local];\n\n                b_vec[0] = Bsub_curr[k + t][b_c0_local];\n                b_vec[1] = Bsub_curr[k + t][b_c1_local];\n                b_vec[2] = Bsub_curr[k + t][b_c2_local];\n                b_vec[3] = Bsub_curr[k + t][b_c3_local];\n                b_vec[4] = Bsub_curr[k + t][b_c4_local];\n                b_vec[5] = Bsub_curr[k + t][b_c5_local];\n                b_vec[6] = Bsub_curr[k + t][b_c6_local];\n                b_vec[7] = Bsub_curr[k + t][b_c7_local];\n\n                #pragma unroll\n                for (int i = 0; i < 8; ++i) {\n                    float av = a_vec[i];\n                    #pragma unroll\n                    for (int j = 0; j < 8; ++j) {\n                        acc[i][j] += av * b_vec[j];\n                    }\n                }\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile - two rows per thread (0..63 and +64)\n            int a_row_sel = tid_x / 4;                  // 0..3\n            int a_vec_seg = tid_x % 4;                  // 0..3\n            int a_local_row0 = tid_y * 4 + a_row_sel;   // 0..63\n            int a_local_row1 = a_local_row0 + 64;       // 64..127\n            int g_row0 = tile_row_base + a_local_row0;\n            int g_row1 = tile_row_base + a_local_row1;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row0 < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n0 = &A[g_row0 * N + gk0];\n                uintptr_t aline_n0 = reinterpret_cast<uintptr_t>(a_ptr_n0);\n                if (gk3 < N && (aline_n0 % 16 == 0)) {\n                    a4n_0 = *reinterpret_cast<const float4*>(a_ptr_n0);\n                } else {\n                    a4n_0.x = (gk0 < N) ? A[g_row0 * N + gk0] : 0.0f;\n                    a4n_0.y = (gk1 < N) ? A[g_row0 * N + gk1] : 0.0f;\n                    a4n_0.z = (gk2 < N) ? A[g_row0 * N + gk2] : 0.0f;\n                    a4n_0.w = (gk3 < N) ? A[g_row0 * N + gk3] : 0.0f;\n                }\n            }\n            Asub_next[local_k_base + 0][a_local_row0] = a4n_0.x;\n            Asub_next[local_k_base + 1][a_local_row0] = a4n_0.y;\n            Asub_next[local_k_base + 2][a_local_row0] = a4n_0.z;\n            Asub_next[local_k_base + 3][a_local_row0] = a4n_0.w;\n\n            float4 a4n_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row1 < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n1 = &A[g_row1 * N + gk0];\n                uintptr_t aline_n1 = reinterpret_cast<uintptr_t>(a_ptr_n1);\n                if (gk3 < N && (aline_n1 % 16 == 0)) {\n                    a4n_1 = *reinterpret_cast<const float4*>(a_ptr_n1);\n                } else {\n                    a4n_1.x = (gk0 < N) ? A[g_row1 * N + gk0] : 0.0f;\n                    a4n_1.y = (gk1 < N) ? A[g_row1 * N + gk1] : 0.0f;\n                    a4n_1.z = (gk2 < N) ? A[g_row1 * N + gk2] : 0.0f;\n                    a4n_1.w = (gk3 < N) ? A[g_row1 * N + gk3] : 0.0f;\n                }\n            }\n            Asub_next[local_k_base + 0][a_local_row1] = a4n_1.x;\n            Asub_next[local_k_base + 1][a_local_row1] = a4n_1.y;\n            Asub_next[local_k_base + 2][a_local_row1] = a4n_1.z;\n            Asub_next[local_k_base + 3][a_local_row1] = a4n_1.w;\n\n            // B next tile - two float4 per thread\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 b4n_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n0 = &B[next_kB * N + c0];\n                uintptr_t bline_n0 = reinterpret_cast<uintptr_t>(b_ptr_n0);\n                if (c3 < N && (bline_n0 % 16 == 0)) {\n                    b4n_0 = *reinterpret_cast<const float4*>(b_ptr_n0);\n                } else {\n                    b4n_0.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n_0.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n_0.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n_0.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n\n                const float* b_ptr_n1 = &B[next_kB * N + c4];\n                uintptr_t bline_n1 = reinterpret_cast<uintptr_t>(b_ptr_n1);\n                if (c7 < N && (bline_n1 % 16 == 0)) {\n                    b4n_1 = *reinterpret_cast<const float4*>(b_ptr_n1);\n                } else {\n                    b4n_1.x = (c4 < N) ? B[next_kB * N + c4] : 0.0f;\n                    b4n_1.y = (c5 < N) ? B[next_kB * N + c5] : 0.0f;\n                    b4n_1.z = (c6 < N) ? B[next_kB * N + c6] : 0.0f;\n                    b4n_1.w = (c7 < N) ? B[next_kB * N + c7] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n_0.x;\n            Bsub_next[tid_y][b_c1_local] = b4n_0.y;\n            Bsub_next[tid_y][b_c2_local] = b4n_0.z;\n            Bsub_next[tid_y][b_c3_local] = b4n_0.w;\n            Bsub_next[tid_y][b_c4_local] = b4n_1.x;\n            Bsub_next[tid_y][b_c5_local] = b4n_1.y;\n            Bsub_next[tid_y][b_c6_local] = b4n_1.z;\n            Bsub_next[tid_y][b_c7_local] = b4n_1.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[8 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[8 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff088x8\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    int r_idx[8] = {r0, r1, r2, r3, r4, r5, r6, r7};\n    int c_idx[8] = {c0, c1, c2, c3, c4, c5, c6, c7};\n#pragma unroll\n    for (int i = 0; i < 8; ++i) {\n        int rr = r_idx[i];\n        if (rr < N) {\n#pragma unroll\n            for (int j = 0; j < 8; ++j) {\n                int cc = c_idx[j];\n                if (cc < N) {\n                    C[rr * N + cc] = acc[i][j];\n                }\n            }\n        }\n    }\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 15,
    "goal": "Optimize data reuse by increasing the per-thread tiling from 4x4 to 8x8 output elements while maintaining the successful Morton ordering and double buffering approach, focusing on reducing global memory transactions per FLOP and improving L2 cache utilization through larger computational intensity.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.9543039321899414,
    "ptxas_metrics": {
      "registers_used": 99.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.954 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 8\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // Per-thread computes an 8x8 output tile\n    // Shared memory double-buffered tiles for A and B:\n    //   Asub/Bsub layout: [K_tile (=BLOCK_SIZE)][Tile_size (=8*BLOCK_SIZE=64)]\n    __shared__ float Asub_ping[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 8 * BLOCK_SIZE; // 64\n    // number of 64x64 tiles needed\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // Flatten blockIdx into a linear id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // Cover rectangle w x h using a Morton-ordered traversal within a P x P quad-tree\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        uint32_t w0 = (w_rem < half) ? w_rem : half;\n        uint32_t h0 = (h_rem < half) ? h_rem : half;\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;\n\n        uint32_t c00 = w0 * h0;\n        uint32_t c10 = w1 * h0;\n        uint32_t c01 = w0 * h1;\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    uint32_t tile_z_x = x_off; // < w\n    uint32_t tile_z_y = y_off; // < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // Per-thread 8x8 output tile local coordinates\n    int a_r0_local = tid_y * 8 + 0;\n    int a_r1_local = tid_y * 8 + 1;\n    int a_r2_local = tid_y * 8 + 2;\n    int a_r3_local = tid_y * 8 + 3;\n    int a_r4_local = tid_y * 8 + 4;\n    int a_r5_local = tid_y * 8 + 5;\n    int a_r6_local = tid_y * 8 + 6;\n    int a_r7_local = tid_y * 8 + 7;\n\n    int b_c0_local = tid_x * 8 + 0;\n    int b_c1_local = tid_x * 8 + 1;\n    int b_c2_local = tid_x * 8 + 2;\n    int b_c3_local = tid_x * 8 + 3;\n    int b_c4_local = tid_x * 8 + 4;\n    int b_c5_local = tid_x * 8 + 5;\n    int b_c6_local = tid_x * 8 + 6;\n    int b_c7_local = tid_x * 8 + 7;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n    int r4 = tile_row_base + a_r4_local;\n    int r5 = tile_row_base + a_r5_local;\n    int r6 = tile_row_base + a_r6_local;\n    int r7 = tile_row_base + a_r7_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n    int c4 = tile_col_base + b_c4_local;\n    int c5 = tile_col_base + b_c5_local;\n    int c6 = tile_col_base + b_c6_local;\n    int c7 = tile_col_base + b_c7_local;\n\n    // Accumulators for 8x8 per-thread output\n    float acc[8][8];\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) {\n        #pragma unroll\n        for (int j = 0; j < 8; ++j) {\n            acc[i][j] = 0.0f;\n        }\n    }\n\n    // Current and next shared buffers\n    float (*Asub_curr)[8 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[8 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[8 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[8 * BLOCK_SIZE] = Bsub_pong;\n\n    // Helper arrays of row/col locals\n    int a_rows_local[8] = {a_r0_local, a_r1_local, a_r2_local, a_r3_local, a_r4_local, a_r5_local, a_r6_local, a_r7_local};\n    int b_cols_local[8] = {b_c0_local, b_c1_local, b_c2_local, b_c3_local, b_c4_local, b_c5_local, b_c6_local, b_c7_local};\n\n    // Prefetch first K tile (k_tile = 0) into ping buffer\n    {\n        // A: each thread loads the entire K-tile (8 elements) for one row\n        int a_local_row = tid_y * 8 + tid_x; // 0..63\n        int g_row = tile_row_base + a_local_row;\n\n        float4 a4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 a4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            // first 4 k elements\n            int gk0 = 0 + 0;\n            int gk1 = 0 + 1;\n            int gk2 = 0 + 2;\n            int gk3 = 0 + 3;\n            const float* a_ptr0 = &A[g_row * N + gk0];\n            uintptr_t aline0 = reinterpret_cast<uintptr_t>(a_ptr0);\n            if (gk3 < N && (aline0 % 16 == 0)) {\n                a4_0 = *reinterpret_cast<const float4*>(a_ptr0);\n            } else {\n                a4_0.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4_0.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4_0.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4_0.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n            // next 4 k elements\n            int gk4 = 0 + 4;\n            int gk5 = 0 + 5;\n            int gk6 = 0 + 6;\n            int gk7 = 0 + 7;\n            const float* a_ptr1 = &A[g_row * N + gk4];\n            uintptr_t aline1 = reinterpret_cast<uintptr_t>(a_ptr1);\n            if (gk7 < N && (aline1 % 16 == 0)) {\n                a4_1 = *reinterpret_cast<const float4*>(a_ptr1);\n            } else {\n                a4_1.x = (gk4 < N) ? A[g_row * N + gk4] : 0.0f;\n                a4_1.y = (gk5 < N) ? A[g_row * N + gk5] : 0.0f;\n                a4_1.z = (gk6 < N) ? A[g_row * N + gk6] : 0.0f;\n                a4_1.w = (gk7 < N) ? A[g_row * N + gk7] : 0.0f;\n            }\n        }\n\n        Asub_curr[0][a_local_row] = a4_0.x;\n        Asub_curr[1][a_local_row] = a4_0.y;\n        Asub_curr[2][a_local_row] = a4_0.z;\n        Asub_curr[3][a_local_row] = a4_0.w;\n        Asub_curr[4][a_local_row] = a4_1.x;\n        Asub_curr[5][a_local_row] = a4_1.y;\n        Asub_curr[6][a_local_row] = a4_1.z;\n        Asub_curr[7][a_local_row] = a4_1.w;\n\n        // B: each thread loads 8 consecutive columns for one k row\n        int kB = 0 + tid_y;\n        float4 b4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 b4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr0 = &B[kB * N + c0];\n            uintptr_t bline0 = reinterpret_cast<uintptr_t>(b_ptr0);\n            if (c3 < N && (bline0 % 16 == 0)) {\n                b4_0 = *reinterpret_cast<const float4*>(b_ptr0);\n            } else {\n                b4_0.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4_0.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4_0.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4_0.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n            const float* b_ptr1 = &B[kB * N + c4];\n            uintptr_t bline1 = reinterpret_cast<uintptr_t>(b_ptr1);\n            if (c7 < N && (bline1 % 16 == 0)) {\n                b4_1 = *reinterpret_cast<const float4*>(b_ptr1);\n            } else {\n                b4_1.x = (c4 < N) ? B[kB * N + c4] : 0.0f;\n                b4_1.y = (c5 < N) ? B[kB * N + c5] : 0.0f;\n                b4_1.z = (c6 < N) ? B[kB * N + c6] : 0.0f;\n                b4_1.w = (c7 < N) ? B[kB * N + c7] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4_0.x;\n        Bsub_curr[tid_y][b_c1_local] = b4_0.y;\n        Bsub_curr[tid_y][b_c2_local] = b4_0.z;\n        Bsub_curr[tid_y][b_c3_local] = b4_0.w;\n        Bsub_curr[tid_y][b_c4_local] = b4_1.x;\n        Bsub_curr[tid_y][b_c5_local] = b4_1.y;\n        Bsub_curr[tid_y][b_c6_local] = b4_1.z;\n        Bsub_curr[tid_y][b_c7_local] = b4_1.w;\n    }\n\n    __syncthreads();\n\n    // Iterate across K dimension in tiles of BLOCK_SIZE (8)\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // Inner k loop, unrolled by 4\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // offset 0\n            {\n                float a_vals[8];\n                float b_vals[8];\n\n                a_vals[0] = Asub_curr[k + 0][a_r0_local];\n                a_vals[1] = Asub_curr[k + 0][a_r1_local];\n                a_vals[2] = Asub_curr[k + 0][a_r2_local];\n                a_vals[3] = Asub_curr[k + 0][a_r3_local];\n                a_vals[4] = Asub_curr[k + 0][a_r4_local];\n                a_vals[5] = Asub_curr[k + 0][a_r5_local];\n                a_vals[6] = Asub_curr[k + 0][a_r6_local];\n                a_vals[7] = Asub_curr[k + 0][a_r7_local];\n\n                b_vals[0] = Bsub_curr[k + 0][b_c0_local];\n                b_vals[1] = Bsub_curr[k + 0][b_c1_local];\n                b_vals[2] = Bsub_curr[k + 0][b_c2_local];\n                b_vals[3] = Bsub_curr[k + 0][b_c3_local];\n                b_vals[4] = Bsub_curr[k + 0][b_c4_local];\n                b_vals[5] = Bsub_curr[k + 0][b_c5_local];\n                b_vals[6] = Bsub_curr[k + 0][b_c6_local];\n                b_vals[7] = Bsub_curr[k + 0][b_c7_local];\n\n                #pragma unroll\n                for (int i = 0; i < 8; ++i) {\n                    float ai = a_vals[i];\n                    #pragma unroll\n                    for (int j = 0; j < 8; ++j) {\n                        acc[i][j] += ai * b_vals[j];\n                    }\n                }\n            }\n\n            // offset 1\n            {\n                float a_vals[8];\n                float b_vals[8];\n\n                a_vals[0] = Asub_curr[k + 1][a_r0_local];\n                a_vals[1] = Asub_curr[k + 1][a_r1_local];\n                a_vals[2] = Asub_curr[k + 1][a_r2_local];\n                a_vals[3] = Asub_curr[k + 1][a_r3_local];\n                a_vals[4] = Asub_curr[k + 1][a_r4_local];\n                a_vals[5] = Asub_curr[k + 1][a_r5_local];\n                a_vals[6] = Asub_curr[k + 1][a_r6_local];\n                a_vals[7] = Asub_curr[k + 1][a_r7_local];\n\n                b_vals[0] = Bsub_curr[k + 1][b_c0_local];\n                b_vals[1] = Bsub_curr[k + 1][b_c1_local];\n                b_vals[2] = Bsub_curr[k + 1][b_c2_local];\n                b_vals[3] = Bsub_curr[k + 1][b_c3_local];\n                b_vals[4] = Bsub_curr[k + 1][b_c4_local];\n                b_vals[5] = Bsub_curr[k + 1][b_c5_local];\n                b_vals[6] = Bsub_curr[k + 1][b_c6_local];\n                b_vals[7] = Bsub_curr[k + 1][b_c7_local];\n\n                #pragma unroll\n                for (int i = 0; i < 8; ++i) {\n                    float ai = a_vals[i];\n                    #pragma unroll\n                    for (int j = 0; j < 8; ++j) {\n                        acc[i][j] += ai * b_vals[j];\n                    }\n                }\n            }\n\n            // offset 2\n            {\n                float a_vals[8];\n                float b_vals[8];\n\n                a_vals[0] = Asub_curr[k + 2][a_r0_local];\n                a_vals[1] = Asub_curr[k + 2][a_r1_local];\n                a_vals[2] = Asub_curr[k + 2][a_r2_local];\n                a_vals[3] = Asub_curr[k + 2][a_r3_local];\n                a_vals[4] = Asub_curr[k + 2][a_r4_local];\n                a_vals[5] = Asub_curr[k + 2][a_r5_local];\n                a_vals[6] = Asub_curr[k + 2][a_r6_local];\n                a_vals[7] = Asub_curr[k + 2][a_r7_local];\n\n                b_vals[0] = Bsub_curr[k + 2][b_c0_local];\n                b_vals[1] = Bsub_curr[k + 2][b_c1_local];\n                b_vals[2] = Bsub_curr[k + 2][b_c2_local];\n                b_vals[3] = Bsub_curr[k + 2][b_c3_local];\n                b_vals[4] = Bsub_curr[k + 2][b_c4_local];\n                b_vals[5] = Bsub_curr[k + 2][b_c5_local];\n                b_vals[6] = Bsub_curr[k + 2][b_c6_local];\n                b_vals[7] = Bsub_curr[k + 2][b_c7_local];\n\n                #pragma unroll\n                for (int i = 0; i < 8; ++i) {\n                    float ai = a_vals[i];\n                    #pragma unroll\n                    for (int j = 0; j < 8; ++j) {\n                        acc[i][j] += ai * b_vals[j];\n                    }\n                }\n            }\n\n            // offset 3\n            {\n                float a_vals[8];\n                float b_vals[8];\n\n                a_vals[0] = Asub_curr[k + 3][a_r0_local];\n                a_vals[1] = Asub_curr[k + 3][a_r1_local];\n                a_vals[2] = Asub_curr[k + 3][a_r2_local];\n                a_vals[3] = Asub_curr[k + 3][a_r3_local];\n                a_vals[4] = Asub_curr[k + 3][a_r4_local];\n                a_vals[5] = Asub_curr[k + 3][a_r5_local];\n                a_vals[6] = Asub_curr[k + 3][a_r6_local];\n                a_vals[7] = Asub_curr[k + 3][a_r7_local];\n\n                b_vals[0] = Bsub_curr[k + 3][b_c0_local];\n                b_vals[1] = Bsub_curr[k + 3][b_c1_local];\n                b_vals[2] = Bsub_curr[k + 3][b_c2_local];\n                b_vals[3] = Bsub_curr[k + 3][b_c3_local];\n                b_vals[4] = Bsub_curr[k + 3][b_c4_local];\n                b_vals[5] = Bsub_curr[k + 3][b_c5_local];\n                b_vals[6] = Bsub_curr[k + 3][b_c6_local];\n                b_vals[7] = Bsub_curr[k + 3][b_c7_local];\n\n                #pragma unroll\n                for (int i = 0; i < 8; ++i) {\n                    float ai = a_vals[i];\n                    #pragma unroll\n                    for (int j = 0; j < 8; ++j) {\n                        acc[i][j] += ai * b_vals[j];\n                    }\n                }\n            }\n        }\n\n        // Prefetch next K tile into next buffers if available\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_local_row = tid_y * 8 + tid_x; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            float4 a4_0n = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 a4_1n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + 0;\n                int gk1 = k_tile + BLOCK_SIZE + 1;\n                int gk2 = k_tile + BLOCK_SIZE + 2;\n                int gk3 = k_tile + BLOCK_SIZE + 3;\n                const float* a_ptr0n = &A[g_row * N + gk0];\n                uintptr_t aline0n = reinterpret_cast<uintptr_t>(a_ptr0n);\n                if (gk3 < N && (aline0n % 16 == 0)) {\n                    a4_0n = *reinterpret_cast<const float4*>(a_ptr0n);\n                } else {\n                    a4_0n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4_0n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4_0n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4_0n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n\n                int gk4 = k_tile + BLOCK_SIZE + 4;\n                int gk5 = k_tile + BLOCK_SIZE + 5;\n                int gk6 = k_tile + BLOCK_SIZE + 6;\n                int gk7 = k_tile + BLOCK_SIZE + 7;\n                const float* a_ptr1n = &A[g_row * N + gk4];\n                uintptr_t aline1n = reinterpret_cast<uintptr_t>(a_ptr1n);\n                if (gk7 < N && (aline1n % 16 == 0)) {\n                    a4_1n = *reinterpret_cast<const float4*>(a_ptr1n);\n                } else {\n                    a4_1n.x = (gk4 < N) ? A[g_row * N + gk4] : 0.0f;\n                    a4_1n.y = (gk5 < N) ? A[g_row * N + gk5] : 0.0f;\n                    a4_1n.z = (gk6 < N) ? A[g_row * N + gk6] : 0.0f;\n                    a4_1n.w = (gk7 < N) ? A[g_row * N + gk7] : 0.0f;\n                }\n            }\n\n            Asub_next[0][a_local_row] = a4_0n.x;\n            Asub_next[1][a_local_row] = a4_0n.y;\n            Asub_next[2][a_local_row] = a4_0n.z;\n            Asub_next[3][a_local_row] = a4_0n.w;\n            Asub_next[4][a_local_row] = a4_1n.x;\n            Asub_next[5][a_local_row] = a4_1n.y;\n            Asub_next[6][a_local_row] = a4_1n.z;\n            Asub_next[7][a_local_row] = a4_1n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4_0n = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 b4_1n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr0n = &B[next_kB * N + c0];\n                uintptr_t bline0n = reinterpret_cast<uintptr_t>(b_ptr0n);\n                if (c3 < N && (bline0n % 16 == 0)) {\n                    b4_0n = *reinterpret_cast<const float4*>(b_ptr0n);\n                } else {\n                    b4_0n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4_0n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4_0n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4_0n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n                const float* b_ptr1n = &B[next_kB * N + c4];\n                uintptr_t bline1n = reinterpret_cast<uintptr_t>(b_ptr1n);\n                if (c7 < N && (bline1n % 16 == 0)) {\n                    b4_1n = *reinterpret_cast<const float4*>(b_ptr1n);\n                } else {\n                    b4_1n.x = (c4 < N) ? B[next_kB * N + c4] : 0.0f;\n                    b4_1n.y = (c5 < N) ? B[next_kB * N + c5] : 0.0f;\n                    b4_1n.z = (c6 < N) ? B[next_kB * N + c6] : 0.0f;\n                    b4_1n.w = (c7 < N) ? B[next_kB * N + c7] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4_0n.x;\n            Bsub_next[tid_y][b_c1_local] = b4_0n.y;\n            Bsub_next[tid_y][b_c2_local] = b4_0n.z;\n            Bsub_next[tid_y][b_c3_local] = b4_0n.w;\n            Bsub_next[tid_y][b_c4_local] = b4_1n.x;\n            Bsub_next[tid_y][b_c5_local] = b4_1n.y;\n            Bsub_next[tid_y][b_c6_local] = b4_1n.z;\n            Bsub_next[tid_y][b_c7_local] = b4_1n.w;\n        }\n\n        __syncthreads();\n\n        // Swap buffers if we prefetched\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[8 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[8 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // Write back 8x8 results with bounds checks\n    int rr[8] = {r0, r1, r2, r3, r4, r5, r6, r7};\n    int cc[8] = {c0, c1, c2, c3, c4, c5, c6, c7};\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) {\n        if (rr[i] < N) {\n            #pragma unroll\n            for (int j = 0; j < 8; ++j) {\n                if (cc[j] < N) {\n                    C[rr[i] * N + cc[j]] = acc[i][j];\n                }\n            }\n        }\n    }\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 16,
    "goal": "Optimize the shared memory access pattern by transposing one of the shared memory buffers (either A or B) to ensure coalesced accesses during shared memory reads, while maintaining the current Morton ordering, double buffering, and 4x4 per-thread tiling to cure the global memory bandwidth bottleneck by improving memory access efficiency.",
    "status": "Failed (Performance Regression)",
    "time_ms": 6.193664169311523,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 6.194 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u4fdd\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u4e0e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4e0d\u53d8\uff0c\u4ec5\u7b80\u5316\u4e86\u7ebf\u7a0b\u5757\u5230\u8f93\u51fatile\u7684Z-order\u6620\u5c04\u903b\u8f91\uff1a\n    //  - \u4f7f\u7528\u5355\u4e00\u7684Morton\u66f2\u7ebf\u8986\u76d6\u5305\u542b(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42\u65b9\u5f62\u533a\u57dfP\u00d7P\n    //  - \u901a\u8fc7\u5728\u56db\u53c9\u6811\u5c42\u7ea7\u4e0a\u8fdb\u884c\u201c\u9009\u62e9\u201d\u64cd\u4f5c\uff08\u6309\u56db\u8c61\u9650\u8ba1\u6570\uff09\u5c06block_id\u6620\u5c04\u5230\u77e9\u5f62\u5185\u7b2cidx\u4e2aZ\u5e8f\u4f4d\u7f6e\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    // Transposed layout for B in shared memory: [cols (64)][k (16)]\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    // For B, use transposed shared memory layout\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping;\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        // Store transposed into shared memory: [col][k]\n        Bsub_curr[b_c0_local][tid_y] = b4.x;\n        Bsub_curr[b_c1_local][tid_y] = b4.y;\n        Bsub_curr[b_c2_local][tid_y] = b4.z;\n        Bsub_curr[b_c3_local][tid_y] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            // Store transposed into shared memory: [col][k]\n            Bsub_next[b_c0_local][tid_y] = b4n.x;\n            Bsub_next[b_c1_local][tid_y] = b4n.y;\n            Bsub_next[b_c2_local][tid_y] = b4n.z;\n            Bsub_next[b_c3_local][tid_y] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 17,
    "goal": "Optimize shared memory bank conflict patterns by reordering the shared memory layout for matrix B to ensure coalesced accesses during the computation phase, while maintaining the current Morton ordering, double buffering, and 4x4 per-thread tiling to improve L2 cache efficiency and reduce global memory pressure.",
    "status": "Failed (Performance Regression)",
    "time_ms": 6.193356704711914,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 6.193 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u4fdd\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u4e0e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4e0d\u53d8\uff0c\u4ec5\u7b80\u5316\u4e86\u7ebf\u7a0b\u5757\u5230\u8f93\u51fatile\u7684Z-order\u6620\u5c04\u903b\u8f91\uff1a\n    //  - \u4f7f\u7528\u5355\u4e00\u7684Morton\u66f2\u7ebf\u8986\u76d6\u5305\u542b(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42\u65b9\u5f62\u533a\u57dfP\u00d7P\n    //  - \u901a\u8fc7\u5728\u56db\u53c9\u6811\u5c42\u7ea7\u4e0a\u8fdb\u884c\u201c\u9009\u62e9\u201d\u64cd\u4f5c\uff08\u6309\u56db\u8c61\u9650\u8ba1\u6570\uff09\u5c06block_id\u6620\u5c04\u5230\u77e9\u5f62\u5185\u7b2cidx\u4e2aZ\u5e8f\u4f4d\u7f6e\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    // Reorganized B layout to reduce bank conflicts: [4*BLOCK_SIZE][BLOCK_SIZE]\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    // \u6bcf\u5c42\u53ea\u5305\u542b\u5c11\u91cf\u7b97\u672f\u4e0e\u6bd4\u8f83\uff0c\u4e14\u6240\u6709\u7ebf\u7a0b\u5757\u5185\u7ebf\u7a0b\u6267\u884c\u4e00\u81f4\uff0c\u907f\u514d\u7ebf\u7a0b\u5185\u5206\u6b67\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    // Updated pointer types for transposed B layout\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        // Store into transposed shared layout for B: [col_in_tile][k_offset]\n        Bsub_curr[b_c0_local][tid_y] = b4.x;\n        Bsub_curr[b_c1_local][tid_y] = b4.y;\n        Bsub_curr[b_c2_local][tid_y] = b4.z;\n        Bsub_curr[b_c3_local][tid_y] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            // Store into transposed shared layout for next B tile\n            Bsub_next[b_c0_local][tid_y] = b4n.x;\n            Bsub_next[b_c1_local][tid_y] = b4n.y;\n            Bsub_next[b_c2_local][tid_y] = b4n.z;\n            Bsub_next[b_c3_local][tid_y] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 18,
    "goal": "Increase computational intensity by implementing 8x8 per-thread tiling with careful register blocking and shared memory layout optimization, while maintaining the successful Morton ordering and double buffering approach, to reduce the DRAM-to-L2 throughput ratio by maximizing data reuse in registers and shared memory.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.9551231384277343,
    "ptxas_metrics": {
      "registers_used": 100.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.955 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 8\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u6bcf\u7ebf\u7a0b\u8ba1\u7b978x8\u8f93\u51fa + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][8 * BLOCK_SIZE]; // [Ktile=8][Rows=64]\n    __shared__ float Asub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][8 * BLOCK_SIZE]; // [Ktile=8][Cols=64]\n    __shared__ float Bsub_pong[BLOCK_SIZE][8 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 8 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76848x8\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 8 + 0;\n    int a_r1_local = tid_y * 8 + 1;\n    int a_r2_local = tid_y * 8 + 2;\n    int a_r3_local = tid_y * 8 + 3;\n    int a_r4_local = tid_y * 8 + 4;\n    int a_r5_local = tid_y * 8 + 5;\n    int a_r6_local = tid_y * 8 + 6;\n    int a_r7_local = tid_y * 8 + 7;\n\n    int b_c0_local = tid_x * 8 + 0;\n    int b_c1_local = tid_x * 8 + 1;\n    int b_c2_local = tid_x * 8 + 2;\n    int b_c3_local = tid_x * 8 + 3;\n    int b_c4_local = tid_x * 8 + 4;\n    int b_c5_local = tid_x * 8 + 5;\n    int b_c6_local = tid_x * 8 + 6;\n    int b_c7_local = tid_x * 8 + 7;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n    int r4 = tile_row_base + a_r4_local;\n    int r5 = tile_row_base + a_r5_local;\n    int r6 = tile_row_base + a_r6_local;\n    int r7 = tile_row_base + a_r7_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n    int c4 = tile_col_base + b_c4_local;\n    int c5 = tile_col_base + b_c5_local;\n    int c6 = tile_col_base + b_c6_local;\n    int c7 = tile_col_base + b_c7_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76848x8\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f, acc04 = 0.0f, acc05 = 0.0f, acc06 = 0.0f, acc07 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f, acc14 = 0.0f, acc15 = 0.0f, acc16 = 0.0f, acc17 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f, acc24 = 0.0f, acc25 = 0.0f, acc26 = 0.0f, acc27 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f, acc34 = 0.0f, acc35 = 0.0f, acc36 = 0.0f, acc37 = 0.0f;\n    float acc40 = 0.0f, acc41 = 0.0f, acc42 = 0.0f, acc43 = 0.0f, acc44 = 0.0f, acc45 = 0.0f, acc46 = 0.0f, acc47 = 0.0f;\n    float acc50 = 0.0f, acc51 = 0.0f, acc52 = 0.0f, acc53 = 0.0f, acc54 = 0.0f, acc55 = 0.0f, acc56 = 0.0f, acc57 = 0.0f;\n    float acc60 = 0.0f, acc61 = 0.0f, acc62 = 0.0f, acc63 = 0.0f, acc64 = 0.0f, acc65 = 0.0f, acc66 = 0.0f, acc67 = 0.0f;\n    float acc70 = 0.0f, acc71 = 0.0f, acc72 = 0.0f, acc73 = 0.0f, acc74 = 0.0f, acc75 = 0.0f, acc76 = 0.0f, acc77 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[8 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[8 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[8 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[8 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u5176\u8d1f\u8d23\u7684\u4e00\u884c\uff088\u4e2a\u8fde\u7eed\u7684K\u5143\u7d20\uff0c2\u4e2afloat4\uff09 ---\n        int a_load_row = tid_y * 8 + tid_x; // 0..63\n        int g_rowA = tile_row_base + a_load_row;\n\n        float4 a4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 a4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_rowA < N) {\n            int gk0 = 0 + 0;\n            int gk1 = 0 + 1;\n            int gk2 = 0 + 2;\n            int gk3 = 0 + 3;\n            int gk4 = 0 + 4;\n            int gk5 = 0 + 5;\n            int gk6 = 0 + 6;\n            int gk7 = 0 + 7;\n\n            const float* a_ptr0 = &A[g_rowA * N + gk0];\n            uintptr_t aline0 = reinterpret_cast<uintptr_t>(a_ptr0);\n            if (gk3 < N && (aline0 % 16 == 0)) {\n                a4_0 = *reinterpret_cast<const float4*>(a_ptr0);\n            } else {\n                a4_0.x = (gk0 < N) ? A[g_rowA * N + gk0] : 0.0f;\n                a4_0.y = (gk1 < N) ? A[g_rowA * N + gk1] : 0.0f;\n                a4_0.z = (gk2 < N) ? A[g_rowA * N + gk2] : 0.0f;\n                a4_0.w = (gk3 < N) ? A[g_rowA * N + gk3] : 0.0f;\n            }\n\n            const float* a_ptr1 = &A[g_rowA * N + gk4];\n            uintptr_t aline1 = reinterpret_cast<uintptr_t>(a_ptr1);\n            if (gk7 < N && (aline1 % 16 == 0)) {\n                a4_1 = *reinterpret_cast<const float4*>(a_ptr1);\n            } else {\n                a4_1.x = (gk4 < N) ? A[g_rowA * N + gk4] : 0.0f;\n                a4_1.y = (gk5 < N) ? A[g_rowA * N + gk5] : 0.0f;\n                a4_1.z = (gk6 < N) ? A[g_rowA * N + gk6] : 0.0f;\n                a4_1.w = (gk7 < N) ? A[g_rowA * N + gk7] : 0.0f;\n            }\n        }\n\n        Asub_curr[0][a_load_row] = a4_0.x;\n        Asub_curr[1][a_load_row] = a4_0.y;\n        Asub_curr[2][a_load_row] = a4_0.z;\n        Asub_curr[3][a_load_row] = a4_0.w;\n        Asub_curr[4][a_load_row] = a4_1.x;\n        Asub_curr[5][a_load_row] = a4_1.y;\n        Asub_curr[6][a_load_row] = a4_1.z;\n        Asub_curr[7][a_load_row] = a4_1.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u5176tid_y\u5bf9\u5e94\u7684K\u884c\u4e0a8\u4e2a\u8fde\u7eed\u5217\uff082\u4e2afloat4\uff09 ---\n        int kB = 0 + tid_y;\n        float4 b4_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 b4_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n        int col_base = tile_col_base + tid_x * 8;\n\n        if (kB < N) {\n            const float* b_ptr0 = &B[kB * N + col_base + 0];\n            uintptr_t bline0 = reinterpret_cast<uintptr_t>(b_ptr0);\n            if ((col_base + 3) < N && (bline0 % 16 == 0)) {\n                b4_0 = *reinterpret_cast<const float4*>(b_ptr0);\n            } else {\n                b4_0.x = ((col_base + 0) < N) ? B[kB * N + (col_base + 0)] : 0.0f;\n                b4_0.y = ((col_base + 1) < N) ? B[kB * N + (col_base + 1)] : 0.0f;\n                b4_0.z = ((col_base + 2) < N) ? B[kB * N + (col_base + 2)] : 0.0f;\n                b4_0.w = ((col_base + 3) < N) ? B[kB * N + (col_base + 3)] : 0.0f;\n            }\n\n            const float* b_ptr1 = &B[kB * N + col_base + 4];\n            uintptr_t bline1 = reinterpret_cast<uintptr_t>(b_ptr1);\n            if ((col_base + 7) < N && (bline1 % 16 == 0)) {\n                b4_1 = *reinterpret_cast<const float4*>(b_ptr1);\n            } else {\n                b4_1.x = ((col_base + 4) < N) ? B[kB * N + (col_base + 4)] : 0.0f;\n                b4_1.y = ((col_base + 5) < N) ? B[kB * N + (col_base + 5)] : 0.0f;\n                b4_1.z = ((col_base + 6) < N) ? B[kB * N + (col_base + 6)] : 0.0f;\n                b4_1.w = ((col_base + 7) < N) ? B[kB * N + (col_base + 7)] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4_0.x;\n        Bsub_curr[tid_y][b_c1_local] = b4_0.y;\n        Bsub_curr[tid_y][b_c2_local] = b4_0.z;\n        Bsub_curr[tid_y][b_c3_local] = b4_0.w;\n        Bsub_curr[tid_y][b_c4_local] = b4_1.x;\n        Bsub_curr[tid_y][b_c5_local] = b4_1.y;\n        Bsub_curr[tid_y][b_c6_local] = b4_1.z;\n        Bsub_curr[tid_y][b_c7_local] = b4_1.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0c\u5904\u74068x8\u5916\u79ef\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; ++k) {\n            float a0 = Asub_curr[k][a_r0_local];\n            float a1 = Asub_curr[k][a_r1_local];\n            float a2 = Asub_curr[k][a_r2_local];\n            float a3 = Asub_curr[k][a_r3_local];\n            float a4 = Asub_curr[k][a_r4_local];\n            float a5 = Asub_curr[k][a_r5_local];\n            float a6 = Asub_curr[k][a_r6_local];\n            float a7 = Asub_curr[k][a_r7_local];\n\n            float b0 = Bsub_curr[k][b_c0_local];\n            float b1 = Bsub_curr[k][b_c1_local];\n            float b2 = Bsub_curr[k][b_c2_local];\n            float b3 = Bsub_curr[k][b_c3_local];\n            float b4 = Bsub_curr[k][b_c4_local];\n            float b5 = Bsub_curr[k][b_c5_local];\n            float b6 = Bsub_curr[k][b_c6_local];\n            float b7 = Bsub_curr[k][b_c7_local];\n\n            // Row 0\n            acc00 += a0 * b0; acc01 += a0 * b1; acc02 += a0 * b2; acc03 += a0 * b3;\n            acc04 += a0 * b4; acc05 += a0 * b5; acc06 += a0 * b6; acc07 += a0 * b7;\n            // Row 1\n            acc10 += a1 * b0; acc11 += a1 * b1; acc12 += a1 * b2; acc13 += a1 * b3;\n            acc14 += a1 * b4; acc15 += a1 * b5; acc16 += a1 * b6; acc17 += a1 * b7;\n            // Row 2\n            acc20 += a2 * b0; acc21 += a2 * b1; acc22 += a2 * b2; acc23 += a2 * b3;\n            acc24 += a2 * b4; acc25 += a2 * b5; acc26 += a2 * b6; acc27 += a2 * b7;\n            // Row 3\n            acc30 += a3 * b0; acc31 += a3 * b1; acc32 += a3 * b2; acc33 += a3 * b3;\n            acc34 += a3 * b4; acc35 += a3 * b5; acc36 += a3 * b6; acc37 += a3 * b7;\n            // Row 4\n            acc40 += a4 * b0; acc41 += a4 * b1; acc42 += a4 * b2; acc43 += a4 * b3;\n            acc44 += a4 * b4; acc45 += a4 * b5; acc46 += a4 * b6; acc47 += a4 * b7;\n            // Row 5\n            acc50 += a5 * b0; acc51 += a5 * b1; acc52 += a5 * b2; acc53 += a5 * b3;\n            acc54 += a5 * b4; acc55 += a5 * b5; acc56 += a5 * b6; acc57 += a5 * b7;\n            // Row 6\n            acc60 += a6 * b0; acc61 += a6 * b1; acc62 += a6 * b2; acc63 += a6 * b3;\n            acc64 += a6 * b4; acc65 += a6 * b5; acc66 += a6 * b6; acc67 += a6 * b7;\n            // Row 7\n            acc70 += a7 * b0; acc71 += a7 * b1; acc72 += a7 * b2; acc73 += a7 * b3;\n            acc74 += a7 * b4; acc75 += a7 * b5; acc76 += a7 * b6; acc77 += a7 * b7;\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u5176\u8d1f\u8d23\u7684\u4e00\u884c\u7684\u4e0b\u4e00\u4e2aK\u5757\uff082\u4e2afloat4\uff09\n            int a_load_row = tid_y * 8 + tid_x; // 0..63\n            int g_rowA = tile_row_base + a_load_row;\n\n            float4 a4n_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 a4n_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_rowA < N) {\n                int gk0 = k_tile + BLOCK_SIZE + 0;\n                int gk1 = k_tile + BLOCK_SIZE + 1;\n                int gk2 = k_tile + BLOCK_SIZE + 2;\n                int gk3 = k_tile + BLOCK_SIZE + 3;\n                int gk4 = k_tile + BLOCK_SIZE + 4;\n                int gk5 = k_tile + BLOCK_SIZE + 5;\n                int gk6 = k_tile + BLOCK_SIZE + 6;\n                int gk7 = k_tile + BLOCK_SIZE + 7;\n\n                const float* a_ptr0_n = &A[g_rowA * N + gk0];\n                uintptr_t aline0_n = reinterpret_cast<uintptr_t>(a_ptr0_n);\n                if (gk3 < N && (aline0_n % 16 == 0)) {\n                    a4n_0 = *reinterpret_cast<const float4*>(a_ptr0_n);\n                } else {\n                    a4n_0.x = (gk0 < N) ? A[g_rowA * N + gk0] : 0.0f;\n                    a4n_0.y = (gk1 < N) ? A[g_rowA * N + gk1] : 0.0f;\n                    a4n_0.z = (gk2 < N) ? A[g_rowA * N + gk2] : 0.0f;\n                    a4n_0.w = (gk3 < N) ? A[g_rowA * N + gk3] : 0.0f;\n                }\n\n                const float* a_ptr1_n = &A[g_rowA * N + gk4];\n                uintptr_t aline1_n = reinterpret_cast<uintptr_t>(a_ptr1_n);\n                if (gk7 < N && (aline1_n % 16 == 0)) {\n                    a4n_1 = *reinterpret_cast<const float4*>(a_ptr1_n);\n                } else {\n                    a4n_1.x = (gk4 < N) ? A[g_rowA * N + gk4] : 0.0f;\n                    a4n_1.y = (gk5 < N) ? A[g_rowA * N + gk5] : 0.0f;\n                    a4n_1.z = (gk6 < N) ? A[g_rowA * N + gk6] : 0.0f;\n                    a4n_1.w = (gk7 < N) ? A[g_rowA * N + gk7] : 0.0f;\n                }\n            }\n\n            Asub_next[0][a_load_row] = a4n_0.x;\n            Asub_next[1][a_load_row] = a4n_0.y;\n            Asub_next[2][a_load_row] = a4n_0.z;\n            Asub_next[3][a_load_row] = a4n_0.w;\n            Asub_next[4][a_load_row] = a4n_1.x;\n            Asub_next[5][a_load_row] = a4n_1.y;\n            Asub_next[6][a_load_row] = a4n_1.z;\n            Asub_next[7][a_load_row] = a4n_1.w;\n\n            // B next tile: \u6bcf\u7ebf\u7a0b\u52a0\u8f7dtid_y\u5bf9\u5e94\u7684\u4e0b\u4e00K\u884c\u76848\u4e2a\u8fde\u7eed\u5217\uff082\u4e2afloat4\uff09\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n_0 = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 b4n_1 = make_float4(0.f, 0.f, 0.f, 0.f);\n            int col_base = tile_col_base + tid_x * 8;\n\n            if (next_kB < N) {\n                const float* b_ptr0_n = &B[next_kB * N + col_base + 0];\n                uintptr_t bline0_n = reinterpret_cast<uintptr_t>(b_ptr0_n);\n                if ((col_base + 3) < N && (bline0_n % 16 == 0)) {\n                    b4n_0 = *reinterpret_cast<const float4*>(b_ptr0_n);\n                } else {\n                    b4n_0.x = ((col_base + 0) < N) ? B[next_kB * N + (col_base + 0)] : 0.0f;\n                    b4n_0.y = ((col_base + 1) < N) ? B[next_kB * N + (col_base + 1)] : 0.0f;\n                    b4n_0.z = ((col_base + 2) < N) ? B[next_kB * N + (col_base + 2)] : 0.0f;\n                    b4n_0.w = ((col_base + 3) < N) ? B[next_kB * N + (col_base + 3)] : 0.0f;\n                }\n\n                const float* b_ptr1_n = &B[next_kB * N + col_base + 4];\n                uintptr_t bline1_n = reinterpret_cast<uintptr_t>(b_ptr1_n);\n                if ((col_base + 7) < N && (bline1_n % 16 == 0)) {\n                    b4n_1 = *reinterpret_cast<const float4*>(b_ptr1_n);\n                } else {\n                    b4n_1.x = ((col_base + 4) < N) ? B[next_kB * N + (col_base + 4)] : 0.0f;\n                    b4n_1.y = ((col_base + 5) < N) ? B[next_kB * N + (col_base + 5)] : 0.0f;\n                    b4n_1.z = ((col_base + 6) < N) ? B[next_kB * N + (col_base + 6)] : 0.0f;\n                    b4n_1.w = ((col_base + 7) < N) ? B[next_kB * N + (col_base + 7)] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n_0.x;\n            Bsub_next[tid_y][b_c1_local] = b4n_0.y;\n            Bsub_next[tid_y][b_c2_local] = b4n_0.z;\n            Bsub_next[tid_y][b_c3_local] = b4n_0.w;\n            Bsub_next[tid_y][b_c4_local] = b4n_1.x;\n            Bsub_next[tid_y][b_c5_local] = b4n_1.y;\n            Bsub_next[tid_y][b_c6_local] = b4n_1.z;\n            Bsub_next[tid_y][b_c7_local] = b4n_1.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[8 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[8 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff088x8\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n    if (r0 < N && c4 < N) C[r0 * N + c4] = acc04;\n    if (r0 < N && c5 < N) C[r0 * N + c5] = acc05;\n    if (r0 < N && c6 < N) C[r0 * N + c6] = acc06;\n    if (r0 < N && c7 < N) C[r0 * N + c7] = acc07;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n    if (r1 < N && c4 < N) C[r1 * N + c4] = acc14;\n    if (r1 < N && c5 < N) C[r1 * N + c5] = acc15;\n    if (r1 < N && c6 < N) C[r1 * N + c6] = acc16;\n    if (r1 < N && c7 < N) C[r1 * N + c7] = acc17;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n    if (r2 < N && c4 < N) C[r2 * N + c4] = acc24;\n    if (r2 < N && c5 < N) C[r2 * N + c5] = acc25;\n    if (r2 < N && c6 < N) C[r2 * N + c6] = acc26;\n    if (r2 < N && c7 < N) C[r2 * N + c7] = acc27;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n    if (r3 < N && c4 < N) C[r3 * N + c4] = acc34;\n    if (r3 < N && c5 < N) C[r3 * N + c5] = acc35;\n    if (r3 < N && c6 < N) C[r3 * N + c6] = acc36;\n    if (r3 < N && c7 < N) C[r3 * N + c7] = acc37;\n\n    if (r4 < N && c0 < N) C[r4 * N + c0] = acc40;\n    if (r4 < N && c1 < N) C[r4 * N + c1] = acc41;\n    if (r4 < N && c2 < N) C[r4 * N + c2] = acc42;\n    if (r4 < N && c3 < N) C[r4 * N + c3] = acc43;\n    if (r4 < N && c4 < N) C[r4 * N + c4] = acc44;\n    if (r4 < N && c5 < N) C[r4 * N + c5] = acc45;\n    if (r4 < N && c6 < N) C[r4 * N + c6] = acc46;\n    if (r4 < N && c7 < N) C[r4 * N + c7] = acc47;\n\n    if (r5 < N && c0 < N) C[r5 * N + c0] = acc50;\n    if (r5 < N && c1 < N) C[r5 * N + c1] = acc51;\n    if (r5 < N && c2 < N) C[r5 * N + c2] = acc52;\n    if (r5 < N && c3 < N) C[r5 * N + c3] = acc53;\n    if (r5 < N && c4 < N) C[r5 * N + c4] = acc54;\n    if (r5 < N && c5 < N) C[r5 * N + c5] = acc55;\n    if (r5 < N && c6 < N) C[r5 * N + c6] = acc56;\n    if (r5 < N && c7 < N) C[r5 * N + c7] = acc57;\n\n    if (r6 < N && c0 < N) C[r6 * N + c0] = acc60;\n    if (r6 < N && c1 < N) C[r6 * N + c1] = acc61;\n    if (r6 < N && c2 < N) C[r6 * N + c2] = acc62;\n    if (r6 < N && c3 < N) C[r6 * N + c3] = acc63;\n    if (r6 < N && c4 < N) C[r6 * N + c4] = acc64;\n    if (r6 < N && c5 < N) C[r6 * N + c5] = acc65;\n    if (r6 < N && c6 < N) C[r6 * N + c6] = acc66;\n    if (r6 < N && c7 < N) C[r6 * N + c7] = acc67;\n\n    if (r7 < N && c0 < N) C[r7 * N + c0] = acc70;\n    if (r7 < N && c1 < N) C[r7 * N + c1] = acc71;\n    if (r7 < N && c2 < N) C[r7 * N + c2] = acc72;\n    if (r7 < N && c3 < N) C[r7 * N + c3] = acc73;\n    if (r7 < N && c4 < N) C[r7 * N + c4] = acc74;\n    if (r7 < N && c5 < N) C[r7 * N + c5] = acc75;\n    if (r7 < N && c6 < N) C[r7 * N + c6] = acc76;\n    if (r7 < N && c7 < N) C[r7 * N + c7] = acc77;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 19,
    "goal": "Optimize global memory coalescing for matrix B prefetching by ensuring contiguous thread access patterns during the double buffering setup, while maintaining the successful Morton ordering and 4x4 per-thread tiling, to maximize global memory bandwidth efficiency and reduce the DRAM-to-L2 throughput ratio.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.9807231903076172,
    "ptxas_metrics": {
      "registers_used": 55.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.981 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u4fdd\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u4e0e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4e0d\u53d8\uff0c\u4ec5\u7b80\u5316\u4e86\u7ebf\u7a0b\u5757\u5230\u8f93\u51fatile\u7684Z-order\u6620\u5c04\u903b\u8f91\uff1a\n    //  - \u4f7f\u7528\u5355\u4e00\u7684Morton\u66f2\u7ebf\u8986\u76d6\u5305\u542b(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42\u65b9\u5f62\u533a\u57dfP\u00d7P\n    //  - \u901a\u8fc7\u5728\u56db\u53c9\u6811\u5c42\u7ea7\u4e0a\u8fdb\u884c\u201c\u9009\u62e9\u201d\u64cd\u4f5c\uff08\u6309\u56db\u8c61\u9650\u8ba1\u6570\uff09\u5c06block_id\u6620\u5c04\u5230\u77e9\u5f62\u5185\u7b2cidx\u4e2aZ\u5e8f\u4f4d\u7f6e\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    // \u6bcf\u5c42\u53ea\u5305\u542b\u5c11\u91cf\u7b97\u672f\u4e0e\u6bd4\u8f83\uff0c\u4e14\u6240\u6709\u7ebf\u7a0b\u5757\u5185\u7ebf\u7a0b\u6267\u884c\u4e00\u81f4\uff0c\u907f\u514d\u7ebf\u7a0b\u5185\u5206\u6b67\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u4fee\u6539\u4e3a\u4f7f\u7528tid_x\u9009\u62e9K\u7ef4\u884c\uff0ctid_y\u8986\u76d6\u5217\u8303\u56f4\uff08\u5171\u4eab\u5185\u5b58\u6309[k][col]\u5b58\u653e\uff09 ---\n        int kB_local = tid_x;                  // \u672ctile\u5185K\u7ef4\u884c\u7d22\u5f15 [0..BLOCK_SIZE)\n        int kB_global = 0 + kB_local;          // \u5168\u5c40K\u7ef4\u7d22\u5f15\n\n        // \u4f7f\u7528tid_y\u6765\u8986\u76d6\u5217\u65b9\u5411\u7684\u8fde\u7eed4\u4e2a\u5143\u7d20\uff0c\u4fdd\u8bc1\u5728\u5171\u4eab\u5185\u5b58\u4e2d\u5b8c\u6574\u8986\u76d664\u5217\n        int b_store_c0_local = tid_y * 4 + 0;\n        int b_store_c1_local = tid_y * 4 + 1;\n        int b_store_c2_local = tid_y * 4 + 2;\n        int b_store_c3_local = tid_y * 4 + 3;\n\n        int cb0 = tile_col_base + b_store_c0_local;\n        int cb1 = tile_col_base + b_store_c1_local;\n        int cb2 = tile_col_base + b_store_c2_local;\n        int cb3 = tile_col_base + b_store_c3_local;\n\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB_global < N) {\n            const float* b_ptr = &B[kB_global * N + cb0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (cb3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (cb0 < N) ? B[kB_global * N + cb0] : 0.0f;\n                b4.y = (cb1 < N) ? B[kB_global * N + cb1] : 0.0f;\n                b4.z = (cb2 < N) ? B[kB_global * N + cb2] : 0.0f;\n                b4.w = (cb3 < N) ? B[kB_global * N + cb3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[kB_local][b_store_c0_local] = b4.x;\n        Bsub_curr[kB_local][b_store_c1_local] = b4.y;\n        Bsub_curr[kB_local][b_store_c2_local] = b4.z;\n        Bsub_curr[kB_local][b_store_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile: \u4f7f\u7528tid_x\u9009\u62e9K\u7ef4\u884c\uff0ctid_y\u8986\u76d6\u5217\u8303\u56f4\n            int next_kB_local = tid_x;                                    // \u672ctile\u5185K\u884c\n            int next_kB = k_tile + BLOCK_SIZE + next_kB_local;            // \u5168\u5c40K\u7d22\u5f15\n\n            int b_store_c0_local = tid_y * 4 + 0;\n            int b_store_c1_local = tid_y * 4 + 1;\n            int b_store_c2_local = tid_y * 4 + 2;\n            int b_store_c3_local = tid_y * 4 + 3;\n\n            int cb0 = tile_col_base + b_store_c0_local;\n            int cb1 = tile_col_base + b_store_c1_local;\n            int cb2 = tile_col_base + b_store_c2_local;\n            int cb3 = tile_col_base + b_store_c3_local;\n\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + cb0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (cb3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (cb0 < N) ? B[next_kB * N + cb0] : 0.0f;\n                    b4n.y = (cb1 < N) ? B[next_kB * N + cb1] : 0.0f;\n                    b4n.z = (cb2 < N) ? B[next_kB * N + cb2] : 0.0f;\n                    b4n.w = (cb3 < N) ? B[next_kB * N + cb3] : 0.0f;\n                }\n            }\n\n            Bsub_next[next_kB_local][b_store_c0_local] = b4n.x;\n            Bsub_next[next_kB_local][b_store_c1_local] = b4n.y;\n            Bsub_next[next_kB_local][b_store_c2_local] = b4n.z;\n            Bsub_next[next_kB_local][b_store_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 20,
    "goal": "Optimize global memory access efficiency by implementing warp-level matrix transposition for matrix B during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.6270336151123046,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16896.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.627 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5728\u4fdd\u6301Morton\u6620\u5c04\u3001\u5bc4\u5b58\u5668\u5206\u5757\u4e0eA\u52a0\u8f7d\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\n    // \u5bf9\u77e9\u9635B\u7684\u52a0\u8f7d\u8fdb\u884cwarp\u53cb\u597d\u7684\u201c\u8f6c\u7f6e\u5f0f\u201d\u5b58\u50a8\u5230\u5171\u4eab\u5185\u5b58\uff1a\n    //  - \u5168\u5c40\u5185\u5b58\u4e2d\u4ecd\u6309\u884c\u65b9\u5411(\u5217\u8fde\u7eed)\u8fdb\u884c\u5411\u91cf\u5316\u8bfb\u53d6\u4ee5\u4fdd\u6301\u5b8c\u5168\u5408\u5e76\n    //  - \u5c06\u8bfb\u53d6\u5230\u7684B\u5206\u5757\u4ee5\u8f6c\u7f6e\u5f62\u5f0f\u5199\u5165\u5171\u4eab\u5185\u5b58\uff0c\u4f7f\u8ba1\u7b97\u9636\u6bb5\u6309[k][col]\u8bbf\u95ee\u65f6\u66f4\u89c4\u6574\n    //  - \u5bf9\u5171\u4eab\u5185\u5b58B\u5757\u7684\u5217\u7ef4\u5ea6\u505a+1\u586b\u5145\u4ee5\u51cf\u5c11\u94f6\u884c\u51b2\u7a81\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    // B\u5206\u5757\u91c7\u7528\u8f6c\u7f6e\u5b58\u50a8\uff1a\u7ef4\u5ea6\u4e3a [tile_cols=64][k_tile=16(+pad)]\n    // \u5176\u4e2d\u7b2c\u4e8c\u7ef4(+1)\u7528\u4e8e\u6253\u7834\u5171\u4eab\u5185\u5b58\u94f6\u884c\u51b2\u7a81\n    __shared__ float BsubT_ping[4 * BLOCK_SIZE][BLOCK_SIZE + 1];\n    __shared__ float BsubT_pong[4 * BLOCK_SIZE][BLOCK_SIZE + 1];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   \n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   \n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            \n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            \n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               \n        uint32_t c10 = w1 * h0;               \n        uint32_t c01 = w0 * h1;               \n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n\n    // B\u4f7f\u7528\u8f6c\u7f6e\u7f13\u51b2\uff08\u7b2c\u4e8c\u7ef4+1\u586b\u5145\uff09\n    float (*Bsub_curr_T)[BLOCK_SIZE + 1] = BsubT_ping;\n    float (*Bsub_next_T)[BLOCK_SIZE + 1] = BsubT_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u8f6c\u7f6e\u5f0f\u5b58\u5165\u5171\u4eab\u5185\u5b58\uff08\u4fdd\u6301\u5168\u5c40\u5185\u5b58\u8bfb\u53d6\u5217\u8fde\u7eed\u3001\u5411\u91cf\u5316\uff09 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        // \u5c06B\u5199\u5165\u5171\u4eab\u5185\u5b58\u7684\u8f6c\u7f6e\u5e03\u5c40\uff1a[col][k]\n        Bsub_curr_T[b_c0_local][tid_y] = b4.x;\n        Bsub_curr_T[b_c1_local][tid_y] = b4.y;\n        Bsub_curr_T[b_c2_local][tid_y] = b4.z;\n        Bsub_curr_T[b_c3_local][tid_y] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                // \u4ece\u8f6c\u7f6e\u7684B\u7f13\u51b2\u8bfb\u53d6\uff1a[col_local][k]\n                float b0 = Bsub_curr_T[b_c0_local][k + 0];\n                float b1 = Bsub_curr_T[b_c1_local][k + 0];\n                float b2 = Bsub_curr_T[b_c2_local][k + 0];\n                float b3 = Bsub_curr_T[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr_T[b_c0_local][k + 1];\n                float b1 = Bsub_curr_T[b_c1_local][k + 1];\n                float b2 = Bsub_curr_T[b_c2_local][k + 1];\n                float b3 = Bsub_curr_T[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr_T[b_c0_local][k + 2];\n                float b1 = Bsub_curr_T[b_c1_local][k + 2];\n                float b2 = Bsub_curr_T[b_c2_local][k + 2];\n                float b3 = Bsub_curr_T[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr_T[b_c0_local][k + 3];\n                float b1 = Bsub_curr_T[b_c1_local][k + 3];\n                float b2 = Bsub_curr_T[b_c2_local][k + 3];\n                float b3 = Bsub_curr_T[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\uff08\u8f6c\u7f6e\u5f0f\u5b58\u5165\u5171\u4eab\u5185\u5b58\uff09\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next_T[b_c0_local][tid_y] = b4n.x;\n            Bsub_next_T[b_c1_local][tid_y] = b4n.y;\n            Bsub_next_T[b_c2_local][tid_y] = b4n.z;\n            Bsub_next_T[b_c3_local][tid_y] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB_T)[BLOCK_SIZE + 1] = Bsub_curr_T;\n            Bsub_curr_T = Bsub_next_T;\n            Bsub_next_T = tmpB_T;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 21,
    "goal": "Optimize global memory coalescing for matrix B prefetching by implementing warp-level matrix transposition during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 5.931417465209961,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 5.931 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u4fdd\u6301\u5411\u91cf\u5316\u52a0\u8f7d\u4e0e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4e0d\u53d8\uff0c\u4ec5\u7b80\u5316\u4e86\u7ebf\u7a0b\u5757\u5230\u8f93\u51fatile\u7684Z-order\u6620\u5c04\u903b\u8f91\uff1a\n    //  - \u4f7f\u7528\u5355\u4e00\u7684Morton\u66f2\u7ebf\u8986\u76d6\u5305\u542b(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42\u65b9\u5f62\u533a\u57dfP\u00d7P\n    //  - \u901a\u8fc7\u5728\u56db\u53c9\u6811\u5c42\u7ea7\u4e0a\u8fdb\u884c\u201c\u9009\u62e9\u201d\u64cd\u4f5c\uff08\u6309\u56db\u8c61\u9650\u8ba1\u6570\uff09\u5c06block_id\u6620\u5c04\u5230\u77e9\u5f62\u5185\u7b2cidx\u4e2aZ\u5e8f\u4f4d\u7f6e\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    // \u6bcf\u5c42\u53ea\u5305\u542b\u5c11\u91cf\u7b97\u672f\u4e0e\u6bd4\u8f83\uff0c\u4e14\u6240\u6709\u7ebf\u7a0b\u5757\u5185\u7ebf\u7a0b\u6267\u884c\u4e00\u81f4\uff0c\u907f\u514d\u7ebf\u7a0b\u5185\u5206\u6b67\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u4f7f\u7528\u8f6c\u7f6e\u5171\u4eab\u5185\u5b58\u5e03\u5c40 [4*BLOCK_SIZE][BLOCK_SIZE]\n        // K\u7ef4\u7531tid_x\u7d22\u5f15\uff0c\u5217\u6bb5\u7531tid_y\u7d22\u5f15\uff0c\u5411\u91cf\u5316\u6309\u5217\u65b9\u5411\u52a0\u8f7d\n        int kB = 0 + tid_x;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        int b_col_base_local = tid_y * 4; // \u672c\u7ebf\u7a0b\u52a0\u8f7d\u7684\u5217\u8d77\u59cb(\u76f8\u5bf9\u4e8etile)\n        int load_c0 = tile_col_base + b_col_base_local + 0;\n        int load_c1 = tile_col_base + b_col_base_local + 1;\n        int load_c2 = tile_col_base + b_col_base_local + 2;\n        int load_c3 = tile_col_base + b_col_base_local + 3;\n\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + load_c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (load_c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (load_c0 < N) ? B[kB * N + load_c0] : 0.0f;\n                b4.y = (load_c1 < N) ? B[kB * N + load_c1] : 0.0f;\n                b4.z = (load_c2 < N) ? B[kB * N + load_c2] : 0.0f;\n                b4.w = (load_c3 < N) ? B[kB * N + load_c3] : 0.0f;\n            }\n        }\n\n        // \u5b58\u5165\u5171\u4eab\u5185\u5b58\uff08\u8f6c\u7f6e\uff09\uff1a\u884c\u4e3a\u5217\u7d22\u5f15\uff0c\u5217\u4e3aK\u6b65\u5185\u7684k\u7d22\u5f15\n        Bsub_curr[b_col_base_local + 0][tid_x] = b4.x;\n        Bsub_curr[b_col_base_local + 1][tid_x] = b4.y;\n        Bsub_curr[b_col_base_local + 2][tid_x] = b4.z;\n        Bsub_curr[b_col_base_local + 3][tid_x] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile (\u8f6c\u7f6e\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u52a0\u8f7d)\n            int next_kB = k_tile + BLOCK_SIZE + tid_x;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            int b_col_base_local_n = tid_y * 4;\n            int nload_c0 = tile_col_base + b_col_base_local_n + 0;\n            int nload_c1 = tile_col_base + b_col_base_local_n + 1;\n            int nload_c2 = tile_col_base + b_col_base_local_n + 2;\n            int nload_c3 = tile_col_base + b_col_base_local_n + 3;\n\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + nload_c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (nload_c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (nload_c0 < N) ? B[next_kB * N + nload_c0] : 0.0f;\n                    b4n.y = (nload_c1 < N) ? B[next_kB * N + nload_c1] : 0.0f;\n                    b4n.z = (nload_c2 < N) ? B[next_kB * N + nload_c2] : 0.0f;\n                    b4n.w = (nload_c3 < N) ? B[next_kB * N + nload_c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[b_col_base_local_n + 0][tid_x] = b4n.x;\n            Bsub_next[b_col_base_local_n + 1][tid_x] = b4n.y;\n            Bsub_next[b_col_base_local_n + 2][tid_x] = b4n.z;\n            Bsub_next[b_col_base_local_n + 3][tid_x] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 22,
    "goal": "Optimize global memory access patterns by implementing warp-level matrix transposition for matrix B during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 6.200627136230469,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 6.201 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u6539\u5584B\u7684\u5168\u5c40\u5185\u5b58\u8bbf\u95ee\uff1a\u91c7\u7528warp\u534f\u540c\u52a0\u8f7d\u5e76\u5728\u5171\u4eab\u5185\u5b58\u4e2d\u8fdb\u884c\u8f6c\u7f6e\u5b58\u50a8\n    // B\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u4ece [BLOCK_SIZE][4*BLOCK_SIZE] \u6539\u4e3a [4*BLOCK_SIZE][BLOCK_SIZE]\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE]; // [64][16] \u8f6c\u7f6e\u5e03\u5c40\uff1a\u7b2c\u4e00\u7ef4\u662ftile\u5217\uff0c\u7b2c\u4e8c\u7ef4\u662fk\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n    int tid_linear = tid_y * BLOCK_SIZE + tid_x;\n    int warp_id = tid_linear >> 5;      // 0..7 (256\u7ebf\u7a0b/32)\n    int lane_id = tid_linear & 31;      // 0..31\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        uint32_t w0 = (w_rem < half) ? w_rem : half;\n        uint32_t h0 = (h_rem < half) ? h_rem : half;\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;\n\n        uint32_t c00 = w0 * h0;\n        uint32_t c10 = w1 * h0;\n        uint32_t c01 = w0 * h1;\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0; size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0; size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1; size = half;\n            continue;\n        }\n        idx -= c01;\n\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1; size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping; // [64][16]\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: warp\u534f\u540c\u52a0\u8f7d + \u5171\u4eab\u5185\u5b58\u8f6c\u7f6e\u5b58\u50a8 ---\n        // \u9700\u8981\u52a0\u8f7d\u7684\u5757\u4e3a\uff1aB[k:0..15, col:tile_col_base..tile_col_base+63]\n        // \u6bcf\u4e2awarp\u8d1f\u8d232\u4e2ak\u884c\uff1b\u6bcf\u4e2alane\u4f9d\u6b21\u52a0\u8f7d\u4e24\u6bb5\u8fde\u7eed\u768432\u5217\u6570\u636e\n        for (int t = 0; t < 2; ++t) {\n            int k_local = warp_id * 2 + t; // \u8be5warp\u8d1f\u8d23\u7684\u672c\u5730k\u884c\n            if (k_local < BLOCK_SIZE) {\n                int gk = 0 + k_local; // \u521d\u59cbtile\u7684\u5168\u5c40k\n                float v0 = 0.f, v1 = 0.f;\n                int col0 = tile_col_base + lane_id;\n                int col1 = tile_col_base + lane_id + 32;\n                if (gk < N) {\n                    if (col0 < N) v0 = B[gk * N + col0];\n                    if (col1 < N) v1 = B[gk * N + col1];\n                }\n                // \u5171\u4eab\u5185\u5b58\u8f6c\u7f6e\u5b58\u50a8\uff1a[64][16] => \u7b2c\u4e00\u7ef4\u662f\u5217\u504f\u79fb\uff0c\u7b2c\u4e8c\u7ef4\u662fk\u504f\u79fb\n                Bsub_curr[lane_id][k_local]      = v0;      // \u52170..31\n                Bsub_curr[lane_id + 32][k_local] = v1;      // \u521732..63\n            }\n        }\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                // \u4ece\u8f6c\u7f6e\u7684B\u7f13\u5b58\u8bfb\u53d6\uff1aBsub_curr[col_offset][k_offset]\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile: warp\u534f\u540c\u52a0\u8f7d + \u8f6c\u7f6e\u5b58\u50a8\u5230next\u7f13\u51b2\u533a\n            for (int t = 0; t < 2; ++t) {\n                int k_local = warp_id * 2 + t; // \u8be5warp\u8d1f\u8d23\u7684\u672c\u5730k\u884c\n                if (k_local < BLOCK_SIZE) {\n                    int gk = k_tile + BLOCK_SIZE + k_local;\n                    float v0 = 0.f, v1 = 0.f;\n                    int col0 = tile_col_base + lane_id;\n                    int col1 = tile_col_base + lane_id + 32;\n                    if (gk < N) {\n                        if (col0 < N) v0 = B[gk * N + col0];\n                        if (col1 < N) v1 = B[gk * N + col1];\n                    }\n                    Bsub_next[lane_id][k_local]      = v0;\n                    Bsub_next[lane_id + 32][k_local] = v1;\n                }\n            }\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 23,
    "goal": "Optimize L2 cache utilization by implementing a more aggressive cache blocking strategy that increases data reuse across multiple output tiles, while maintaining the successful Morton ordering and double buffering approach, to reduce the DRAM-to-L2 throughput ratio by maximizing cache locality.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.541222381591797,
    "ptxas_metrics": {
      "registers_used": 45.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.541 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n#ifndef CACHE_BLOCK_K\n#define CACHE_BLOCK_K 64\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u5f15\u5165K\u7ef4\u8d85\u7ea7\u5757\uff08CACHE_BLOCK_K\uff09\u8fdb\u884c\u4e24\u7ea7\u7f13\u5b58\u963b\u585e\uff1a\u5916\u5c42\u904d\u5386K\u7684\u8d85\u7ea7\u5757\uff0c\u5185\u5c42\u4ecd\u4ee5BLOCK_SIZE\u6b65\u957f\u8fdb\u884c\u53cc\u7f13\u51b2\u3002\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Z-Order (Morton) block mapping (\u4fdd\u6301\u539f\u903b\u8f91)\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    // 1) \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\n    // 2) \u5728P\u00d7P\u7684\u56db\u53c9\u6811\u4e0a\uff0c\u6309Z\u5e8f\u8c61\u9650\u987a\u5e8f(00,10,01,11)\u8fdb\u884c\u201c\u9009\u62e9\u201d\uff0c\n    //    \u5c06\u7b2cblock_id\u4e2a\u6709\u6548\u70b9\u6620\u5c04\u5230\u77e9\u5f62\u5185\u5750\u6807(tile_z_x, tile_z_y)\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    // \u9010\u5c42\u9009\u62e9\u6240\u5728\u8c61\u9650\uff08Z\u5e8f\uff1aq00 -> q10 -> q01 -> q11\uff09\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u5916\u5c42\uff1aK\u7ef4\u8d85\u7ea7\u5757\u904d\u5386\uff08\u4e24\u7ea7\u7f13\u5b58\u963b\u585e\uff09\n    for (int ks = 0; ks < N; ks += CACHE_BLOCK_K) {\n        int ks_end = ks + CACHE_BLOCK_K;\n        if (ks_end > N) ks_end = N;\n\n        // \u9884\u53d6\u672c\u8d85\u7ea7\u5757\u7684\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230\u5f53\u524d\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n        {\n            // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n            int a_row_sel = tid_x / 4;      // 0..3\n            int a_vec_seg = tid_x % 4;      // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n            float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = ks + local_k_base + 0;\n                int gk1 = ks + local_k_base + 1;\n                int gk2 = ks + local_k_base + 2;\n                int gk3 = ks + local_k_base + 3;\n                const float* a_ptr = &A[g_row * N + gk0];\n                uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n                if (gk3 < N && (aline % 16 == 0)) {\n                    a4 = *reinterpret_cast<const float4*>(a_ptr);\n                } else {\n                    a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n            Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n            Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n            Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n            // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n            int kB = ks + tid_y;\n            float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (kB < N) {\n                const float* b_ptr = &B[kB * N + c0];\n                uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n                if (c3 < N && (bline % 16 == 0)) {\n                    b4 = *reinterpret_cast<const float4*>(b_ptr);\n                } else {\n                    b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                    b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                    b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                    b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_curr[tid_y][b_c0_local] = b4.x;\n            Bsub_curr[tid_y][b_c1_local] = b4.y;\n            Bsub_curr[tid_y][b_c2_local] = b4.z;\n            Bsub_curr[tid_y][b_c3_local] = b4.w;\n        }\n\n        __syncthreads();\n\n        // \u5185\u5c42\uff1a\u5728\u5f53\u524dK\u8d85\u7ea7\u5757\u5185\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\u8fdb\u884c\u53cc\u7f13\u51b2\u8f6f\u4ef6\u6d41\u6c34\n        for (int k_tile = ks; k_tile < ks_end; k_tile += BLOCK_SIZE) {\n\n            // \u8ba1\u7b97\uff1a\u5bf9\u5f53\u524d\u5171\u4eab\u5185\u5b58tile\u6267\u884cFMA\uff08\u6bcf\u6b65\u5c55\u5f004\uff09\n            #pragma unroll\n            for (int k = 0; k < BLOCK_SIZE; k += 4) {\n                // k + 0\n                {\n                    float a0 = Asub_curr[k + 0][a_r0_local];\n                    float a1 = Asub_curr[k + 0][a_r1_local];\n                    float a2 = Asub_curr[k + 0][a_r2_local];\n                    float a3 = Asub_curr[k + 0][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 0][b_c0_local];\n                    float b1 = Bsub_curr[k + 0][b_c1_local];\n                    float b2 = Bsub_curr[k + 0][b_c2_local];\n                    float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 1\n                {\n                    float a0 = Asub_curr[k + 1][a_r0_local];\n                    float a1 = Asub_curr[k + 1][a_r1_local];\n                    float a2 = Asub_curr[k + 1][a_r2_local];\n                    float a3 = Asub_curr[k + 1][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 1][b_c0_local];\n                    float b1 = Bsub_curr[k + 1][b_c1_local];\n                    float b2 = Bsub_curr[k + 1][b_c2_local];\n                    float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 2\n                {\n                    float a0 = Asub_curr[k + 2][a_r0_local];\n                    float a1 = Asub_curr[k + 2][a_r1_local];\n                    float a2 = Asub_curr[k + 2][a_r2_local];\n                    float a3 = Asub_curr[k + 2][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 2][b_c0_local];\n                    float b1 = Bsub_curr[k + 2][b_c1_local];\n                    float b2 = Bsub_curr[k + 2][b_c2_local];\n                    float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 3\n                {\n                    float a0 = Asub_curr[k + 3][a_r0_local];\n                    float a1 = Asub_curr[k + 3][a_r1_local];\n                    float a2 = Asub_curr[k + 3][a_r2_local];\n                    float a3 = Asub_curr[k + 3][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 3][b_c0_local];\n                    float b1 = Bsub_curr[k + 3][b_c1_local];\n                    float b2 = Bsub_curr[k + 3][b_c2_local];\n                    float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n            }\n\n            // \u9884\u53d6\u5f53\u524d\u8d85\u7ea7\u5757\u5185\u7684\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n            if (k_tile + BLOCK_SIZE < ks_end) {\n                // A next tile\n                int a_row_sel = tid_x / 4;          // 0..3\n                int a_vec_seg = tid_x % 4;          // 0..3\n                int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n                int g_row = tile_row_base + a_local_row;\n                int local_k_base = a_vec_seg * 4;\n\n                float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n                if (g_row < N) {\n                    int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                    int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                    int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                    int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                    const float* a_ptr_n = &A[g_row * N + gk0];\n                    uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                    if (gk3 < N && (aline_n % 16 == 0)) {\n                        a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                    } else {\n                        a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                        a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                        a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                        a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                    }\n                }\n\n                Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n                Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n                Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n                Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n                // B next tile\n                int next_kB = k_tile + BLOCK_SIZE + tid_y;\n                float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n                if (next_kB < N) {\n                    const float* b_ptr_n = &B[next_kB * N + c0];\n                    uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                    if (c3 < N && (bline_n % 16 == 0)) {\n                        b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                    } else {\n                        b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                        b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                        b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                        b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                    }\n                }\n\n                Bsub_next[tid_y][b_c0_local] = b4n.x;\n                Bsub_next[tid_y][b_c1_local] = b4n.y;\n                Bsub_next[tid_y][b_c2_local] = b4n.z;\n                Bsub_next[tid_y][b_c3_local] = b4n.w;\n            }\n\n            // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n            __syncthreads();\n\n            // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n            if (k_tile + BLOCK_SIZE < ks_end) {\n                float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n                Asub_curr = Asub_next;\n                Asub_next = tmpA;\n\n                float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n                Bsub_curr = Bsub_next;\n                Bsub_next = tmpB;\n            }\n        }\n\n        // \u8d85\u7ea7\u5757\u8f6c\u6362\u7684\u540c\u6b65\uff08\u786e\u4fdd\u524d\u4e00\u8d85\u7ea7\u5757\u7684\u6240\u6709\u7ebf\u7a0b\u5df2\u5b8c\u6210\uff09\n        __syncthreads();\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 24,
    "goal": "Optimize global memory access efficiency by implementing warp-level matrix transposition for matrix A during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5220735549926758,
    "ptxas_metrics": {
      "registers_used": 56.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.522 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u5c06A\u5728\u5171\u4eab\u5185\u5b58\u4e2d\u6309\u8f6c\u7f6e\u5e03\u5c40\u5b58\u50a8\uff1aAsub[row][k]\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u9636\u6bb5\u5bf9A\u7684\u5171\u4eab\u5185\u5b58\u8bbf\u95ee\u51b2\u7a81\n    // B\u4fdd\u6301\u539f\u6709\u5e03\u5c40\uff1aBsub[k][col]\n    __shared__ float Asub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];  // A: [row][k] => 64 x 16\n    __shared__ float Asub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];  // B: [k][col] => 16 x 64\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;               // (x:[0,half),   y:[0,half))\n        uint32_t c10 = w1 * h0;               // (x:[half,P),   y:[0,half))\n        uint32_t c01 = w0 * h1;               // (x:[0,half),   y:[half,P))\n        // c11 = w1 * h1;                      // (x:[half,P),   y:[half,P)), \u9690\u5f0f\u5269\u4f59\n\n        if (idx < c00) {\n            // \u9009q00\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            // \u9009q10\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            // \u9009q01\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[BLOCK_SIZE] = Asub_ping;               // A: [row][k]\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;           // B: [k][col]\n    float (*Asub_next)[BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff08K\u7ef4\u8fde\u7eed\uff09\uff0c\u5e76\u4ee5\u8f6c\u7f6e\u65b9\u5f0f\u5199\u5165\u5171\u4eab\u5185\u5b58Asub[row][k] ---\n        int a_row_sel = tid_x / 4;                // 0..3\n        int a_vec_seg = tid_x % 4;                // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel;  // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;         // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        // \u8f6c\u7f6e\u5199\u5165\uff1aAsub[row][k]\n        Asub_curr[a_local_row][local_k_base + 0] = a4.x;\n        Asub_curr[a_local_row][local_k_base + 1] = a4.y;\n        Asub_curr[a_local_row][local_k_base + 2] = a4.z;\n        Asub_curr[a_local_row][local_k_base + 3] = a4.w;\n\n        // --- B: \u4fdd\u6301\u539f\u6709\u5e03\u5c40\uff1aBsub[k][col] ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[a_r0_local][k + 0];\n                float a1 = Asub_curr[a_r1_local][k + 0];\n                float a2 = Asub_curr[a_r2_local][k + 0];\n                float a3 = Asub_curr[a_r3_local][k + 0];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[a_r0_local][k + 1];\n                float a1 = Asub_curr[a_r1_local][k + 1];\n                float a2 = Asub_curr[a_r2_local][k + 1];\n                float a3 = Asub_curr[a_r3_local][k + 1];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[a_r0_local][k + 2];\n                float a1 = Asub_curr[a_r1_local][k + 2];\n                float a2 = Asub_curr[a_r2_local][k + 2];\n                float a3 = Asub_curr[a_r3_local][k + 2];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[a_r0_local][k + 3];\n                float a1 = Asub_curr[a_r1_local][k + 3];\n                float a2 = Asub_curr[a_r2_local][k + 3];\n                float a3 = Asub_curr[a_r3_local][k + 3];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\uff08\u8f6c\u7f6e\u5199\u5165Asub_next[row][k]\uff09\n            int a_row_sel = tid_x / 4;                // 0..3\n            int a_vec_seg = tid_x % 4;                // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel;  // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[a_local_row][local_k_base + 0] = a4n.x;\n            Asub_next[a_local_row][local_k_base + 1] = a4n.y;\n            Asub_next[a_local_row][local_k_base + 2] = a4n.z;\n            Asub_next[a_local_row][local_k_base + 3] = a4n.w;\n\n            // B next tile\uff08\u4fdd\u6301\u539f\u5e03\u5c40\uff09\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 25,
    "goal": "Optimize global memory access efficiency by implementing warp-level matrix transposition for both matrices during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization and reduce the DRAM-to-L2 throughput ratio.",
    "status": "Failed (Performance Regression)",
    "time_ms": 6.103654479980468,
    "ptxas_metrics": {
      "registers_used": 80.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 6.104 ms is not better than best time 1.503 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    // \u672c\u7248\u672c\u5728\u52a0\u8f7d\u5230\u5171\u4eab\u5185\u5b58\u65f6\u8fdb\u884c\u8f6c\u7f6e\u5b58\u50a8\uff1a\n    //  - A/B\u7684\u5171\u4eab\u5185\u5b58\u5e03\u5c40\u6539\u4e3a[4*BLOCK_SIZE][BLOCK_SIZE] (\u5373[64][16])\n    //  - \u52a0\u8f7d\u4fdd\u6301float4\u5411\u91cf\u5316\uff0c\u4f46\u5199\u5165\u5171\u4eab\u5185\u5b58\u65f6\u8f6c\u7f6e\uff0c\u4ee5\u63d0\u5347\u5168\u5c40\u5185\u5b58\u8bbf\u95ee\u7684\u534f\u540c\u4e0e\u5171\u4eab\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\n    __shared__ float Asub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Asub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Simplified Z-Order (Morton) block mapping\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t total_tiles  = w * h;\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u82e5\u5f53\u524dblock\u8d85\u51fa\u6709\u6548tile\u6570\u91cf\uff0c\u63d0\u524d\u8fd4\u56de\uff08\u907f\u514d\u91cd\u590d/\u8d8a\u754c\u8ba1\u7b97\uff09\n    if (block_id >= total_tiles) {\n        return;\n    }\n\n    // \u4ee5\u5355\u4e00Morton\u66f2\u7ebf\u8986\u76d6\u6574\u4e2a\u77e9\u5f62\uff1a\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1; // next power-of-two >= max(w,h)\n\n    uint32_t idx = block_id;\n    uint32_t size = P;\n    uint32_t x_off = 0u, y_off = 0u;\n    uint32_t w_rem = w, h_rem = h;\n\n    while (size > 1u) {\n        uint32_t half = size >> 1;\n\n        // \u4e0e\u56db\u8c61\u9650\u7684\u4ea4\u96c6\u5c3a\u5bf8\n        uint32_t w0 = (w_rem < half) ? w_rem : half;                   // min(w_rem, half)\n        uint32_t h0 = (h_rem < half) ? h_rem : half;                   // min(h_rem, half)\n        uint32_t w1 = (w_rem > half) ? (w_rem - half) : 0u;            // max(w_rem - half, 0)\n        uint32_t h1 = (h_rem > half) ? (h_rem - half) : 0u;            // max(h_rem - half, 0)\n\n        // \u5bf9\u5e94Z\u5e8f\u8c61\u9650\u7684\u6709\u6548\u70b9\u6570\n        uint32_t c00 = w0 * h0;\n        uint32_t c10 = w1 * h0;\n        uint32_t c01 = w0 * h1;\n\n        if (idx < c00) {\n            w_rem = w0; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c00;\n\n        if (idx < c10) {\n            x_off += half;\n            w_rem = w1; h_rem = h0;\n            size = half;\n            continue;\n        }\n        idx -= c10;\n\n        if (idx < c01) {\n            y_off += half;\n            w_rem = w0; h_rem = h1;\n            size = half;\n            continue;\n        }\n        idx -= c01;\n\n        // \u9009q11\n        x_off += half; y_off += half;\n        w_rem = w1; h_rem = h1;\n        size = half;\n    }\n\n    // \u5f53\u524d\u5757\u5bf9\u5e94\u7684\u8f93\u51fatile\u8d77\u59cb\u5750\u6807\uff08\u6bcf\u5757\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t tile_z_x = x_off; // \u4fdd\u8bc1 < w\n    uint32_t tile_z_y = y_off; // \u4fdd\u8bc1 < h\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\uff08\u8f6c\u7f6e\u5e03\u5c40\uff1a[64][16]\uff09\n    float (*Asub_curr)[BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff0c\u8f6c\u7f6e\u5b58\u50a8\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4 ---\n        int a_row_sel = tid_x / 4;                // 0..3\n        int a_vec_seg = tid_x % 4;                // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel;  // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4;         // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        // \u8f6c\u7f6e\u5199\u5165\u5171\u4eab\u5185\u5b58\uff1aAsub[row][k]\n        Asub_curr[a_local_row][local_k_base + 0] = a4.x;\n        Asub_curr[a_local_row][local_k_base + 1] = a4.y;\n        Asub_curr[a_local_row][local_k_base + 2] = a4.z;\n        Asub_curr[a_local_row][local_k_base + 3] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        // \u8f6c\u7f6e\u5199\u5165\u5171\u4eab\u5185\u5b58\uff1aBsub[col][k]\n        Bsub_curr[b_c0_local][tid_y] = b4.x;\n        Bsub_curr[b_c1_local][tid_y] = b4.y;\n        Bsub_curr[b_c2_local][tid_y] = b4.z;\n        Bsub_curr[b_c3_local][tid_y] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[a_r0_local][k + 0];\n                float a1 = Asub_curr[a_r1_local][k + 0];\n                float a2 = Asub_curr[a_r2_local][k + 0];\n                float a3 = Asub_curr[a_r3_local][k + 0];\n\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[a_r0_local][k + 1];\n                float a1 = Asub_curr[a_r1_local][k + 1];\n                float a2 = Asub_curr[a_r2_local][k + 1];\n                float a3 = Asub_curr[a_r3_local][k + 1];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[a_r0_local][k + 2];\n                float a1 = Asub_curr[a_r1_local][k + 2];\n                float a2 = Asub_curr[a_r2_local][k + 2];\n                float a3 = Asub_curr[a_r3_local][k + 2];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[a_r0_local][k + 3];\n                float a1 = Asub_curr[a_r1_local][k + 3];\n                float a2 = Asub_curr[a_r2_local][k + 3];\n                float a3 = Asub_curr[a_r3_local][k + 3];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;                // 0..3\n            int a_vec_seg = tid_x % 4;                // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel;  // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            // \u8f6c\u7f6e\u5199\u5165\u5171\u4eab\u5185\u5b58\uff1aAsub[row][k]\n            Asub_next[a_local_row][local_k_base + 0] = a4n.x;\n            Asub_next[a_local_row][local_k_base + 1] = a4n.y;\n            Asub_next[a_local_row][local_k_base + 2] = a4n.z;\n            Asub_next[a_local_row][local_k_base + 3] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            // \u8f6c\u7f6e\u5199\u5165\u5171\u4eab\u5185\u5b58\uff1aBsub[col][k]\n            Bsub_next[b_c0_local][tid_y] = b4n.x;\n            Bsub_next[b_c1_local][tid_y] = b4n.y;\n            Bsub_next[b_c2_local][tid_y] = b4n.z;\n            Bsub_next[b_c3_local][tid_y] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 26,
    "goal": "Optimize computational efficiency by simplifying the Morton ordering logic to reduce branching overhead while maintaining the successful 4x4 per-thread tiling and double buffering approach, focusing on minimizing control flow divergence to improve instruction throughput and better utilize available memory bandwidth.",
    "status": "Success (New Best)",
    "time_ms": 1.4989312171936036,
    "ptxas_metrics": {
      "registers_used": 40.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "Performance improved from 1.503 ms to 1.499 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Direct Z-Order (Morton) block mapping via bit deinterleave\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\uff0c\u5e76\u4ec5\u4f7f\u7528\u524dP*P\u4e2a\u5757\u8fdb\u884cMorton\u6620\u5c04\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t P2 = P * P;\n    if (block_id >= P2) {\n        return;\n    }\n\n    // \u76f4\u63a5\u901a\u8fc7Morton\u89e3\u7801\u5f97\u5230P\u00d7P\u7f51\u683c\u4e2d\u7684\u5750\u6807\uff0c\u7136\u540e\u88c1\u526a\u5230\u6709\u6548\u77e9\u5f62(w,h)\n    uint32_t tile_z_x = morton_decode_x(block_id);\n    uint32_t tile_z_y = morton_decode_y(block_id);\n\n    if (tile_z_x >= w || tile_z_y >= h) {\n        return;\n    }\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 27,
    "goal": "Increase computational intensity by implementing warp-level matrix multiplication with 8x8 per-thread tiling using register blocking, while maintaining the successful Morton ordering and double buffering approach, to better utilize the available memory bandwidth by performing more FLOPs per byte loaded from global memory.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.80316162109375,
    "ptxas_metrics": {
      "registers_used": 120.0,
      "shared_mem_bytes": 8192.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.803 ms is not better than best time 1.499 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 8\n#endif\n\n#define TILE_SIZE (8 * BLOCK_SIZE)   // 64\n#define BLOCK_K   (BLOCK_SIZE)       // 8\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // 8x8 per-thread output tile, 8x8 threads per block => 64x64 block output\n    // Shared memory: double-buffered tiles, dimensions [BLOCK_K x TILE_SIZE] = [8 x 64]\n    __shared__ float Asub_ping[BLOCK_K][TILE_SIZE];\n    __shared__ float Asub_pong[BLOCK_K][TILE_SIZE];\n    __shared__ float Bsub_ping[BLOCK_K][TILE_SIZE];\n    __shared__ float Bsub_pong[BLOCK_K][TILE_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Direct Z-Order (Morton) block mapping via bit deinterleave\n    // -------------------------------\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\uff0c\u5e76\u4ec5\u4f7f\u7528\u524dP*P\u4e2a\u5757\u8fdb\u884cMorton\u6620\u5c04\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t P2 = P * P;\n    if (block_id >= P2) {\n        return;\n    }\n\n    // \u76f4\u63a5\u901a\u8fc7Morton\u89e3\u7801\u5f97\u5230P\u00d7P\u7f51\u683c\u4e2d\u7684\u5750\u6807\uff0c\u7136\u540e\u88c1\u526a\u5230\u6709\u6548\u77e9\u5f62(w,h)\n    uint32_t tile_z_x = morton_decode_x(block_id);\n    uint32_t tile_z_y = morton_decode_y(block_id);\n\n    if (tile_z_x >= w || tile_z_y >= h) {\n        return;\n    }\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76848x8\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int r_local_idx[8];\n    int c_local_idx[8];\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) { r_local_idx[i] = tid_y * 8 + i; }\n    #pragma unroll\n    for (int j = 0; j < 8; ++j) { c_local_idx[j] = tid_x * 8 + j; }\n\n    int r_global_idx[8];\n    int c_global_idx[8];\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) { r_global_idx[i] = tile_row_base + r_local_idx[i]; }\n    #pragma unroll\n    for (int j = 0; j < 8; ++j) { c_global_idx[j] = tile_col_base + c_local_idx[j]; }\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76848x8\u7d2f\u52a0\u5668\n    float acc[8][8];\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) {\n        #pragma unroll\n        for (int j = 0; j < 8; ++j) {\n            acc[i][j] = 0.0f;\n        }\n    }\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[TILE_SIZE] = Asub_ping;\n    float (*Bsub_curr)[TILE_SIZE] = Bsub_ping;\n    float (*Asub_next)[TILE_SIZE] = Asub_pong;\n    float (*Bsub_next)[TILE_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e24\u4e2afloat4\uff0c\u51718\u4e2aK\u65b9\u5411\u8fde\u7eed\u5143\u7d20\uff0c\u5199\u5165\u5176\u8d1f\u8d23\u7684\u884c ---\n        int a_local_row = tid_y * 8 + tid_x; // 0..63 unique per thread\n        int g_row = tile_row_base + a_local_row;\n\n        float4 a40 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 a41 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            // first 4\n            int gk0 = 0 + 0;\n            int gk1 = 0 + 1;\n            int gk2 = 0 + 2;\n            int gk3 = 0 + 3;\n            const float* a_ptr0 = &A[g_row * N + gk0];\n            uintptr_t aline0 = reinterpret_cast<uintptr_t>(a_ptr0);\n            if (gk3 < N && (aline0 % 16 == 0)) {\n                a40 = *reinterpret_cast<const float4*>(a_ptr0);\n            } else {\n                a40.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a40.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a40.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a40.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n            // next 4\n            int gk4 = 0 + 4;\n            int gk5 = 0 + 5;\n            int gk6 = 0 + 6;\n            int gk7 = 0 + 7;\n            const float* a_ptr1 = &A[g_row * N + gk4];\n            uintptr_t aline1 = reinterpret_cast<uintptr_t>(a_ptr1);\n            if (gk7 < N && (aline1 % 16 == 0)) {\n                a41 = *reinterpret_cast<const float4*>(a_ptr1);\n            } else {\n                a41.x = (gk4 < N) ? A[g_row * N + gk4] : 0.0f;\n                a41.y = (gk5 < N) ? A[g_row * N + gk5] : 0.0f;\n                a41.z = (gk6 < N) ? A[g_row * N + gk6] : 0.0f;\n                a41.w = (gk7 < N) ? A[g_row * N + gk7] : 0.0f;\n            }\n        }\n        Asub_curr[0][a_local_row] = a40.x;\n        Asub_curr[1][a_local_row] = a40.y;\n        Asub_curr[2][a_local_row] = a40.z;\n        Asub_curr[3][a_local_row] = a40.w;\n        Asub_curr[4][a_local_row] = a41.x;\n        Asub_curr[5][a_local_row] = a41.y;\n        Asub_curr[6][a_local_row] = a41.z;\n        Asub_curr[7][a_local_row] = a41.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e24\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76848\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y; // 0..7\n        float4 b40 = make_float4(0.f, 0.f, 0.f, 0.f);\n        float4 b41 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            int c0 = tile_col_base + c_local_idx[0];\n            int c4 = tile_col_base + c_local_idx[4];\n            int c1 = tile_col_base + c_local_idx[1];\n            int c2 = tile_col_base + c_local_idx[2];\n            int c3 = tile_col_base + c_local_idx[3];\n            int c5 = tile_col_base + c_local_idx[5];\n            int c6 = tile_col_base + c_local_idx[6];\n            int c7 = tile_col_base + c_local_idx[7];\n\n            const float* b_ptr0 = &B[kB * N + c0];\n            uintptr_t bline0 = reinterpret_cast<uintptr_t>(b_ptr0);\n            if (c3 < N && (bline0 % 16 == 0)) {\n                b40 = *reinterpret_cast<const float4*>(b_ptr0);\n            } else {\n                b40.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b40.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b40.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b40.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n\n            const float* b_ptr1 = &B[kB * N + c4];\n            uintptr_t bline1 = reinterpret_cast<uintptr_t>(b_ptr1);\n            if (c7 < N && (bline1 % 16 == 0)) {\n                b41 = *reinterpret_cast<const float4*>(b_ptr1);\n            } else {\n                b41.x = (c4 < N) ? B[kB * N + c4] : 0.0f;\n                b41.y = (c5 < N) ? B[kB * N + c5] : 0.0f;\n                b41.z = (c6 < N) ? B[kB * N + c6] : 0.0f;\n                b41.w = (c7 < N) ? B[kB * N + c7] : 0.0f;\n            }\n\n            // Store into shared\n            Bsub_curr[tid_y][c_local_idx[0]] = b40.x;\n            Bsub_curr[tid_y][c_local_idx[1]] = b40.y;\n            Bsub_curr[tid_y][c_local_idx[2]] = b40.z;\n            Bsub_curr[tid_y][c_local_idx[3]] = b40.w;\n            Bsub_curr[tid_y][c_local_idx[4]] = b41.x;\n            Bsub_curr[tid_y][c_local_idx[5]] = b41.y;\n            Bsub_curr[tid_y][c_local_idx[6]] = b41.z;\n            Bsub_curr[tid_y][c_local_idx[7]] = b41.w;\n        } else {\n            // zero-fill if kB out of bounds\n            #pragma unroll\n            for (int j = 0; j < 8; ++j) {\n                Bsub_curr[tid_y][c_local_idx[j]] = 0.0f;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_K\u4e3a\u6b65\u957f\uff08\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_K) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0c\u52a0\u8f7d8\u4e2aA\u4e0e8\u4e2aB\uff0c\u8fdb\u884c8x8\u7d2f\u52a0\n        #pragma unroll\n        for (int k = 0; k < BLOCK_K; ++k) {\n            float a_vec[8];\n            float b_vec[8];\n\n            // Load A row vector for each of the 8 rows this thread computes\n            #pragma unroll\n            for (int i = 0; i < 8; ++i) {\n                a_vec[i] = Asub_curr[k][r_local_idx[i]];\n            }\n\n            // Load B column vector for each of the 8 columns this thread computes\n            #pragma unroll\n            for (int j = 0; j < 8; ++j) {\n                b_vec[j] = Bsub_curr[k][c_local_idx[j]];\n            }\n\n            // FMA: acc[i][j] += a_vec[i] * b_vec[j]\n            #pragma unroll\n            for (int i = 0; i < 8; ++i) {\n                float ai = a_vec[i];\n                #pragma unroll\n                for (int j = 0; j < 8; ++j) {\n                    acc[i][j] += ai * b_vec[j];\n                }\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\uff09\n        if (k_tile + BLOCK_K < N) {\n            // A next tile for this thread's owned row\n            int a_local_row = tid_y * 8 + tid_x; // 0..63\n            int g_row = tile_row_base + a_local_row;\n\n            float4 a40n = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 a41n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int base = k_tile + BLOCK_K;\n\n                // first 4\n                int gk0 = base + 0;\n                int gk1 = base + 1;\n                int gk2 = base + 2;\n                int gk3 = base + 3;\n                const float* a_ptr0n = &A[g_row * N + gk0];\n                uintptr_t aline0n = reinterpret_cast<uintptr_t>(a_ptr0n);\n                if (gk3 < N && (aline0n % 16 == 0)) {\n                    a40n = *reinterpret_cast<const float4*>(a_ptr0n);\n                } else {\n                    a40n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a40n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a40n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a40n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n\n                // next 4\n                int gk4 = base + 4;\n                int gk5 = base + 5;\n                int gk6 = base + 6;\n                int gk7 = base + 7;\n                const float* a_ptr1n = &A[g_row * N + gk4];\n                uintptr_t aline1n = reinterpret_cast<uintptr_t>(a_ptr1n);\n                if (gk7 < N && (aline1n % 16 == 0)) {\n                    a41n = *reinterpret_cast<const float4*>(a_ptr1n);\n                } else {\n                    a41n.x = (gk4 < N) ? A[g_row * N + gk4] : 0.0f;\n                    a41n.y = (gk5 < N) ? A[g_row * N + gk5] : 0.0f;\n                    a41n.z = (gk6 < N) ? A[g_row * N + gk6] : 0.0f;\n                    a41n.w = (gk7 < N) ? A[g_row * N + gk7] : 0.0f;\n                }\n            }\n\n            Asub_next[0][a_local_row] = a40n.x;\n            Asub_next[1][a_local_row] = a40n.y;\n            Asub_next[2][a_local_row] = a40n.z;\n            Asub_next[3][a_local_row] = a40n.w;\n            Asub_next[4][a_local_row] = a41n.x;\n            Asub_next[5][a_local_row] = a41n.y;\n            Asub_next[6][a_local_row] = a41n.z;\n            Asub_next[7][a_local_row] = a41n.w;\n\n            // B next tile for this thread's K row\n            int next_kB = k_tile + BLOCK_K + tid_y;\n            float4 b40n = make_float4(0.f, 0.f, 0.f, 0.f);\n            float4 b41n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                int c0 = tile_col_base + c_local_idx[0];\n                int c4 = tile_col_base + c_local_idx[4];\n                int c1 = tile_col_base + c_local_idx[1];\n                int c2 = tile_col_base + c_local_idx[2];\n                int c3 = tile_col_base + c_local_idx[3];\n                int c5 = tile_col_base + c_local_idx[5];\n                int c6 = tile_col_base + c_local_idx[6];\n                int c7 = tile_col_base + c_local_idx[7];\n\n                const float* b_ptr0n = &B[next_kB * N + c0];\n                uintptr_t bline0n = reinterpret_cast<uintptr_t>(b_ptr0n);\n                if (c3 < N && (bline0n % 16 == 0)) {\n                    b40n = *reinterpret_cast<const float4*>(b_ptr0n);\n                } else {\n                    b40n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b40n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b40n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b40n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n\n                const float* b_ptr1n = &B[next_kB * N + c4];\n                uintptr_t bline1n = reinterpret_cast<uintptr_t>(b_ptr1n);\n                if (c7 < N && (bline1n % 16 == 0)) {\n                    b41n = *reinterpret_cast<const float4*>(b_ptr1n);\n                } else {\n                    b41n.x = (c4 < N) ? B[next_kB * N + c4] : 0.0f;\n                    b41n.y = (c5 < N) ? B[next_kB * N + c5] : 0.0f;\n                    b41n.z = (c6 < N) ? B[next_kB * N + c6] : 0.0f;\n                    b41n.w = (c7 < N) ? B[next_kB * N + c7] : 0.0f;\n                }\n\n                Bsub_next[tid_y][c_local_idx[0]] = b40n.x;\n                Bsub_next[tid_y][c_local_idx[1]] = b40n.y;\n                Bsub_next[tid_y][c_local_idx[2]] = b40n.z;\n                Bsub_next[tid_y][c_local_idx[3]] = b40n.w;\n                Bsub_next[tid_y][c_local_idx[4]] = b41n.x;\n                Bsub_next[tid_y][c_local_idx[5]] = b41n.y;\n                Bsub_next[tid_y][c_local_idx[6]] = b41n.z;\n                Bsub_next[tid_y][c_local_idx[7]] = b41n.w;\n            } else {\n                #pragma unroll\n                for (int j = 0; j < 8; ++j) {\n                    Bsub_next[tid_y][c_local_idx[j]] = 0.0f;\n                }\n            }\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_K < N) {\n            float (*tmpA)[TILE_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[TILE_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff088x8\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    #pragma unroll\n    for (int i = 0; i < 8; ++i) {\n        int rg = r_global_idx[i];\n        if (rg < N) {\n            #pragma unroll\n            for (int j = 0; j < 8; ++j) {\n                int cg = c_global_idx[j];\n                if (cg < N) {\n                    C[rg * N + cg] = acc[i][j];\n                }\n            }\n        }\n    }\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 28,
    "goal": "Optimize global memory bandwidth utilization by increasing the thread block size from 16x16 to 32x32 while maintaining the successful Morton ordering and double buffering approach, focusing on better saturating the memory bus by increasing concurrent memory transactions and improving memory-level parallelism.",
    "status": "Failed (Compilation)",
    "time_ms": null,
    "ptxas_metrics": {},
    "details": "CUDA C++ \u6269\u5c55\u7f16\u8bd1\u5931\u8d25: Error building extension 'gemm_evolved_28'\n--- [ NVCC/Ninja STDOUT ] ---\n[1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -ccbin /usr/bin/gcc-12 -DTORCH_EXTENSION_NAME=gemm_evolved_28 -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/lxt/OpenEvolve_env/lib/python3.12/site-packages/torch/include -isystem /home/lxt/OpenEvolve_env/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -allow-unsupported-compiler -DBLOCK_SIZE=32 --ptxas-options=-v -gencode=arch=compute_80,code=sm_80 -std=c++17 -c /home/lxt/.cache/torch_extensions/py312_cu128/gemm_evolved_28/cuda.cu -o cuda.cuda.o \nFAILED: cuda.cuda.o \n/usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -ccbin /usr/bin/gcc-12 -DTORCH_EXTENSION_NAME=gemm_evolved_28 -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/lxt/OpenEvolve_env/lib/python3.12/site-packages/torch/include -isystem /home/lxt/OpenEvolve_env/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -allow-unsupported-compiler -DBLOCK_SIZE=32 --ptxas-options=-v -gencode=arch=compute_80,code=sm_80 -std=c++17 -c /home/lxt/.cache/torch_extensions/py312_cu128/gemm_evolved_28/cuda.cu -o cuda.cuda.o \nptxas error   : Entry function '_Z11gemm_kernelPKfS0_Pfi' uses too much shared data (0x10000 bytes, 0xc000 max)\nptxas info    : 3 bytes gmem\nptxas info    : Compiling entry function '_Z11gemm_kernelPKfS0_Pfi' for 'sm_80'\nptxas info    : Function properties for _Z11gemm_kernelPKfS0_Pfi\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 46 registers, 65536 bytes smem, 380 bytes cmem[0]\nninja: build stopped: subcommand failed.\n\n--- [ NVCC/Ninja STDERR ] ---\n\n-----------------------------\n",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 32\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Direct Z-Order (Morton) block mapping via bit deinterleave\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 128 when BLOCK_SIZE=32\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d6128x128\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\uff0c\u5e76\u4ec5\u4f7f\u7528\u524dP*P\u4e2a\u5757\u8fdb\u884cMorton\u6620\u5c04\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t P2 = P * P;\n    if (block_id >= P2) {\n        return;\n    }\n\n    // \u76f4\u63a5\u901a\u8fc7Morton\u89e3\u7801\u5f97\u5230P\u00d7P\u7f51\u683c\u4e2d\u7684\u5750\u6807\uff0c\u7136\u540e\u88c1\u526a\u5230\u6709\u6548\u77e9\u5f62(w,h)\n    uint32_t tile_z_x = morton_decode_x(block_id);\n    uint32_t tile_z_y = morton_decode_y(block_id);\n\n    if (tile_z_x >= w || tile_z_y >= h) {\n        return;\n    }\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 8;      // 0..3\n        int a_vec_seg = tid_x % 8;      // 0..7\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..127\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,...,28\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        Bsub_curr[tid_y][b_c0_local] = b4.x;\n        Bsub_curr[tid_y][b_c1_local] = b4.y;\n        Bsub_curr[tid_y][b_c2_local] = b4.z;\n        Bsub_curr[tid_y][b_c3_local] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[k + 0][b_c0_local];\n                float b1 = Bsub_curr[k + 0][b_c1_local];\n                float b2 = Bsub_curr[k + 0][b_c2_local];\n                float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[k + 1][b_c0_local];\n                float b1 = Bsub_curr[k + 1][b_c1_local];\n                float b2 = Bsub_curr[k + 1][b_c2_local];\n                float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[k + 2][b_c0_local];\n                float b1 = Bsub_curr[k + 2][b_c1_local];\n                float b2 = Bsub_curr[k + 2][b_c2_local];\n                float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[k + 3][b_c0_local];\n                float b1 = Bsub_curr[k + 3][b_c1_local];\n                float b2 = Bsub_curr[k + 3][b_c2_local];\n                float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 8;          // 0..3\n            int a_vec_seg = tid_x % 8;          // 0..7\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..127\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[tid_y][b_c0_local] = b4n.x;\n            Bsub_next[tid_y][b_c1_local] = b4n.y;\n            Bsub_next[tid_y][b_c2_local] = b4n.z;\n            Bsub_next[tid_y][b_c3_local] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 29,
    "goal": "Optimize global memory coalescing for matrix B prefetching by implementing a warp-level matrix transposition during shared memory loading to ensure perfect coalescing across all warps, while maintaining the successful Morton ordering, double buffering, and 4x4 per-thread tiling to maximize global memory bandwidth utilization.",
    "status": "Failed (Performance Regression)",
    "time_ms": 6.191616058349609,
    "ptxas_metrics": {
      "registers_used": 64.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 6.192 ms is not better than best time 1.499 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    // B \u91c7\u7528\u8f6c\u7f6e\u5e03\u5c40\u5b58\u653e\u5230\u5171\u4eab\u5185\u5b58\uff1a[4*BLOCK_SIZE][BLOCK_SIZE] == [64][16] => [col][k]\n    __shared__ float Bsub_ping[4 * BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ float Bsub_pong[4 * BLOCK_SIZE][BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Direct Z-Order (Morton) block mapping via bit deinterleave\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\uff0c\u5e76\u4ec5\u4f7f\u7528\u524dP*P\u4e2a\u5757\u8fdb\u884cMorton\u6620\u5c04\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t P2 = P * P;\n    if (block_id >= P2) {\n        return;\n    }\n\n    // \u76f4\u63a5\u901a\u8fc7Morton\u89e3\u7801\u5f97\u5230P\u00d7P\u7f51\u683c\u4e2d\u7684\u5750\u6807\uff0c\u7136\u540e\u88c1\u526a\u5230\u6709\u6548\u77e9\u5f62(w,h)\n    uint32_t tile_z_x = morton_decode_x(block_id);\n    uint32_t tile_z_y = morton_decode_y(block_id);\n\n    if (tile_z_x >= w || tile_z_y >= h) {\n        return;\n    }\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[BLOCK_SIZE] = Bsub_ping;   // [col][k]\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[BLOCK_SIZE] = Bsub_pong;   // [col][k]\n\n    // \u9884\u53d6\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230ping\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n    {\n        // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n        int a_row_sel = tid_x / 4;      // 0..3\n        int a_vec_seg = tid_x % 4;      // 0..3\n        int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n        int g_row = tile_row_base + a_local_row;\n        int local_k_base = a_vec_seg * 4; // 0,4,8,12\n\n        float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (g_row < N) {\n            int gk0 = 0 + local_k_base + 0;\n            int gk1 = 0 + local_k_base + 1;\n            int gk2 = 0 + local_k_base + 2;\n            int gk3 = 0 + local_k_base + 3;\n            const float* a_ptr = &A[g_row * N + gk0];\n            uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n            if (gk3 < N && (aline % 16 == 0)) {\n                a4 = *reinterpret_cast<const float4*>(a_ptr);\n            } else {\n                a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n            }\n        }\n\n        Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n        Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n        Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n        Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n        // --- B: \u91c7\u7528warp\u7ea7\u8f6c\u7f6e\u601d\u8def\u52a0\u8f7d\u3002\u6bcf\u7ebf\u7a0b\u4ece\u540c\u4e00k\u884c\u52a0\u8f7d4\u4e2a\u8fde\u7eed\u5217\uff0c\u7136\u540e\u5199\u5165\u5171\u4eab\u5185\u5b58\u4e3a\u8f6c\u7f6e\u5e03\u5c40 [col][k] ---\n        int kB = 0 + tid_y;\n        float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n        if (kB < N) {\n            const float* b_ptr = &B[kB * N + c0];\n            uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n            if (c3 < N && (bline % 16 == 0)) {\n                b4 = *reinterpret_cast<const float4*>(b_ptr);\n            } else {\n                b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n            }\n        }\n\n        // \u5199\u5165\u8f6c\u7f6e\u5171\u4eab\u5185\u5b58\uff1a[col][k]\n        Bsub_curr[b_c0_local][tid_y] = b4.x;\n        Bsub_curr[b_c1_local][tid_y] = b4.y;\n        Bsub_curr[b_c2_local][tid_y] = b4.z;\n        Bsub_curr[b_c3_local][tid_y] = b4.w;\n    }\n\n    __syncthreads();\n\n    // K\u7ef4\u904d\u5386\uff0c\u4ee5BLOCK_SIZE\u4e3a\u6b65\u957f\uff08\u8f6f\u4ef6\u6d41\u6c34+\u53cc\u7f13\u51b2\uff09\n    for (int k_tile = 0; k_tile < N; k_tile += BLOCK_SIZE) {\n\n        // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; k += 4) {\n            // k + 0\n            {\n                float a0 = Asub_curr[k + 0][a_r0_local];\n                float a1 = Asub_curr[k + 0][a_r1_local];\n                float a2 = Asub_curr[k + 0][a_r2_local];\n                float a3 = Asub_curr[k + 0][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 0];\n                float b1 = Bsub_curr[b_c1_local][k + 0];\n                float b2 = Bsub_curr[b_c2_local][k + 0];\n                float b3 = Bsub_curr[b_c3_local][k + 0];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 1\n            {\n                float a0 = Asub_curr[k + 1][a_r0_local];\n                float a1 = Asub_curr[k + 1][a_r1_local];\n                float a2 = Asub_curr[k + 1][a_r2_local];\n                float a3 = Asub_curr[k + 1][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 1];\n                float b1 = Bsub_curr[b_c1_local][k + 1];\n                float b2 = Bsub_curr[b_c2_local][k + 1];\n                float b3 = Bsub_curr[b_c3_local][k + 1];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 2\n            {\n                float a0 = Asub_curr[k + 2][a_r0_local];\n                float a1 = Asub_curr[k + 2][a_r1_local];\n                float a2 = Asub_curr[k + 2][a_r2_local];\n                float a3 = Asub_curr[k + 2][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 2];\n                float b1 = Bsub_curr[b_c1_local][k + 2];\n                float b2 = Bsub_curr[b_c2_local][k + 2];\n                float b3 = Bsub_curr[b_c3_local][k + 2];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n\n            // k + 3\n            {\n                float a0 = Asub_curr[k + 3][a_r0_local];\n                float a1 = Asub_curr[k + 3][a_r1_local];\n                float a2 = Asub_curr[k + 3][a_r2_local];\n                float a3 = Asub_curr[k + 3][a_r3_local];\n\n                float b0 = Bsub_curr[b_c0_local][k + 3];\n                float b1 = Bsub_curr[b_c1_local][k + 3];\n                float b2 = Bsub_curr[b_c2_local][k + 3];\n                float b3 = Bsub_curr[b_c3_local][k + 3];\n\n                acc00 += a0 * b0;\n                acc11 += a1 * b1;\n                acc22 += a2 * b2;\n                acc33 += a3 * b3;\n\n                acc01 += a0 * b1;\n                acc12 += a1 * b2;\n                acc23 += a2 * b3;\n                acc30 += a3 * b0;\n\n                acc02 += a0 * b2;\n                acc13 += a1 * b3;\n                acc20 += a2 * b0;\n                acc31 += a3 * b1;\n\n                acc03 += a0 * b3;\n                acc10 += a1 * b0;\n                acc21 += a2 * b1;\n                acc32 += a3 * b2;\n            }\n        }\n\n        // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u8f6f\u4ef6\u6d41\u6c34\uff0c\u5411\u91cf\u5316\u52a0\u8f7d\uff09\uff0c\u53ea\u6709\u5728\u5b58\u5728\u4e0b\u4e00tile\u65f6\u8fdb\u884c\n        if (k_tile + BLOCK_SIZE < N) {\n            // A next tile\n            int a_row_sel = tid_x / 4;          // 0..3\n            int a_vec_seg = tid_x % 4;          // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4;\n\n            float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = k_tile + BLOCK_SIZE + local_k_base + 0;\n                int gk1 = k_tile + BLOCK_SIZE + local_k_base + 1;\n                int gk2 = k_tile + BLOCK_SIZE + local_k_base + 2;\n                int gk3 = k_tile + BLOCK_SIZE + local_k_base + 3;\n                const float* a_ptr_n = &A[g_row * N + gk0];\n                uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                if (gk3 < N && (aline_n % 16 == 0)) {\n                    a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                } else {\n                    a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n            Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n            Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n            Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n            // B next tile: \u7ee7\u7eed\u91c7\u7528\u8f6c\u7f6e\u5e03\u5c40\u5199\u5165\u5171\u4eab\u5185\u5b58\n            int next_kB = k_tile + BLOCK_SIZE + tid_y;\n            float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (next_kB < N) {\n                const float* b_ptr_n = &B[next_kB * N + c0];\n                uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                if (c3 < N && (bline_n % 16 == 0)) {\n                    b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                } else {\n                    b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                    b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                    b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                    b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_next[b_c0_local][tid_y] = b4n.x;\n            Bsub_next[b_c1_local][tid_y] = b4n.y;\n            Bsub_next[b_c2_local][tid_y] = b4n.z;\n            Bsub_next[b_c3_local][tid_y] = b4n.w;\n        }\n\n        // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u4e0b\u4e00tile\u7684\u52a0\u8f7d\n        __syncthreads();\n\n        // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n        if (k_tile + BLOCK_SIZE < N) {\n            float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n            Asub_curr = Asub_next;\n            Asub_next = tmpA;\n\n            float (*tmpB)[BLOCK_SIZE] = Bsub_curr;\n            Bsub_curr = Bsub_next;\n            Bsub_next = tmpB;\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  },
  {
    "round": 30,
    "goal": "Optimize L2 cache utilization by implementing a more aggressive cache blocking strategy that increases data reuse across multiple output tiles within the same thread block, while maintaining the successful Morton ordering and double buffering approach, to reduce the DRAM-to-L2 throughput ratio by maximizing cache locality and minimizing global memory transactions per FLOP.",
    "status": "Failed (Performance Regression)",
    "time_ms": 1.5209471702575683,
    "ptxas_metrics": {
      "registers_used": 45.0,
      "shared_mem_bytes": 16384.0,
      "spill_bytes": 0.0
    },
    "details": "New time 1.521 ms is not better than best time 1.499 ms.",
    "code": "#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <stdint.h>\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 16\n#endif\n\n#ifndef CACHE_BLOCK_FACTOR\n#define CACHE_BLOCK_FACTOR 2\n#endif\n\n// Helpers for Morton (Z-order) decoding\n__device__ __forceinline__ uint32_t compact1by1(uint32_t x) {\n    x &= 0x55555555u;\n    x = (x | (x >> 1)) & 0x33333333u;\n    x = (x | (x >> 2)) & 0x0F0F0F0Fu;\n    x = (x | (x >> 4)) & 0x00FF00FFu;\n    x = (x | (x >> 8)) & 0x0000FFFFu;\n    return x;\n}\n\n__device__ __forceinline__ uint32_t morton_decode_x(uint32_t code) {\n    return compact1by1(code);\n}\n\n__device__ __forceinline__ uint32_t morton_decode_y(uint32_t code) {\n    return compact1by1(code >> 1);\n}\n\n__device__ __forceinline__ uint32_t highest_pow2_leq(uint32_t n) {\n    uint32_t p = 1u;\n    while ((p << 1u) <= n) { p <<= 1u; }\n    return p;\n}\n\n// ------------------------------------------------------------------\n// KERNEL: gemm_kernel \n// ------------------------------------------------------------------\n__global__ void gemm_kernel(\n    const float* __restrict__ A,\n    const float* __restrict__ B,\n    float* __restrict__ C,\n    int N\n) {\n    // \u5bc4\u5b58\u5668\u5206\u5757(\u6bcf\u7ebf\u7a0b\u8ba1\u7b974x4\u8f93\u51fa) + \u5171\u4eab\u5185\u5b58\u53cc\u7f13\u51b2 + \u8f6f\u4ef6\u6d41\u6c34\n    __shared__ float Asub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Asub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_ping[BLOCK_SIZE][4 * BLOCK_SIZE];\n    __shared__ float Bsub_pong[BLOCK_SIZE][4 * BLOCK_SIZE];\n\n    int tid_y = threadIdx.y; // [0, BLOCK_SIZE)\n    int tid_x = threadIdx.x; // [0, BLOCK_SIZE)\n\n    // -------------------------------\n    // Direct Z-Order (Morton) block mapping via bit deinterleave\n    // -------------------------------\n    const int TILE_SIZE = 4 * BLOCK_SIZE; // 64\n    // \u9700\u8981\u7684tile\u6570\u91cf\uff08\u6bcftile\u8986\u76d664x64\u8f93\u51fa\uff09\n    uint32_t w = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n    uint32_t h = static_cast<uint32_t>((N + TILE_SIZE - 1) / TILE_SIZE);\n\n    // \u5c06\u4e8c\u7ef4block\u7d22\u5f15\u6309\u884c\u4e3b\u5e8f\u538b\u6210\u4e00\u7ef4id\n    uint32_t block_id = static_cast<uint32_t>(blockIdx.y) * static_cast<uint32_t>(gridDim.x)\n                      + static_cast<uint32_t>(blockIdx.x);\n\n    // \u8ba1\u7b97\u80fd\u8986\u76d6max(w,h)\u7684\u6700\u5c0f2\u6b21\u5e42P\uff0c\u5e76\u4ec5\u4f7f\u7528\u524dP*P\u4e2a\u5757\u8fdb\u884cMorton\u6620\u5c04\n    uint32_t max_wh = (w > h) ? w : h;\n    uint32_t P = 1u;\n    while (P < max_wh) P <<= 1;\n\n    uint32_t P2 = P * P;\n    if (block_id >= P2) {\n        return;\n    }\n\n    // \u76f4\u63a5\u901a\u8fc7Morton\u89e3\u7801\u5f97\u5230P\u00d7P\u7f51\u683c\u4e2d\u7684\u5750\u6807\uff0c\u7136\u540e\u88c1\u526a\u5230\u6709\u6548\u77e9\u5f62(w,h)\n    uint32_t tile_z_x = morton_decode_x(block_id);\n    uint32_t tile_z_y = morton_decode_y(block_id);\n\n    if (tile_z_x >= w || tile_z_y >= h) {\n        return;\n    }\n\n    int tile_row_base = static_cast<int>(tile_z_y) * TILE_SIZE;\n    int tile_col_base = static_cast<int>(tile_z_x) * TILE_SIZE;\n\n    // \u82e5\u6574\u4e2atile\u5df2\u5b8c\u5168\u8d8a\u754c\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\uff08\u4fdd\u62a4\uff0c\u7406\u8bba\u4e0a\u4e0d\u4f1a\u89e6\u53d1\uff09\n    if (tile_row_base >= N || tile_col_base >= N) {\n        return;\n    }\n\n    // \u6bcf\u7ebf\u7a0b\u8d1f\u8d23\u76844x4\u8f93\u51fa\u4f4d\u7f6e\uff08\u76f8\u5bf9\u4e8etile\u8d77\u59cb\uff09\n    int a_r0_local = tid_y * 4 + 0;\n    int a_r1_local = tid_y * 4 + 1;\n    int a_r2_local = tid_y * 4 + 2;\n    int a_r3_local = tid_y * 4 + 3;\n\n    int b_c0_local = tid_x * 4 + 0;\n    int b_c1_local = tid_x * 4 + 1;\n    int b_c2_local = tid_x * 4 + 2;\n    int b_c3_local = tid_x * 4 + 3;\n\n    int r0 = tile_row_base + a_r0_local;\n    int r1 = tile_row_base + a_r1_local;\n    int r2 = tile_row_base + a_r2_local;\n    int r3 = tile_row_base + a_r3_local;\n\n    int c0 = tile_col_base + b_c0_local;\n    int c1 = tile_col_base + b_c1_local;\n    int c2 = tile_col_base + b_c2_local;\n    int c3 = tile_col_base + b_c3_local;\n\n    // \u5bc4\u5b58\u5668\u4e2d\u76844x4\u7d2f\u52a0\u5668\n    float acc00 = 0.0f, acc01 = 0.0f, acc02 = 0.0f, acc03 = 0.0f;\n    float acc10 = 0.0f, acc11 = 0.0f, acc12 = 0.0f, acc13 = 0.0f;\n    float acc20 = 0.0f, acc21 = 0.0f, acc22 = 0.0f, acc23 = 0.0f;\n    float acc30 = 0.0f, acc31 = 0.0f, acc32 = 0.0f, acc33 = 0.0f;\n\n    // \u6307\u5411\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u7684\u5171\u4eab\u5185\u5b58\u7f13\u51b2\u533a\n    float (*Asub_curr)[4 * BLOCK_SIZE] = Asub_ping;\n    float (*Bsub_curr)[4 * BLOCK_SIZE] = Bsub_ping;\n    float (*Asub_next)[4 * BLOCK_SIZE] = Asub_pong;\n    float (*Bsub_next)[4 * BLOCK_SIZE] = Bsub_pong;\n\n    // ----------------------------------------------\n    // K\u7ef4\u904d\u5386\uff1a\u5f15\u5165CACHE_BLOCK_FACTOR\u8fdb\u884cCache Blocking\n    // ----------------------------------------------\n    for (int group_k0 = 0; group_k0 < N; group_k0 += BLOCK_SIZE * CACHE_BLOCK_FACTOR) {\n        int group_k_end = group_k0 + BLOCK_SIZE * CACHE_BLOCK_FACTOR;\n        if (group_k_end > N) group_k_end = N;\n\n        // \u9884\u53d6\u672c\u7ec4\u7b2c\u4e00\u4e2aK\u7ef4tile\u5230curr\u7f13\u51b2\u533a\uff08\u5411\u91cf\u5316\u52a0\u8f7d\uff09\n        {\n            // --- A: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u67d0\u4e00\u884c\u5728K\u7ef4\u76844\u4e2a\u8fde\u7eed\u5143\u7d20 ---\n            int a_row_sel = tid_x / 4;      // 0..3\n            int a_vec_seg = tid_x % 4;      // 0..3\n            int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n            int g_row = tile_row_base + a_local_row;\n            int local_k_base = a_vec_seg * 4; // 0,4,8,12\n            int base_k = group_k0;\n\n            float4 a4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (g_row < N) {\n                int gk0 = base_k + local_k_base + 0;\n                int gk1 = base_k + local_k_base + 1;\n                int gk2 = base_k + local_k_base + 2;\n                int gk3 = base_k + local_k_base + 3;\n                const float* a_ptr = &A[g_row * N + gk0];\n                uintptr_t aline = reinterpret_cast<uintptr_t>(a_ptr);\n                if (gk3 < N && (aline % 16 == 0)) {\n                    a4 = *reinterpret_cast<const float4*>(a_ptr);\n                } else {\n                    a4.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                    a4.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                    a4.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                    a4.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                }\n            }\n\n            Asub_curr[local_k_base + 0][a_local_row] = a4.x;\n            Asub_curr[local_k_base + 1][a_local_row] = a4.y;\n            Asub_curr[local_k_base + 2][a_local_row] = a4.z;\n            Asub_curr[local_k_base + 3][a_local_row] = a4.w;\n\n            // --- B: \u6bcf\u7ebf\u7a0b\u52a0\u8f7d\u4e00\u4e2afloat4\uff0c\u8986\u76d6\u540c\u4e00K\u884c\u4e0a\u76844\u4e2a\u8fde\u7eed\u5217 ---\n            int kB = base_k + tid_y;\n            float4 b4 = make_float4(0.f, 0.f, 0.f, 0.f);\n            if (kB < N) {\n                const float* b_ptr = &B[kB * N + c0];\n                uintptr_t bline = reinterpret_cast<uintptr_t>(b_ptr);\n                if (c3 < N && (bline % 16 == 0)) {\n                    b4 = *reinterpret_cast<const float4*>(b_ptr);\n                } else {\n                    b4.x = (c0 < N) ? B[kB * N + c0] : 0.0f;\n                    b4.y = (c1 < N) ? B[kB * N + c1] : 0.0f;\n                    b4.z = (c2 < N) ? B[kB * N + c2] : 0.0f;\n                    b4.w = (c3 < N) ? B[kB * N + c3] : 0.0f;\n                }\n            }\n\n            Bsub_curr[tid_y][b_c0_local] = b4.x;\n            Bsub_curr[tid_y][b_c1_local] = b4.y;\n            Bsub_curr[tid_y][b_c2_local] = b4.z;\n            Bsub_curr[tid_y][b_c3_local] = b4.w;\n        }\n\n        __syncthreads();\n\n        // \u5904\u7406\u672c\u7ec4\u5185\u7684\u591a\u4e2aK tiles\n        for (int k_tile = group_k0; k_tile < group_k_end; k_tile += BLOCK_SIZE) {\n\n            // \u5185\u5c42k\u5faa\u73af\uff0cUNROLL_FACTOR=4\uff08\u91cd\u6392FMA\u4ee5\u63d0\u5347\u6307\u4ee4\u7ea7\u5e76\u884c\u5ea6\uff09\n            #pragma unroll\n            for (int k = 0; k < BLOCK_SIZE; k += 4) {\n                // k + 0\n                {\n                    float a0 = Asub_curr[k + 0][a_r0_local];\n                    float a1 = Asub_curr[k + 0][a_r1_local];\n                    float a2 = Asub_curr[k + 0][a_r2_local];\n                    float a3 = Asub_curr[k + 0][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 0][b_c0_local];\n                    float b1 = Bsub_curr[k + 0][b_c1_local];\n                    float b2 = Bsub_curr[k + 0][b_c2_local];\n                    float b3 = Bsub_curr[k + 0][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 1\n                {\n                    float a0 = Asub_curr[k + 1][a_r0_local];\n                    float a1 = Asub_curr[k + 1][a_r1_local];\n                    float a2 = Asub_curr[k + 1][a_r2_local];\n                    float a3 = Asub_curr[k + 1][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 1][b_c0_local];\n                    float b1 = Bsub_curr[k + 1][b_c1_local];\n                    float b2 = Bsub_curr[k + 1][b_c2_local];\n                    float b3 = Bsub_curr[k + 1][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 2\n                {\n                    float a0 = Asub_curr[k + 2][a_r0_local];\n                    float a1 = Asub_curr[k + 2][a_r1_local];\n                    float a2 = Asub_curr[k + 2][a_r2_local];\n                    float a3 = Asub_curr[k + 2][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 2][b_c0_local];\n                    float b1 = Bsub_curr[k + 2][b_c1_local];\n                    float b2 = Bsub_curr[k + 2][b_c2_local];\n                    float b3 = Bsub_curr[k + 2][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n\n                // k + 3\n                {\n                    float a0 = Asub_curr[k + 3][a_r0_local];\n                    float a1 = Asub_curr[k + 3][a_r1_local];\n                    float a2 = Asub_curr[k + 3][a_r2_local];\n                    float a3 = Asub_curr[k + 3][a_r3_local];\n\n                    float b0 = Bsub_curr[k + 3][b_c0_local];\n                    float b1 = Bsub_curr[k + 3][b_c1_local];\n                    float b2 = Bsub_curr[k + 3][b_c2_local];\n                    float b3 = Bsub_curr[k + 3][b_c3_local];\n\n                    acc00 += a0 * b0;\n                    acc11 += a1 * b1;\n                    acc22 += a2 * b2;\n                    acc33 += a3 * b3;\n\n                    acc01 += a0 * b1;\n                    acc12 += a1 * b2;\n                    acc23 += a2 * b3;\n                    acc30 += a3 * b0;\n\n                    acc02 += a0 * b2;\n                    acc13 += a1 * b3;\n                    acc20 += a2 * b0;\n                    acc31 += a3 * b1;\n\n                    acc03 += a0 * b3;\n                    acc10 += a1 * b0;\n                    acc21 += a2 * b1;\n                    acc32 += a3 * b2;\n                }\n            }\n\n            // \u9884\u53d6\u4e0b\u4e00\u4e2aK\u7ef4tile\u5230next\u7f13\u51b2\u533a\uff08\u4ec5\u9650\u4e8e\u672ccache-block\u5185\uff09\n            bool next_in_same_group = (k_tile + BLOCK_SIZE) < group_k_end;\n            if (next_in_same_group) {\n                // A next tile\n                int a_row_sel = tid_x / 4;          // 0..3\n                int a_vec_seg = tid_x % 4;          // 0..3\n                int a_local_row = tid_y * 4 + a_row_sel; // 0..63\n                int g_row = tile_row_base + a_local_row;\n                int local_k_base = a_vec_seg * 4;\n                int base_k_n = k_tile + BLOCK_SIZE;\n\n                float4 a4n = make_float4(0.f, 0.f, 0.f, 0.f);\n                if (g_row < N) {\n                    int gk0 = base_k_n + local_k_base + 0;\n                    int gk1 = base_k_n + local_k_base + 1;\n                    int gk2 = base_k_n + local_k_base + 2;\n                    int gk3 = base_k_n + local_k_base + 3;\n                    const float* a_ptr_n = &A[g_row * N + gk0];\n                    uintptr_t aline_n = reinterpret_cast<uintptr_t>(a_ptr_n);\n                    if (gk3 < N && (aline_n % 16 == 0)) {\n                        a4n = *reinterpret_cast<const float4*>(a_ptr_n);\n                    } else {\n                        a4n.x = (gk0 < N) ? A[g_row * N + gk0] : 0.0f;\n                        a4n.y = (gk1 < N) ? A[g_row * N + gk1] : 0.0f;\n                        a4n.z = (gk2 < N) ? A[g_row * N + gk2] : 0.0f;\n                        a4n.w = (gk3 < N) ? A[g_row * N + gk3] : 0.0f;\n                    }\n                }\n\n                Asub_next[local_k_base + 0][a_local_row] = a4n.x;\n                Asub_next[local_k_base + 1][a_local_row] = a4n.y;\n                Asub_next[local_k_base + 2][a_local_row] = a4n.z;\n                Asub_next[local_k_base + 3][a_local_row] = a4n.w;\n\n                // B next tile\n                int next_kB = (k_tile + BLOCK_SIZE) + tid_y;\n                float4 b4n = make_float4(0.f, 0.f, 0.f, 0.f);\n                if (next_kB < N) {\n                    const float* b_ptr_n = &B[next_kB * N + c0];\n                    uintptr_t bline_n = reinterpret_cast<uintptr_t>(b_ptr_n);\n                    if (c3 < N && (bline_n % 16 == 0)) {\n                        b4n = *reinterpret_cast<const float4*>(b_ptr_n);\n                    } else {\n                        b4n.x = (c0 < N) ? B[next_kB * N + c0] : 0.0f;\n                        b4n.y = (c1 < N) ? B[next_kB * N + c1] : 0.0f;\n                        b4n.z = (c2 < N) ? B[next_kB * N + c2] : 0.0f;\n                        b4n.w = (c3 < N) ? B[next_kB * N + c3] : 0.0f;\n                    }\n                }\n\n                Bsub_next[tid_y][b_c0_local] = b4n.x;\n                Bsub_next[tid_y][b_c1_local] = b4n.y;\n                Bsub_next[tid_y][b_c2_local] = b4n.z;\n                Bsub_next[tid_y][b_c3_local] = b4n.w;\n            }\n\n            // \u7b49\u5f85\u6240\u6709\u7ebf\u7a0b\u5b8c\u6210\u5f53\u524d\u8ba1\u7b97\u548c\u53ef\u80fd\u7684\u4e0b\u4e00tile\u7684\u52a0\u8f7d\uff08\u4ec5\u672c\u7ec4\u5185\uff09\n            __syncthreads();\n\n            // \u4ea4\u6362\u7f13\u51b2\u533a\uff08\u4ec5\u5f53\u786e\u5b9e\u9884\u53d6\u4e86\u4e0b\u4e00tile\u65f6\uff09\n            if (next_in_same_group) {\n                float (*tmpA)[4 * BLOCK_SIZE] = Asub_curr;\n                Asub_curr = Asub_next;\n                Asub_next = tmpA;\n\n                float (*tmpB)[4 * BLOCK_SIZE] = Bsub_curr;\n                Bsub_curr = Bsub_next;\n                Bsub_next = tmpB;\n            }\n        }\n    }\n\n    // \u5199\u56de\u6700\u7ec8\u7ed3\u679c\uff084x4\u8f93\u51fa\uff0c\u9700\u8fb9\u754c\u68c0\u67e5\uff09\n    if (r0 < N && c0 < N) C[r0 * N + c0] = acc00;\n    if (r0 < N && c1 < N) C[r0 * N + c1] = acc01;\n    if (r0 < N && c2 < N) C[r0 * N + c2] = acc02;\n    if (r0 < N && c3 < N) C[r0 * N + c3] = acc03;\n\n    if (r1 < N && c0 < N) C[r1 * N + c0] = acc10;\n    if (r1 < N && c1 < N) C[r1 * N + c1] = acc11;\n    if (r1 < N && c2 < N) C[r1 * N + c2] = acc12;\n    if (r1 < N && c3 < N) C[r1 * N + c3] = acc13;\n\n    if (r2 < N && c0 < N) C[r2 * N + c0] = acc20;\n    if (r2 < N && c1 < N) C[r2 * N + c1] = acc21;\n    if (r2 < N && c2 < N) C[r2 * N + c2] = acc22;\n    if (r2 < N && c3 < N) C[r2 * N + c3] = acc23;\n\n    if (r3 < N && c0 < N) C[r3 * N + c0] = acc30;\n    if (r3 < N && c1 < N) C[r3 * N + c1] = acc31;\n    if (r3 < N && c2 < N) C[r3 * N + c2] = acc32;\n    if (r3 < N && c3 < N) C[r3 * N + c3] = acc33;\n}\n\n// ------------------------------------------------------------------\n// WRAPPER: gemm_cuda (\u8fd9\u662fPyTorch\u548cCUDA\u4e4b\u95f4\u7684\u6865\u6881)\n// ------------------------------------------------------------------\ntorch::Tensor gemm_cuda(torch::Tensor A, torch::Tensor B) {\n    \n    // --- \u8f93\u5165\u9a8c\u8bc1 ---\n    TORCH_CHECK(A.device().is_cuda(), \"A must be a CUDA tensor\");\n    TORCH_CHECK(B.device().is_cuda(), \"B must be a CUDA tensor\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat32, \"A must be float32\");\n    TORCH_CHECK(B.scalar_type() == torch::kFloat32, \"B must be float32\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Inputs must be 2D tensors\");\n    TORCH_CHECK(A.size(1) == B.size(0), \"Matrix dimensions mismatch\");\n    TORCH_CHECK(A.is_contiguous(), \"A must be contiguous\");\n    TORCH_CHECK(B.is_contiguous(), \"B must be contiguous\");\n\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    TORCH_CHECK(M == N && K == N, \"This naive example assumes square N=M=K matrices\");\n    auto C = torch::zeros({M, N}, A.options());\n\n    // --- \u5185\u6838\u542f\u52a8\u914d\u7f6e ---\n    const int block_dim_x = BLOCK_SIZE;\n    const int block_dim_y = BLOCK_SIZE;\n    const int grid_dim_x = (N + block_dim_x - 1) / block_dim_x;\n    const int grid_dim_y = (N + block_dim_y - 1) / block_dim_y;\n    dim3 blocks(grid_dim_x, grid_dim_y);\n    dim3 threads(block_dim_x, block_dim_y);\n\n    // --- \u542f\u52a8\u5185\u6838 ---\n    gemm_kernel<<<blocks, threads>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    // --- \u9519\u8bef\u68c0\u67e5 ---\n    cudaError_t err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        throw std::runtime_error(\"CUDA error in gemm_kernel: \" + std::string(cudaGetErrorString(err)));\n    }\n    return C;\n}"
  }
]